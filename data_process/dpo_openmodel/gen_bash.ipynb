{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated qwen_bash/run_1.sh with index range [0, 12539) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_0_12539.log\n",
      "Generated qwen_bash/run_2.sh with index range [12539, 25078) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_12539_25078.log\n",
      "Generated qwen_bash/run_3.sh with index range [25078, 37617) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_25078_37617.log\n",
      "Generated qwen_bash/run_4.sh with index range [37617, 50156) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_37617_50156.log\n",
      "Generated qwen_bash/run_5.sh with index range [50156, 62695) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_50156_62695.log\n",
      "Generated qwen_bash/run_6.sh with index range [62695, 75234) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_62695_75234.log\n",
      "Generated qwen_bash/run_7.sh with index range [75234, 87773) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_75234_87773.log\n",
      "Generated qwen_bash/run_8.sh with index range [87773, 100312) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_87773_100312.log\n",
      "Generated qwen_bash/run_9.sh with index range [100312, 112851) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_100312_112851.log\n",
      "Generated qwen_bash/run_10.sh with index range [112851, 125390) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_112851_125390.log\n",
      "Generated qwen_bash/run_11.sh with index range [125390, 137929) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_125390_137929.log\n",
      "Generated qwen_bash/run_12.sh with index range [137929, 150476) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_137929_150476.log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 配置路径\n",
    "DATA_PATH = \"/mnt/lingjiejiang/multimodal_code/data/dpo/merged_html_chart_150k.json\"\n",
    "OUTPUT_DIR = \"qwen_bash\"\n",
    "PYTHON_SCRIPT = \"data_process/dpo_openmodel/html_generate.py\"\n",
    "MODEL_NAME = \"Qwen2-VL-72B-Instruct\"\n",
    "MODEL_PATH = \"/mnt/lingjiejiang/multimodal_code/checkpoints/llms/Qwen2-VL-72B-Instruct\"\n",
    "CUDA_DEVICES = \"0,1,2,3,4,5,6,7\"\n",
    "\n",
    "def get_total_lines(file_path):\n",
    "    \"\"\" 计算 JSON 文件的总数据量 \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return len(data)\n",
    "\n",
    "def generate_bash_scripts(machine_num):\n",
    "    \"\"\" 生成 run_X.sh 脚本，并在 {MODEL_NAME}_log/ 目录下记录日志 \"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    log_dir = f\"/mnt/lingjiejiang/multimodal_code/data/dpo/{MODEL_NAME}_log\"\n",
    "    os.makedirs(log_dir, exist_ok=True)  # 创建日志目录\n",
    "\n",
    "    total_lines = get_total_lines(DATA_PATH)\n",
    "    batch_size = total_lines // machine_num  # 每台机器的索引范围\n",
    "\n",
    "    for i in range(machine_num):\n",
    "        start_index = i * batch_size\n",
    "        end_index = total_lines if i == machine_num - 1 else (i + 1) * batch_size  # 最后一台机器处理剩余部分\n",
    "\n",
    "        log_file = f\"{log_dir}/dpo_{start_index}_{end_index}.log\"\n",
    "        script_name = os.path.join(OUTPUT_DIR, f\"run_{i+1}.sh\")\n",
    "\n",
    "        with open(script_name, \"w\") as f:\n",
    "            f.write(f\"\"\"#!/bin/bash\n",
    "\n",
    "export CUDA_VISIBLE_DEVICES={CUDA_DEVICES}\n",
    "\n",
    "python {PYTHON_SCRIPT} \\\\\n",
    "    --model_name {MODEL_NAME} \\\\\n",
    "    --model_path {MODEL_PATH} \\\\\n",
    "    --start_index {start_index} \\\\\n",
    "    --end_index {end_index} | tee -a {log_file}\n",
    "\n",
    "python run_gpu.py\n",
    "\"\"\")\n",
    "        # os.chmod(script_name, 0o755)  # 赋予可执行权限\n",
    "        print(f\"Generated {script_name} with index range [{start_index}, {end_index}) and logging to {log_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    machine_num = int(input(\"Enter the number of machines: \"))\n",
    "    generate_bash_scripts(machine_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated qwen_bash_7b/run_multi_gpu.sh for multi-GPU execution.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 配置路径\n",
    "DATA_PATH = \"/mnt/lingjiejiang/multimodal_code/data/dpo/merged_html_chart_150k.json\"\n",
    "OUTPUT_DIR = \"qwen_bash_7b\"\n",
    "PYTHON_SCRIPT = \"data_process/dpo_openmodel/html_generate_7b.py\"\n",
    "MODEL_NAME = \"Qwen2-VL-7B-Instruct\"\n",
    "MODEL_PATH = \"/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/vlm_checkpoints/Qwen2-VL-7B-Instruct\"\n",
    "CUDA_DEVICES = [\"0\", \"1\", \"2\", \"3\"]  # **设置可用的 GPU 编号**\n",
    "\n",
    "def get_total_lines(file_path):\n",
    "    \"\"\"计算 JSON 文件的总数据量\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return len(data)\n",
    "\n",
    "def generate_multi_gpu_script():\n",
    "    \"\"\"生成 `run_multi_gpu.sh`，在一台机器上并行使用多个 GPU\"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    log_dir = f\"/mnt/lingjiejiang/multimodal_code/data/dpo/{MODEL_NAME}_log\"\n",
    "    os.makedirs(log_dir, exist_ok=True)  # 创建日志目录\n",
    "\n",
    "    total_lines = get_total_lines(DATA_PATH)\n",
    "    num_gpus = len(CUDA_DEVICES)\n",
    "    batch_size = total_lines // num_gpus  # 每个 GPU 处理的索引范围\n",
    "\n",
    "    script_name = os.path.join(OUTPUT_DIR, \"run_multi_gpu.sh\")\n",
    "    \n",
    "    with open(script_name, \"w\") as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "        for i, gpu_id in enumerate(CUDA_DEVICES):\n",
    "            start_index = i * batch_size\n",
    "            end_index = total_lines if i == num_gpus - 1 else (i + 1) * batch_size  # 最后一个 GPU 处理剩余部分\n",
    "\n",
    "            log_file = f\"{log_dir}/dpo_{start_index}_{end_index}.log\"\n",
    "\n",
    "            f.write(f\"\"\"CUDA_VISIBLE_DEVICES={gpu_id} python {PYTHON_SCRIPT} \\\\\n",
    "    --model_name {MODEL_NAME} \\\\\n",
    "    --model_path {MODEL_PATH} \\\\\n",
    "    --batch_size 64 \\\\\n",
    "    --start_index {start_index} \\\\\n",
    "    --end_index {end_index} | tee -a {log_file} &\\n\"\"\")  # **后台运行 (&) 任务**\n",
    "\n",
    "        f.write(\"\\nwait\\n\")  # **等待所有进程完成**\n",
    "\n",
    "    # os.chmod(script_name, 0o755)  # 赋予执行权限\n",
    "    print(f\"Generated {script_name} for multi-GPU execution.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_multi_gpu_script()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chartmimic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
