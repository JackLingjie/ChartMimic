{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated qwen_bash/run_1.sh with index range [0, 12539) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_0_12539.log\n",
      "Generated qwen_bash/run_2.sh with index range [12539, 25078) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_12539_25078.log\n",
      "Generated qwen_bash/run_3.sh with index range [25078, 37617) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_25078_37617.log\n",
      "Generated qwen_bash/run_4.sh with index range [37617, 50156) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_37617_50156.log\n",
      "Generated qwen_bash/run_5.sh with index range [50156, 62695) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_50156_62695.log\n",
      "Generated qwen_bash/run_6.sh with index range [62695, 75234) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_62695_75234.log\n",
      "Generated qwen_bash/run_7.sh with index range [75234, 87773) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_75234_87773.log\n",
      "Generated qwen_bash/run_8.sh with index range [87773, 100312) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_87773_100312.log\n",
      "Generated qwen_bash/run_9.sh with index range [100312, 112851) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_100312_112851.log\n",
      "Generated qwen_bash/run_10.sh with index range [112851, 125390) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_112851_125390.log\n",
      "Generated qwen_bash/run_11.sh with index range [125390, 137929) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_125390_137929.log\n",
      "Generated qwen_bash/run_12.sh with index range [137929, 150476) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_137929_150476.log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 配置路径\n",
    "DATA_PATH = \"/mnt/lingjiejiang/multimodal_code/data/dpo/merged_html_chart_150k.json\"\n",
    "OUTPUT_DIR = \"qwen_bash\"\n",
    "PYTHON_SCRIPT = \"data_process/dpo_openmodel/html_generate.py\"\n",
    "MODEL_NAME = \"Qwen2-VL-72B-Instruct\"\n",
    "MODEL_PATH = \"/mnt/lingjiejiang/multimodal_code/checkpoints/llms/Qwen2-VL-72B-Instruct\"\n",
    "CUDA_DEVICES = \"0,1,2,3,4,5,6,7\"\n",
    "\n",
    "def get_total_lines(file_path):\n",
    "    \"\"\" 计算 JSON 文件的总数据量 \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return len(data)\n",
    "\n",
    "def generate_bash_scripts(machine_num):\n",
    "    \"\"\" 生成 run_X.sh 脚本，并在 {MODEL_NAME}_log/ 目录下记录日志 \"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    log_dir = f\"/mnt/lingjiejiang/multimodal_code/data/dpo/{MODEL_NAME}_log\"\n",
    "    os.makedirs(log_dir, exist_ok=True)  # 创建日志目录\n",
    "\n",
    "    total_lines = get_total_lines(DATA_PATH)\n",
    "    batch_size = total_lines // machine_num  # 每台机器的索引范围\n",
    "\n",
    "    for i in range(machine_num):\n",
    "        start_index = i * batch_size\n",
    "        end_index = total_lines if i == machine_num - 1 else (i + 1) * batch_size  # 最后一台机器处理剩余部分\n",
    "\n",
    "        log_file = f\"{log_dir}/dpo_{start_index}_{end_index}.log\"\n",
    "        script_name = os.path.join(OUTPUT_DIR, f\"run_{i+1}.sh\")\n",
    "\n",
    "        with open(script_name, \"w\") as f:\n",
    "            f.write(f\"\"\"#!/bin/bash\n",
    "\n",
    "export CUDA_VISIBLE_DEVICES={CUDA_DEVICES}\n",
    "\n",
    "python {PYTHON_SCRIPT} \\\\\n",
    "    --model_name {MODEL_NAME} \\\\\n",
    "    --model_path {MODEL_PATH} \\\\\n",
    "    --start_index {start_index} \\\\\n",
    "    --end_index {end_index} | tee -a {log_file}\n",
    "\n",
    "python run_gpu.py\n",
    "\"\"\")\n",
    "        # os.chmod(script_name, 0o755)  # 赋予可执行权限\n",
    "        print(f\"Generated {script_name} with index range [{start_index}, {end_index}) and logging to {log_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    machine_num = int(input(\"Enter the number of machines: \"))\n",
    "    generate_bash_scripts(machine_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated qwen_bash_7b/run_multi_gpu.sh for multi-GPU execution.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 配置路径\n",
    "DATA_PATH = \"/mnt/lingjiejiang/multimodal_code/data/dpo/merged_html_chart_150k.json\"\n",
    "OUTPUT_DIR = \"qwen_bash_7b\"\n",
    "PYTHON_SCRIPT = \"data_process/dpo_openmodel/html_generate_7b.py\"\n",
    "MODEL_NAME = \"Qwen2-VL-7B-Instruct\"\n",
    "MODEL_PATH = \"/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/vlm_checkpoints/Qwen2-VL-7B-Instruct\"\n",
    "CUDA_DEVICES = [\"0\", \"1\", \"2\", \"3\"]  # **设置可用的 GPU 编号**\n",
    "\n",
    "def get_total_lines(file_path):\n",
    "    \"\"\"计算 JSON 文件的总数据量\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return len(data)\n",
    "\n",
    "def generate_multi_gpu_script():\n",
    "    \"\"\"生成 `run_multi_gpu.sh`，在一台机器上并行使用多个 GPU\"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    log_dir = f\"/mnt/lingjiejiang/multimodal_code/data/dpo/{MODEL_NAME}_log\"\n",
    "    os.makedirs(log_dir, exist_ok=True)  # 创建日志目录\n",
    "\n",
    "    total_lines = get_total_lines(DATA_PATH)\n",
    "    num_gpus = len(CUDA_DEVICES)\n",
    "    batch_size = total_lines // num_gpus  # 每个 GPU 处理的索引范围\n",
    "\n",
    "    script_name = os.path.join(OUTPUT_DIR, \"run_multi_gpu.sh\")\n",
    "    \n",
    "    with open(script_name, \"w\") as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "        for i, gpu_id in enumerate(CUDA_DEVICES):\n",
    "            start_index = i * batch_size\n",
    "            end_index = total_lines if i == num_gpus - 1 else (i + 1) * batch_size  # 最后一个 GPU 处理剩余部分\n",
    "\n",
    "            log_file = f\"{log_dir}/dpo_{start_index}_{end_index}.log\"\n",
    "\n",
    "            f.write(f\"\"\"CUDA_VISIBLE_DEVICES={gpu_id} python {PYTHON_SCRIPT} \\\\\n",
    "    --model_name {MODEL_NAME} \\\\\n",
    "    --model_path {MODEL_PATH} \\\\\n",
    "    --batch_size 64 \\\\\n",
    "    --start_index {start_index} \\\\\n",
    "    --end_index {end_index} | tee -a {log_file} &\\n\"\"\")  # **后台运行 (&) 任务**\n",
    "\n",
    "        f.write(\"\\nwait\\n\")  # **等待所有进程完成**\n",
    "\n",
    "    # os.chmod(script_name, 0o755)  # 赋予执行权限\n",
    "    print(f\"Generated {script_name} for multi-GPU execution.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_multi_gpu_script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated code_bash/run_multi_gpu.sh for multi-GPU execution.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 配置路径\n",
    "SAVE_PATH = \"/mnt/lingjiejiang/multimodal_code/data/dpo/code/code_95k.json\"\n",
    "OUTPUT_DIR = \"code_bash\"\n",
    "PYTHON_SCRIPT = \"data_process/dpo_openmodel/code_generate.py\"\n",
    "MODEL_NAME = \"Meta-Llama-3.1-8B-Instruct\"\n",
    "MODEL_PATH = \"/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/sft_merge_checkpoints/Meta-Llama-3.1-8B-Instruct\"\n",
    "NUM_GPUS = 8  # GPU 数量\n",
    "BATCH_SIZE = 256  # 设定的 batch_size\n",
    "LOG_DIR = f\"/mnt/lingjiejiang/multimodal_code/data/dpo/{MODEL_NAME}_log\"\n",
    "\n",
    "# 确保日志目录存在\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def get_total_lines(file_path):\n",
    "    \"\"\" 计算 JSON 文件的总数据量 \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return len(data)\n",
    "\n",
    "def generate_multi_gpu_script():\n",
    "    \"\"\" 生成 `run_multi_gpu.sh`，在 8 个 GPU 上并行运行 \"\"\"\n",
    "    total_lines = get_total_lines(SAVE_PATH)\n",
    "    chunk_size = total_lines // NUM_GPUS  # 每个 GPU 处理的数据量\n",
    "\n",
    "    script_name = os.path.join(OUTPUT_DIR, \"run_multi_gpu.sh\")\n",
    "    \n",
    "    with open(script_name, \"w\") as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "        for i in range(NUM_GPUS):\n",
    "            start_index = i * chunk_size\n",
    "            end_index = total_lines if i == NUM_GPUS - 1 else (i + 1) * chunk_size  # 最后一个 GPU 处理剩余部分\n",
    "\n",
    "            log_file = f\"{LOG_DIR}/dpo_{start_index}_{end_index}.log\"\n",
    "\n",
    "            f.write(f\"\"\"CUDA_VISIBLE_DEVICES={i} python {PYTHON_SCRIPT} \\\\\n",
    "    --model_name {MODEL_NAME} \\\\\n",
    "    --model_path {MODEL_PATH} \\\\\n",
    "    --batch_size {BATCH_SIZE} \\\\\n",
    "    --start_index {start_index} \\\\\n",
    "    --end_index {end_index} | tee -a {log_file} &\\n\"\"\")  # **后台运行 (&) 任务**\n",
    "\n",
    "        f.write(\"\\nwait\\n\")  # **等待所有进程完成**\n",
    "\n",
    "    os.chmod(script_name, 0o755)  # 赋予执行权限\n",
    "    print(f\"Generated {script_name} for multi-GPU execution.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_multi_gpu_script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated qwen_chartbench/run_1.sh with index range [0, 11744) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_0_11744_chartbench46k.log\n",
      "Generated qwen_chartbench/run_2.sh with index range [11744, 23488) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_11744_23488_chartbench46k.log\n",
      "Generated qwen_chartbench/run_3.sh with index range [23488, 35232) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_23488_35232_chartbench46k.log\n",
      "Generated qwen_chartbench/run_4.sh with index range [35232, 46977) and logging to /mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-72B-Instruct_log/dpo_35232_46977_chartbench46k.log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 配置路径\n",
    "DATA_PATH = \"/mnt/lingjiejiang/multimodal_code/data/chart_data/ChartBench/chartbench_images_46k_code_dpo.json\"\n",
    "OUTPUT_DIR = \"qwen_chartbench\"\n",
    "PYTHON_SCRIPT = \"data_process/dpo_openmodel/html_generate_chart_bench.py\"\n",
    "MODEL_NAME = \"Qwen2-VL-72B-Instruct\"\n",
    "MODEL_PATH = \"/mnt/lingjiejiang/multimodal_code/checkpoints/llms/Qwen2-VL-72B-Instruct\"\n",
    "CUDA_DEVICES = \"0,1,2,3,4,5,6,7\"\n",
    "\n",
    "def get_total_lines(file_path):\n",
    "    \"\"\" 计算 JSON 文件的总数据量 \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return len(data)\n",
    "\n",
    "def generate_bash_scripts(machine_num):\n",
    "    \"\"\" 生成 run_X.sh 脚本，并在 {MODEL_NAME}_log/ 目录下记录日志 \"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    log_dir = f\"/mnt/lingjiejiang/multimodal_code/data/dpo/{MODEL_NAME}_log\"\n",
    "    os.makedirs(log_dir, exist_ok=True)  # 创建日志目录\n",
    "\n",
    "    total_lines = get_total_lines(DATA_PATH)\n",
    "    batch_size = total_lines // machine_num  # 每台机器的索引范围\n",
    "\n",
    "    for i in range(machine_num):\n",
    "        start_index = i * batch_size\n",
    "        end_index = total_lines if i == machine_num - 1 else (i + 1) * batch_size  # 最后一台机器处理剩余部分\n",
    "\n",
    "        log_file = f\"{log_dir}/dpo_{start_index}_{end_index}_chartbench46k.log\"\n",
    "        script_name = os.path.join(OUTPUT_DIR, f\"run_{i+1}.sh\")\n",
    "\n",
    "        with open(script_name, \"w\") as f:\n",
    "            f.write(f\"\"\"#!/bin/bash\n",
    "\n",
    "export CUDA_VISIBLE_DEVICES={CUDA_DEVICES}\n",
    "\n",
    "python {PYTHON_SCRIPT} \\\\\n",
    "    --model_name {MODEL_NAME} \\\\\n",
    "    --model_path {MODEL_PATH} \\\\\n",
    "    --start_index {start_index} \\\\\n",
    "    --end_index {end_index} | tee -a {log_file}\n",
    "\n",
    "python run_gpu.py\n",
    "\"\"\")\n",
    "        # os.chmod(script_name, 0o755)  # 赋予可执行权限\n",
    "        print(f\"Generated {script_name} with index range [{start_index}, {end_index}) and logging to {log_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    machine_num = 4\n",
    "    generate_bash_scripts(machine_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated qwen_bash_7b/run_multi_gpu_chart_bench.sh for multi-GPU execution.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 配置路径\n",
    "DATA_PATH = \"/mnt/lingjiejiang/multimodal_code/data/chart_data/ChartBench/chartbench_images_46k_code_dpo.json\"\n",
    "OUTPUT_DIR = \"qwen_bash_7b\"\n",
    "PYTHON_SCRIPT = \"data_process/dpo_openmodel/html_generate_7b_chart_bench.py\"\n",
    "MODEL_NAME = \"Qwen2-VL-7B-Instruct\"\n",
    "MODEL_PATH = \"/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/vlm_checkpoints/Qwen2-VL-7B-Instruct\"\n",
    "CUDA_PAIRS = [(\"0,1\"), (\"2,3\"), (\"4,5\"), (\"6,7\")]\n",
    "OUTPUT_DIR_PARAM = \"/mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-7B-Instruct_generate_chartbench46k\"  # 新增 output_dir 参数\n",
    "\n",
    "def get_total_lines(file_path):\n",
    "    \"\"\"计算 JSON 文件的总数据量\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return len(data)\n",
    "\n",
    "def generate_multi_gpu_script():\n",
    "    \"\"\"生成 `run_multi_gpu.sh`，在一台机器上并行使用多个 GPU\"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    log_dir = f\"/mnt/lingjiejiang/multimodal_code/data/dpo/{MODEL_NAME}_log\"\n",
    "    os.makedirs(log_dir, exist_ok=True)  # 创建日志目录\n",
    "\n",
    "    total_lines = get_total_lines(DATA_PATH)\n",
    "    num_jobs = len(CUDA_PAIRS)\n",
    "    batch_size = total_lines // num_jobs  # 每个作业处理的索引范围\n",
    "\n",
    "    script_name = os.path.join(OUTPUT_DIR, \"run_multi_gpu_chart_bench.sh\")\n",
    "    \n",
    "    with open(script_name, \"w\") as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "        for i in range(num_jobs):\n",
    "            cuda_devices = CUDA_PAIRS[i % len(CUDA_PAIRS)]  # 交替使用 GPU 设备\n",
    "            start_index = i * batch_size\n",
    "            end_index = total_lines if i == num_jobs - 1 else (i + 1) * batch_size  # 最后一个 GPU 处理剩余部分\n",
    "\n",
    "            log_file = f\"{log_dir}/dpo_{start_index}_{end_index}_chart_bench.log\"\n",
    "\n",
    "            f.write(f\"\"\"CUDA_VISIBLE_DEVICES={cuda_devices} python {PYTHON_SCRIPT} \\\n",
    "    --model_name {MODEL_NAME} \\\n",
    "    --model_path {MODEL_PATH} \\\n",
    "    --batch_size 64 \\\n",
    "    --start_index {start_index} \\\n",
    "    --end_index {end_index} \\\n",
    "    --output_dir {OUTPUT_DIR_PARAM} | tee -a {log_file} &\\n\"\"\")  # **后台运行 (&) 任务**\n",
    "\n",
    "        f.write(\"\\nwait\\n\")  # **等待所有进程完成**\n",
    "\n",
    "    print(f\"Generated {script_name} for multi-GPU execution.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_multi_gpu_script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated qwen_bash_7b/run_multi_gpu_chart_bench_4.sh for multi-GPU execution.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 配置路径\n",
    "DATA_PATH = \"/mnt/lingjiejiang/multimodal_code/data/chart_data/ChartBench/chartbench_images_46k_code_dpo.json\"\n",
    "OUTPUT_DIR = \"qwen_bash_7b\"\n",
    "PYTHON_SCRIPT = \"data_process/dpo_openmodel/html_generate_7b_chart_bench.py\"\n",
    "MODEL_NAME = \"Qwen2-VL-7B-Instruct\"\n",
    "MODEL_PATH = \"/mnt/lingjiejiang/textual_aesthetics/model_checkpoint/vlm_checkpoints/Qwen2-VL-7B-Instruct\"\n",
    "CUDA_PAIRS = [(\"0,1\"), (\"2,3\"), (\"4,5\"), (\"6,7\")]\n",
    "OUTPUT_DIR_PARAM = \"/mnt/lingjiejiang/multimodal_code/data/dpo/Qwen2-VL-7B-Instruct_generate_chartbench46k_4\"  # 新增 output_dir 参数\n",
    "\n",
    "def get_total_lines(file_path):\n",
    "    \"\"\"计算 JSON 文件的总数据量\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return len(data)\n",
    "\n",
    "def generate_multi_gpu_script():\n",
    "    \"\"\"生成 `run_multi_gpu.sh`，在一台机器上并行使用多个 GPU\"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    log_dir = f\"/mnt/lingjiejiang/multimodal_code/data/dpo/{MODEL_NAME}_log\"\n",
    "    os.makedirs(log_dir, exist_ok=True)  # 创建日志目录\n",
    "\n",
    "    total_lines = get_total_lines(DATA_PATH)\n",
    "    num_jobs = len(CUDA_PAIRS)\n",
    "    batch_size = total_lines // num_jobs  # 每个作业处理的索引范围\n",
    "\n",
    "    script_name = os.path.join(OUTPUT_DIR, \"run_multi_gpu_chart_bench_4.sh\")\n",
    "    \n",
    "    with open(script_name, \"w\") as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "        for i in range(num_jobs):\n",
    "            cuda_devices = CUDA_PAIRS[i % len(CUDA_PAIRS)]  # 交替使用 GPU 设备\n",
    "            start_index = i * batch_size\n",
    "            end_index = total_lines if i == num_jobs - 1 else (i + 1) * batch_size  # 最后一个 GPU 处理剩余部分\n",
    "\n",
    "            log_file = f\"{log_dir}/dpo_{start_index}_{end_index}_chart_bench.log\"\n",
    "\n",
    "            f.write(f\"\"\"CUDA_VISIBLE_DEVICES={cuda_devices} python {PYTHON_SCRIPT} \\\n",
    "    --model_name {MODEL_NAME} \\\n",
    "    --model_path {MODEL_PATH} \\\n",
    "    --batch_size 64 \\\n",
    "    --start_index {start_index} \\\n",
    "    --end_index {end_index} \\\n",
    "    --output_dir {OUTPUT_DIR_PARAM} | tee -a {log_file} &\\n\"\"\")  # **后台运行 (&) 任务**\n",
    "\n",
    "        f.write(\"\\nwait\\n\")  # **等待所有进程完成**\n",
    "\n",
    "    print(f\"Generated {script_name} for multi-GPU execution.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_multi_gpu_script()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chartmimic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
