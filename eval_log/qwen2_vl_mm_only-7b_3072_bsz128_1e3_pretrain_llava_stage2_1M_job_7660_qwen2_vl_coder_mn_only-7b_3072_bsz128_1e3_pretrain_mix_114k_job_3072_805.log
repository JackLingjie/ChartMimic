开始处理所有模型...
正在处理模型: qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660
INFO 01-17 16:52:07 config.py:350] This model supports multiple tasks: {'generate', 'embedding'}. Defaulting to 'generate'.
INFO 01-17 16:52:07 llm_engine.py:249] Initializing an LLM engine (v0.6.4) with config: model='/mnt/lingjiejiang/multimodal_code/exp/saves/qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job/sft/full/checkpoint-7660', speculative_config=None, tokenizer='/mnt/lingjiejiang/multimodal_code/exp/saves/qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job/sft/full/checkpoint-7660', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/mnt/lingjiejiang/multimodal_code/exp/saves/qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job/sft/full/checkpoint-7660, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-17 16:52:07 selector.py:135] Using Flash Attention backend.
INFO 01-17 16:52:08 model_runner.py:1072] Starting to load model /mnt/lingjiejiang/multimodal_code/exp/saves/qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job/sft/full/checkpoint-7660...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.89s/it]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:33<00:36, 18.34s/it]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [02:24<01:00, 60.39s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:27<00:00, 37.64s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:27<00:00, 36.76s/it]

INFO 01-17 16:54:35 model_runner.py:1077] Loading model weights took 15.5083 GB
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
INFO 01-17 16:54:40 worker.py:232] Memory profiling results: total_gpu_memory=79.25GiB initial_memory_usage=16.15GiB peak_torch_memory=20.53GiB memory_usage_post_profile=16.55Gib non_torch_memory=1.04GiB kv_cache_size=49.77GiB gpu_memory_utilization=0.90
INFO 01-17 16:54:40 gpu_executor.py:113] # GPU blocks: 58239, # CPU blocks: 4681
INFO 01-17 16:54:40 gpu_executor.py:117] Maximum concurrency for 32768 tokens per request: 28.44x
INFO 01-17 16:54:45 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-17 16:54:45 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-17 16:54:59 model_runner.py:1518] Graph capturing finished in 14 secs, took 0.37 GiB
Processing 500 files
INFO 01-17 16:55:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:55:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:33,  4.94s/it, est. speed input: 152.62 toks/s, output: 6.07 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:07,  2.24s/it, est. speed input: 399.96 toks/s, output: 15.29 toks/s]Processed prompts:   9%|▉         | 3/32 [00:05<00:37,  1.30s/it, est. speed input: 565.62 toks/s, output: 25.97 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:05<00:16,  1.64it/s, est. speed input: 863.27 toks/s, output: 49.32 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:05<00:10,  2.47it/s, est. speed input: 1087.44 toks/s, output: 74.14 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:06<00:05,  3.90it/s, est. speed input: 1470.35 toks/s, output: 117.60 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:06<00:05,  4.15it/s, est. speed input: 1534.72 toks/s, output: 132.96 toks/s]Processed prompts:  41%|████      | 13/32 [00:06<00:03,  4.85it/s, est. speed input: 1747.96 toks/s, output: 166.02 toks/s]Processed prompts:  50%|█████     | 16/32 [00:06<00:02,  6.64it/s, est. speed input: 2003.77 toks/s, output: 222.70 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:07<00:02,  6.85it/s, est. speed input: 2102.36 toks/s, output: 259.91 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:07<00:01,  6.95it/s, est. speed input: 2166.19 toks/s, output: 279.59 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:07<00:00, 11.23it/s, est. speed input: 2598.38 toks/s, output: 373.51 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:07<00:00, 10.71it/s, est. speed input: 2694.66 toks/s, output: 414.95 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:08<00:01,  4.89it/s, est. speed input: 2591.61 toks/s, output: 425.67 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:09<00:01,  3.92it/s, est. speed input: 2551.85 toks/s, output: 435.89 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:09<00:00,  3.80it/s, est. speed input: 2599.46 toks/s, output: 457.67 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:13<00:02,  1.02s/it, est. speed input: 1947.57 toks/s, output: 373.77 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:58<00:11, 11.24s/it, est. speed input: 462.87 toks/s, output: 155.75 toks/s] Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.82s/it, est. speed input: 475.81 toks/s, output: 226.04 toks/s]
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:40,  5.19s/it, est. speed input: 194.00 toks/s, output: 4.62 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:05<00:28,  1.03s/it, est. speed input: 761.60 toks/s, output: 20.70 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:05<00:16,  1.59it/s, est. speed input: 1001.42 toks/s, output: 35.68 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:05<00:13,  1.90it/s, est. speed input: 1158.89 toks/s, output: 44.65 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:05<00:07,  2.89it/s, est. speed input: 1406.85 toks/s, output: 65.81 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:06<00:06,  3.21it/s, est. speed input: 1571.79 toks/s, output: 76.97 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:06<00:06,  3.20it/s, est. speed input: 1630.81 toks/s, output: 88.89 toks/s]Processed prompts:  41%|████      | 13/32 [00:06<00:04,  4.09it/s, est. speed input: 1771.64 toks/s, output: 117.94 toks/s]Processed prompts:  50%|█████     | 16/32 [00:06<00:02,  6.27it/s, est. speed input: 2107.00 toks/s, output: 168.91 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:07<00:02,  6.70it/s, est. speed input: 2181.73 toks/s, output: 186.17 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:07<00:02,  5.86it/s, est. speed input: 2244.32 toks/s, output: 201.13 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:07<00:02,  5.49it/s, est. speed input: 2312.40 toks/s, output: 217.98 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:07<00:02,  5.53it/s, est. speed input: 2386.06 toks/s, output: 236.80 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:07<00:01,  5.69it/s, est. speed input: 2461.36 toks/s, output: 256.68 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:08<00:01,  5.84it/s, est. speed input: 2559.13 toks/s, output: 277.18 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:08<00:01,  6.44it/s, est. speed input: 2616.03 toks/s, output: 299.53 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:08<00:02,  3.23it/s, est. speed input: 2499.64 toks/s, output: 305.57 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:09<00:02,  3.20it/s, est. speed input: 2518.72 toks/s, output: 326.08 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:09<00:00,  5.10it/s, est. speed input: 2649.40 toks/s, output: 385.35 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:09<00:00,  4.26it/s, est. speed input: 2656.89 toks/s, output: 404.41 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:11<00:01,  1.91it/s, est. speed input: 2373.72 toks/s, output: 407.00 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:58<00:11, 11.13s/it, est. speed input: 486.59 toks/s, output: 149.17 toks/s] Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.84s/it, est. speed input: 498.72 toks/s, output: 218.90 toks/s]
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:52,  5.55s/it, est. speed input: 185.09 toks/s, output: 5.94 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:05<00:30,  1.08s/it, est. speed input: 710.82 toks/s, output: 25.91 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:05<00:13,  1.91it/s, est. speed input: 1249.75 toks/s, output: 48.53 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:06<00:08,  2.62it/s, est. speed input: 1493.83 toks/s, output: 65.15 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:06<00:06,  3.16it/s, est. speed input: 1811.02 toks/s, output: 84.38 toks/s]Processed prompts:  41%|████      | 13/32 [00:06<00:04,  4.15it/s, est. speed input: 2010.90 toks/s, output: 109.79 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:06<00:04,  4.17it/s, est. speed input: 2120.41 toks/s, output: 133.77 toks/s]Processed prompts:  50%|█████     | 16/32 [00:07<00:03,  4.10it/s, est. speed input: 2228.90 toks/s, output: 148.35 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:07<00:02,  5.30it/s, est. speed input: 2427.41 toks/s, output: 184.67 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:08<00:02,  5.12it/s, est. speed input: 2633.15 toks/s, output: 233.56 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:08<00:01,  6.58it/s, est. speed input: 2845.39 toks/s, output: 299.84 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:08<00:01,  5.56it/s, est. speed input: 2847.89 toks/s, output: 315.48 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:08<00:00,  6.74it/s, est. speed input: 3034.21 toks/s, output: 387.09 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:09<00:00,  4.70it/s, est. speed input: 2930.36 toks/s, output: 396.06 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:09<00:00,  4.78it/s, est. speed input: 2993.18 toks/s, output: 420.72 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:11<00:00,  1.64it/s, est. speed input: 2534.96 toks/s, output: 385.49 toks/s]Processed prompts: 100%|██████████| 32/32 [00:12<00:00,  1.72it/s, est. speed input: 2496.52 toks/s, output: 412.65 toks/s]Processed prompts: 100%|██████████| 32/32 [00:12<00:00,  2.61it/s, est. speed input: 2496.52 toks/s, output: 412.65 toks/s]
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:57:14 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:44,  5.31s/it, est. speed input: 221.48 toks/s, output: 7.35 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:07,  2.25s/it, est. speed input: 339.73 toks/s, output: 15.67 toks/s]Processed prompts:   9%|▉         | 3/32 [00:05<00:38,  1.34s/it, est. speed input: 421.07 toks/s, output: 25.70 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:28,  1.01s/it, est. speed input: 444.03 toks/s, output: 38.24 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:18,  1.46it/s, est. speed input: 553.67 toks/s, output: 52.95 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:06<00:14,  1.82it/s, est. speed input: 682.83 toks/s, output: 67.99 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:10,  2.36it/s, est. speed input: 746.80 toks/s, output: 84.71 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:06,  3.54it/s, est. speed input: 1030.79 toks/s, output: 119.28 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:07<00:06,  3.38it/s, est. speed input: 1172.24 toks/s, output: 135.75 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:04,  4.74it/s, est. speed input: 1457.10 toks/s, output: 177.25 toks/s]Processed prompts:  50%|█████     | 16/32 [00:07<00:02,  7.14it/s, est. speed input: 1909.84 toks/s, output: 261.99 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:07<00:02,  7.31it/s, est. speed input: 2003.29 toks/s, output: 283.39 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:08<00:02,  6.18it/s, est. speed input: 2086.42 toks/s, output: 300.82 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:08<00:01,  7.79it/s, est. speed input: 2243.47 toks/s, output: 349.91 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:08<00:01,  5.68it/s, est. speed input: 2245.44 toks/s, output: 364.32 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:08<00:01,  5.92it/s, est. speed input: 2312.74 toks/s, output: 388.10 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:09<00:01,  4.18it/s, est. speed input: 2312.66 toks/s, output: 420.25 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:10<00:02,  3.34it/s, est. speed input: 2248.82 toks/s, output: 433.42 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:10<00:02,  2.66it/s, est. speed input: 2155.30 toks/s, output: 445.05 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:10<00:01,  2.97it/s, est. speed input: 2188.32 toks/s, output: 473.61 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:11<00:01,  2.57it/s, est. speed input: 2205.37 toks/s, output: 490.77 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:13<00:02,  1.04it/s, est. speed input: 1886.27 toks/s, output: 449.62 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:15<00:02,  1.10s/it, est. speed input: 1757.01 toks/s, output: 456.06 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:16<00:01,  1.13s/it, est. speed input: 1685.81 toks/s, output: 474.17 toks/s]Processed prompts: 100%|██████████| 32/32 [00:58<00:00, 12.93s/it, est. speed input: 494.60 toks/s, output: 205.33 toks/s] Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.82s/it, est. speed input: 494.60 toks/s, output: 205.33 toks/s]
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:12 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:52,  5.58s/it, est. speed input: 153.95 toks/s, output: 2.87 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:13,  2.45s/it, est. speed input: 348.30 toks/s, output: 8.05 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:27,  1.02it/s, est. speed input: 688.54 toks/s, output: 20.78 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:06<00:14,  1.81it/s, est. speed input: 1086.54 toks/s, output: 36.63 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:06<00:07,  3.02it/s, est. speed input: 1597.13 toks/s, output: 62.85 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:06<00:04,  4.30it/s, est. speed input: 1823.99 toks/s, output: 95.68 toks/s]Processed prompts:  41%|████      | 13/32 [00:06<00:04,  4.72it/s, est. speed input: 1993.28 toks/s, output: 108.31 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:07<00:02,  5.76it/s, est. speed input: 2286.09 toks/s, output: 135.26 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:07<00:02,  7.25it/s, est. speed input: 2455.88 toks/s, output: 164.90 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:07<00:01, 10.39it/s, est. speed input: 2941.65 toks/s, output: 211.75 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:07<00:01,  7.70it/s, est. speed input: 3024.22 toks/s, output: 237.33 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:08<00:01,  6.59it/s, est. speed input: 3181.14 toks/s, output: 268.03 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:08<00:01,  5.37it/s, est. speed input: 3143.96 toks/s, output: 301.56 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:08<00:00,  6.74it/s, est. speed input: 3377.84 toks/s, output: 370.45 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:09<00:00,  5.19it/s, est. speed input: 3310.35 toks/s, output: 382.67 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:09<00:00,  4.23it/s, est. speed input: 3231.82 toks/s, output: 397.28 toks/s]Processed prompts: 100%|██████████| 32/32 [00:12<00:00,  1.57it/s, est. speed input: 2727.74 toks/s, output: 365.17 toks/s]Processed prompts: 100%|██████████| 32/32 [00:12<00:00,  2.65it/s, est. speed input: 2727.74 toks/s, output: 365.17 toks/s]
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:58:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:06,  6.03s/it, est. speed input: 152.91 toks/s, output: 3.65 toks/s]Processed prompts:   6%|▋         | 2/32 [00:06<01:20,  2.70s/it, est. speed input: 296.63 toks/s, output: 10.17 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:21,  1.26it/s, est. speed input: 789.15 toks/s, output: 31.64 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:13,  1.79it/s, est. speed input: 914.13 toks/s, output: 50.35 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:08,  2.67it/s, est. speed input: 1154.32 toks/s, output: 72.23 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:04,  4.09it/s, est. speed input: 1561.35 toks/s, output: 106.64 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:07<00:03,  4.77it/s, est. speed input: 1820.96 toks/s, output: 132.13 toks/s]Processed prompts:  50%|█████     | 16/32 [00:07<00:02,  6.03it/s, est. speed input: 2066.44 toks/s, output: 160.93 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:08<00:02,  4.81it/s, est. speed input: 2179.64 toks/s, output: 185.20 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:02,  4.36it/s, est. speed input: 2255.59 toks/s, output: 199.48 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:09<00:03,  3.79it/s, est. speed input: 2297.18 toks/s, output: 214.01 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:09<00:03,  3.65it/s, est. speed input: 2346.84 toks/s, output: 231.79 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:02,  4.17it/s, est. speed input: 2458.31 toks/s, output: 254.03 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:10<00:02,  3.01it/s, est. speed input: 2484.87 toks/s, output: 284.44 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:10<00:02,  3.36it/s, est. speed input: 2537.45 toks/s, output: 309.75 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:11<00:02,  2.85it/s, est. speed input: 2462.38 toks/s, output: 327.50 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:12<00:03,  1.59it/s, est. speed input: 2288.50 toks/s, output: 326.81 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:14<00:03,  1.08it/s, est. speed input: 2092.24 toks/s, output: 327.88 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:20<00:03,  1.98s/it, est. speed input: 1513.77 toks/s, output: 304.24 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:59<00:10, 10.77s/it, est. speed input: 547.62 toks/s, output: 174.42 toks/s] Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  1.87s/it, est. speed input: 567.21 toks/s, output: 242.72 toks/s]
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 16:59:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:32,  4.93s/it, est. speed input: 204.14 toks/s, output: 4.87 toks/s]Processed prompts:   9%|▉         | 3/32 [00:05<00:38,  1.33s/it, est. speed input: 485.14 toks/s, output: 15.78 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:05<00:25,  1.08it/s, est. speed input: 661.82 toks/s, output: 23.30 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:05<00:11,  2.09it/s, est. speed input: 1138.19 toks/s, output: 49.78 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:06<00:10,  2.30it/s, est. speed input: 1246.82 toks/s, output: 62.54 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:06<00:07,  3.00it/s, est. speed input: 1433.21 toks/s, output: 91.82 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:06<00:06,  3.46it/s, est. speed input: 1554.77 toks/s, output: 108.60 toks/s]Processed prompts:  50%|█████     | 16/32 [00:06<00:02,  6.63it/s, est. speed input: 2108.50 toks/s, output: 197.29 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:06<00:01,  7.97it/s, est. speed input: 2298.83 toks/s, output: 236.29 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:07<00:01,  8.23it/s, est. speed input: 2411.25 toks/s, output: 274.39 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:07<00:00, 10.38it/s, est. speed input: 2735.59 toks/s, output: 337.66 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:08<00:01,  4.92it/s, est. speed input: 2577.24 toks/s, output: 355.01 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:09<00:01,  4.11it/s, est. speed input: 2557.53 toks/s, output: 391.05 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:09<00:00,  4.51it/s, est. speed input: 2598.00 toks/s, output: 419.73 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:14<00:03,  1.18s/it, est. speed input: 1730.38 toks/s, output: 314.54 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:15<00:02,  1.11s/it, est. speed input: 1681.41 toks/s, output: 347.61 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:58<00:10, 10.88s/it, est. speed input: 462.01 toks/s, output: 160.90 toks/s] Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.83s/it, est. speed input: 482.06 toks/s, output: 230.81 toks/s]
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:15,  6.29s/it, est. speed input: 133.17 toks/s, output: 5.56 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:38,  1.38s/it, est. speed input: 533.99 toks/s, output: 26.30 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:16,  1.49it/s, est. speed input: 1081.81 toks/s, output: 60.01 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:13,  1.73it/s, est. speed input: 1209.18 toks/s, output: 71.65 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:07<00:07,  2.97it/s, est. speed input: 1602.97 toks/s, output: 111.89 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:04,  3.89it/s, est. speed input: 1808.32 toks/s, output: 139.80 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:07<00:03,  4.71it/s, est. speed input: 2078.27 toks/s, output: 168.56 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:08<00:03,  3.79it/s, est. speed input: 2102.94 toks/s, output: 194.08 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:02,  4.84it/s, est. speed input: 2307.20 toks/s, output: 233.49 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:09<00:01,  5.92it/s, est. speed input: 2489.09 toks/s, output: 273.66 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:09<00:01,  5.44it/s, est. speed input: 2618.60 toks/s, output: 307.74 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:09<00:01,  4.09it/s, est. speed input: 2551.57 toks/s, output: 318.72 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:10<00:01,  4.52it/s, est. speed input: 2627.70 toks/s, output: 363.15 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:10<00:00,  4.44it/s, est. speed input: 2706.90 toks/s, output: 405.74 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:11<00:00,  4.05it/s, est. speed input: 2739.44 toks/s, output: 425.44 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:18<00:01,  1.47s/it, est. speed input: 1741.48 toks/s, output: 323.92 toks/s]Processed prompts: 100%|██████████| 32/32 [00:19<00:00,  1.28s/it, est. speed input: 1766.13 toks/s, output: 366.43 toks/s]Processed prompts: 100%|██████████| 32/32 [00:19<00:00,  1.67it/s, est. speed input: 1766.13 toks/s, output: 366.43 toks/s]
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:00:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:58,  5.77s/it, est. speed input: 102.82 toks/s, output: 4.86 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:13,  2.45s/it, est. speed input: 192.43 toks/s, output: 10.70 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:26,  1.04it/s, est. speed input: 476.21 toks/s, output: 23.84 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:20,  1.30it/s, est. speed input: 664.89 toks/s, output: 32.60 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:11,  2.18it/s, est. speed input: 960.75 toks/s, output: 53.50 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:06<00:09,  2.51it/s, est. speed input: 1022.50 toks/s, output: 65.02 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:06<00:07,  3.02it/s, est. speed input: 1151.63 toks/s, output: 77.87 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:07<00:04,  4.21it/s, est. speed input: 1382.81 toks/s, output: 105.05 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:05,  3.96it/s, est. speed input: 1479.90 toks/s, output: 118.45 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:04,  4.30it/s, est. speed input: 1627.24 toks/s, output: 134.44 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:07<00:03,  4.70it/s, est. speed input: 1653.27 toks/s, output: 151.30 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:07<00:03,  4.96it/s, est. speed input: 1717.33 toks/s, output: 168.55 toks/s]Processed prompts:  50%|█████     | 16/32 [00:08<00:02,  5.57it/s, est. speed input: 1794.65 toks/s, output: 187.19 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:08<00:03,  4.85it/s, est. speed input: 1901.46 toks/s, output: 203.76 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:08<00:02,  5.51it/s, est. speed input: 2024.98 toks/s, output: 224.15 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:08<00:01,  8.15it/s, est. speed input: 2239.70 toks/s, output: 268.35 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:02,  4.23it/s, est. speed input: 2283.86 toks/s, output: 299.39 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:09<00:02,  3.78it/s, est. speed input: 2335.98 toks/s, output: 317.47 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:10<00:01,  4.45it/s, est. speed input: 2426.82 toks/s, output: 366.45 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:10<00:01,  4.64it/s, est. speed input: 2535.71 toks/s, output: 414.13 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:11<00:01,  3.06it/s, est. speed input: 2440.76 toks/s, output: 420.88 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:11<00:00,  2.99it/s, est. speed input: 2512.55 toks/s, output: 467.28 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:13<00:00,  1.77it/s, est. speed input: 2299.25 toks/s, output: 458.97 toks/s]Processed prompts: 100%|██████████| 32/32 [00:22<00:00,  2.46s/it, est. speed input: 1427.97 toks/s, output: 332.80 toks/s]Processed prompts: 100%|██████████| 32/32 [00:22<00:00,  1.44it/s, est. speed input: 1427.97 toks/s, output: 332.80 toks/s]
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:01:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:46,  5.36s/it, est. speed input: 172.54 toks/s, output: 3.92 toks/s]Processed prompts:   9%|▉         | 3/32 [00:05<00:41,  1.43s/it, est. speed input: 360.01 toks/s, output: 13.19 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:23,  1.14it/s, est. speed input: 541.90 toks/s, output: 33.44 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:06<00:18,  1.41it/s, est. speed input: 622.96 toks/s, output: 45.29 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:13,  1.82it/s, est. speed input: 818.33 toks/s, output: 58.39 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:06<00:07,  2.99it/s, est. speed input: 1049.94 toks/s, output: 85.95 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:06<00:03,  5.25it/s, est. speed input: 1384.86 toks/s, output: 130.83 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:07<00:03,  4.84it/s, est. speed input: 1613.97 toks/s, output: 156.59 toks/s]Processed prompts:  50%|█████     | 16/32 [00:07<00:02,  5.93it/s, est. speed input: 1917.04 toks/s, output: 191.93 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:07<00:02,  5.98it/s, est. speed input: 2099.24 toks/s, output: 224.94 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:02,  4.71it/s, est. speed input: 2045.72 toks/s, output: 237.73 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:08<00:02,  5.26it/s, est. speed input: 2065.49 toks/s, output: 259.57 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:03,  3.22it/s, est. speed input: 2034.93 toks/s, output: 282.90 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:09<00:03,  2.86it/s, est. speed input: 2007.97 toks/s, output: 300.08 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:09<00:02,  3.38it/s, est. speed input: 2122.67 toks/s, output: 328.57 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:10<00:01,  4.78it/s, est. speed input: 2386.41 toks/s, output: 413.18 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:11<00:01,  2.62it/s, est. speed input: 2274.72 toks/s, output: 410.08 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:13<00:02,  1.42it/s, est. speed input: 2056.05 toks/s, output: 394.92 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:14<00:01,  1.09it/s, est. speed input: 1909.79 toks/s, output: 398.31 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:16<00:01,  1.08s/it, est. speed input: 1766.64 toks/s, output: 410.07 toks/s]Processed prompts: 100%|██████████| 32/32 [00:58<00:00, 11.90s/it, est. speed input: 507.43 toks/s, output: 185.45 toks/s] Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.83s/it, est. speed input: 507.43 toks/s, output: 185.45 toks/s]
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:02:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:42,  5.25s/it, est. speed input: 123.58 toks/s, output: 13.33 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:08,  2.28s/it, est. speed input: 172.45 toks/s, output: 27.86 toks/s]Processed prompts:   9%|▉         | 3/32 [00:05<00:37,  1.30s/it, est. speed input: 266.43 toks/s, output: 43.27 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:26,  1.04it/s, est. speed input: 301.46 toks/s, output: 59.36 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:06<00:12,  2.09it/s, est. speed input: 630.52 toks/s, output: 97.86 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:10,  2.49it/s, est. speed input: 693.44 toks/s, output: 115.94 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:06<00:08,  2.90it/s, est. speed input: 787.12 toks/s, output: 134.78 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:06<00:04,  4.55it/s, est. speed input: 1026.07 toks/s, output: 177.97 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:06<00:05,  4.04it/s, est. speed input: 1116.22 toks/s, output: 194.47 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:05,  3.37it/s, est. speed input: 1153.64 toks/s, output: 210.25 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:04,  3.99it/s, est. speed input: 1263.43 toks/s, output: 234.69 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:07<00:02,  5.92it/s, est. speed input: 1405.89 toks/s, output: 287.40 toks/s]Processed prompts:  50%|█████     | 16/32 [00:08<00:03,  4.55it/s, est. speed input: 1509.34 toks/s, output: 303.95 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:08<00:03,  4.04it/s, est. speed input: 1570.06 toks/s, output: 321.56 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:08<00:03,  4.35it/s, est. speed input: 1647.70 toks/s, output: 345.12 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:02,  5.01it/s, est. speed input: 1736.93 toks/s, output: 371.16 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:08<00:02,  5.79it/s, est. speed input: 1753.58 toks/s, output: 398.00 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:09<00:02,  4.55it/s, est. speed input: 1749.13 toks/s, output: 415.97 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:09<00:01,  5.79it/s, est. speed input: 1855.18 toks/s, output: 471.24 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:09<00:01,  4.71it/s, est. speed input: 1863.61 toks/s, output: 512.92 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:11<00:02,  2.29it/s, est. speed input: 1746.72 toks/s, output: 495.53 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:12<00:03,  1.57it/s, est. speed input: 1646.31 toks/s, output: 487.78 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:15<00:03,  1.02s/it, est. speed input: 1430.38 toks/s, output: 473.18 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:24<00:05,  2.74s/it, est. speed input: 958.91 toks/s, output: 363.46 toks/s] Processed prompts:  97%|█████████▋| 31/32 [00:58<00:10, 10.46s/it, est. speed input: 404.99 toks/s, output: 219.58 toks/s]Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.84s/it, est. speed input: 423.63 toks/s, output: 289.20 toks/s]
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:03:06 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:24,  6.59s/it, est. speed input: 173.48 toks/s, output: 9.55 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:30,  3.03s/it, est. speed input: 311.01 toks/s, output: 22.01 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:50,  1.74s/it, est. speed input: 448.57 toks/s, output: 35.84 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:30,  1.10s/it, est. speed input: 601.69 toks/s, output: 50.41 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:11,  2.21it/s, est. speed input: 954.21 toks/s, output: 96.06 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:10,  2.22it/s, est. speed input: 1078.41 toks/s, output: 121.72 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:07,  2.90it/s, est. speed input: 1302.86 toks/s, output: 160.88 toks/s]Processed prompts:  41%|████      | 13/32 [00:09<00:04,  3.90it/s, est. speed input: 1450.76 toks/s, output: 203.22 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:03,  5.16it/s, est. speed input: 1603.10 toks/s, output: 246.87 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:09<00:02,  5.17it/s, est. speed input: 1808.66 toks/s, output: 286.88 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:09<00:01,  8.49it/s, est. speed input: 2255.71 toks/s, output: 384.60 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:10<00:01,  5.80it/s, est. speed input: 2276.72 toks/s, output: 414.63 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:11<00:02,  3.32it/s, est. speed input: 2140.68 toks/s, output: 433.03 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:12<00:02,  2.81it/s, est. speed input: 2071.58 toks/s, output: 445.62 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:12<00:01,  2.95it/s, est. speed input: 2137.41 toks/s, output: 472.36 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:14<00:02,  1.62it/s, est. speed input: 1968.73 toks/s, output: 457.25 toks/s]Processed prompts:  91%|█████████ | 29/32 [01:01<00:33, 11.30s/it, est. speed input: 479.58 toks/s, output: 173.07 toks/s] Processed prompts: 100%|██████████| 32/32 [01:01<00:00,  1.91s/it, est. speed input: 538.25 toks/s, output: 373.71 toks/s]
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:04:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:16,  6.32s/it, est. speed input: 85.38 toks/s, output: 4.74 toks/s]Processed prompts:   9%|▉         | 3/32 [00:06<00:53,  1.83s/it, est. speed input: 398.65 toks/s, output: 17.54 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:35,  1.27s/it, est. speed input: 528.54 toks/s, output: 27.32 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:17,  1.47it/s, est. speed input: 796.33 toks/s, output: 48.77 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:14,  1.75it/s, est. speed input: 924.67 toks/s, output: 60.10 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:07<00:06,  3.45it/s, est. speed input: 1310.65 toks/s, output: 100.09 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:04,  4.20it/s, est. speed input: 1589.28 toks/s, output: 126.47 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:08<00:04,  4.41it/s, est. speed input: 1820.64 toks/s, output: 153.85 toks/s]Processed prompts:  50%|█████     | 16/32 [00:08<00:03,  4.96it/s, est. speed input: 2034.78 toks/s, output: 185.89 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:08<00:01,  7.55it/s, est. speed input: 2468.20 toks/s, output: 259.38 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:01,  7.76it/s, est. speed input: 2631.13 toks/s, output: 295.64 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:09<00:00,  8.40it/s, est. speed input: 2918.07 toks/s, output: 370.02 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:09<00:00,  6.64it/s, est. speed input: 2987.99 toks/s, output: 402.69 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:10<00:00,  6.23it/s, est. speed input: 3057.04 toks/s, output: 421.62 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:21<00:01,  1.77s/it, est. speed input: 1547.59 toks/s, output: 265.20 toks/s]Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  7.89s/it, est. speed input: 582.90 toks/s, output: 165.98 toks/s] Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  1.86s/it, est. speed input: 582.90 toks/s, output: 165.98 toks/s]
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:05:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:24,  4.66s/it, est. speed input: 121.17 toks/s, output: 6.86 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:08,  2.28s/it, est. speed input: 206.27 toks/s, output: 18.94 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:05<00:14,  1.84it/s, est. speed input: 665.24 toks/s, output: 70.63 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:05<00:08,  2.68it/s, est. speed input: 961.92 toks/s, output: 97.43 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:05<00:04,  4.38it/s, est. speed input: 1371.67 toks/s, output: 141.88 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:05<00:02,  6.91it/s, est. speed input: 1953.02 toks/s, output: 202.89 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:06<00:01,  7.88it/s, est. speed input: 2334.16 toks/s, output: 249.08 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:06<00:01,  9.16it/s, est. speed input: 2537.53 toks/s, output: 284.74 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:06<00:01,  7.61it/s, est. speed input: 2682.16 toks/s, output: 312.42 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:07<00:01,  4.21it/s, est. speed input: 2509.11 toks/s, output: 318.70 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:07<00:01,  5.23it/s, est. speed input: 2718.91 toks/s, output: 373.02 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:08<00:01,  3.93it/s, est. speed input: 2646.18 toks/s, output: 400.54 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:21<00:06,  2.31s/it, est. speed input: 1136.83 toks/s, output: 222.52 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:58<00:18,  9.10s/it, est. speed input: 430.20 toks/s, output: 150.23 toks/s] Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.83s/it, est. speed input: 448.64 toks/s, output: 290.12 toks/s]
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:06:07 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:44,  5.31s/it, est. speed input: 202.29 toks/s, output: 3.01 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:15,  2.51s/it, est. speed input: 326.24 toks/s, output: 10.92 toks/s]Processed prompts:   9%|▉         | 3/32 [00:05<00:41,  1.42s/it, est. speed input: 517.00 toks/s, output: 19.90 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:18,  1.43it/s, est. speed input: 810.19 toks/s, output: 39.57 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:11,  2.17it/s, est. speed input: 989.05 toks/s, output: 62.72 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:06<00:09,  2.60it/s, est. speed input: 1174.50 toks/s, output: 76.29 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:06<00:07,  2.94it/s, est. speed input: 1259.47 toks/s, output: 90.35 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:07<00:06,  3.58it/s, est. speed input: 1329.93 toks/s, output: 106.01 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:07<00:05,  4.07it/s, est. speed input: 1378.75 toks/s, output: 121.78 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:04,  4.36it/s, est. speed input: 1434.29 toks/s, output: 137.97 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:04,  4.42it/s, est. speed input: 1448.64 toks/s, output: 154.56 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:07<00:03,  5.07it/s, est. speed input: 1544.16 toks/s, output: 173.29 toks/s]Processed prompts:  50%|█████     | 16/32 [00:07<00:02,  7.16it/s, est. speed input: 1741.37 toks/s, output: 213.31 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:08<00:02,  5.81it/s, est. speed input: 1802.48 toks/s, output: 229.68 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:08<00:02,  5.37it/s, est. speed input: 1865.79 toks/s, output: 248.12 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:02,  4.62it/s, est. speed input: 1958.62 toks/s, output: 265.69 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:09<00:03,  3.34it/s, est. speed input: 2010.45 toks/s, output: 296.77 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:03,  3.17it/s, est. speed input: 2021.85 toks/s, output: 316.81 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:10<00:03,  2.99it/s, est. speed input: 2039.89 toks/s, output: 337.29 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:10<00:02,  3.38it/s, est. speed input: 2133.66 toks/s, output: 364.39 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:11<00:02,  2.45it/s, est. speed input: 2066.40 toks/s, output: 376.99 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:11<00:02,  2.78it/s, est. speed input: 2111.65 toks/s, output: 405.44 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:12<00:02,  1.99it/s, est. speed input: 2007.85 toks/s, output: 415.80 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:16<00:06,  1.70s/it, est. speed input: 1502.18 toks/s, output: 349.97 toks/s]Processed prompts:  91%|█████████ | 29/32 [01:00<00:42, 14.08s/it, est. speed input: 433.55 toks/s, output: 164.73 toks/s] Processed prompts: 100%|██████████| 32/32 [01:00<00:00,  1.90s/it, est. speed input: 490.49 toks/s, output: 366.99 toks/s]
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:07:08 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:04<01:25,  4.50s/it, est. speed input: 122.13 toks/s, output: 15.57 toks/s]Processed prompts:  10%|█         | 2/20 [00:04<00:35,  1.96s/it, est. speed input: 277.20 toks/s, output: 32.46 toks/s]Processed prompts:  15%|█▌        | 3/20 [00:04<00:19,  1.16s/it, est. speed input: 526.23 toks/s, output: 50.62 toks/s]Processed prompts:  20%|██        | 4/20 [00:05<00:12,  1.28it/s, est. speed input: 756.61 toks/s, output: 70.01 toks/s]Processed prompts:  35%|███▌      | 7/20 [00:05<00:04,  2.85it/s, est. speed input: 1133.58 toks/s, output: 131.92 toks/s]Processed prompts:  45%|████▌     | 9/20 [00:06<00:03,  2.87it/s, est. speed input: 1320.79 toks/s, output: 166.79 toks/s]Processed prompts:  50%|█████     | 10/20 [00:06<00:03,  3.11it/s, est. speed input: 1492.90 toks/s, output: 191.18 toks/s]Processed prompts:  55%|█████▌    | 11/20 [00:06<00:03,  2.96it/s, est. speed input: 1468.70 toks/s, output: 212.42 toks/s]Processed prompts:  60%|██████    | 12/20 [00:06<00:02,  3.50it/s, est. speed input: 1642.27 toks/s, output: 241.57 toks/s]Processed prompts:  75%|███████▌  | 15/20 [00:07<00:01,  4.07it/s, est. speed input: 1923.08 toks/s, output: 319.89 toks/s]Processed prompts:  80%|████████  | 16/20 [00:07<00:00,  4.46it/s, est. speed input: 2069.61 toks/s, output: 351.23 toks/s]Processed prompts:  85%|████████▌ | 17/20 [00:24<00:12,  4.00s/it, est. speed input: 657.54 toks/s, output: 171.04 toks/s] Processed prompts:  90%|█████████ | 18/20 [00:57<00:21, 10.88s/it, est. speed input: 297.21 toks/s, output: 144.83 toks/s]Processed prompts: 100%|██████████| 20/20 [00:57<00:00,  2.89s/it, est. speed input: 332.33 toks/s, output: 286.62 toks/s]
[rank0]:[W117 17:08:07.698190646 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
input_file results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results.json
output_dir results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker
  0%|          | 0/25 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/3d_2.py", line 16, in <module>
    surf = ax.plot_surface(X, Y, Z, cmap='viridis')
AttributeError: 'Axes' object has no attribute 'plot_surface'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/bar_52.py", line 12, in <module>
    rects1 = ax.bar(x - width/2, synthetic_data, width, label='Synthetic data')
TypeError: unsupported operand type(s) for -: 'range' and 'float'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/errorbar_27.py", line 12, in <module>
    ax.bar(categories, agree_rates, color='lightcoral')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (7,) and arg 1 with shape (6,).
 60%|██████    | 15/25 [00:01<00:00, 13.54it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/hist_17.py", line 1, in <module>
    fig, ax = plt.subplots(figsize=(16.0, 7.0))
NameError: name 'plt' is not defined
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/errorbar_13.py", line 1, in <module>
    fig, ax = plt.subplots(figsize=(8.0, 8.0))
NameError: name 'plt' is not defined
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/bar_35.py", line 13, in <module>
    ax.bar(categories, random_scores, color='purple', label='Random')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (2,) and arg 1 with shape (5,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/bar_28.py", line 14, in <module>
    plt.xticks(range(3), ['VOC 2012', 'COCO 2017'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/pyplot.py", line 2068, in xticks
    labels_out = ax.set_xticklabels(labels, minor=minor, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (3), usually from a call to set_ticks, does not match the number of labels (2).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/density_1.py", line 10, in <module>
    plt.bar(x, y, color='red')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/pyplot.py", line 2754, in bar
    return gca().bar(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (8,) and arg 1 with shape (7,).
 88%|████████▊ | 22/25 [00:02<00:00,  8.18it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/errorbar_15.py", line 17, in <module>
    ax.bar(range(len(data[0])), data[3], bottom=[sum(x) for x in zip(data[0], data[1], data[2])], color='black', label='DiffStitch')
IndexError: list index out of range
 92%|█████████▏| 23/25 [00:03<00:00,  4.79it/s]100%|██████████| 25/25 [00:03<00:00,  6.68it/s]
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/errorbar_26.py", line 17, in <module>
    ax.bar(categories, support, color='blue')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (7,) and arg 1 with shape (2,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct_checker/HR_13.py", line 4, in <module>
    ax.pie([24, 45, 8], labels=["CigaR", "ChatRepair"], autopct='%1.1f%%')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 3240, in pie
    raise ValueError("'label' must be of length 'x'")
ValueError: 'label' must be of length 'x'
Total Python Files 70
Total PDF Files 59
input_file results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results.json
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:00<00:46,  1.06it/s]  4%|▍         | 2/50 [00:02<00:50,  1.06s/it]  6%|▌         | 3/50 [00:03<00:50,  1.07s/it]  8%|▊         | 4/50 [00:04<00:58,  1.28s/it] 10%|█         | 5/50 [00:05<00:54,  1.21s/it] 12%|█▏        | 6/50 [00:07<00:54,  1.23s/it] 14%|█▍        | 7/50 [00:08<00:51,  1.20s/it] 16%|█▌        | 8/50 [00:09<00:49,  1.19s/it] 18%|█▊        | 9/50 [00:10<00:49,  1.21s/it] 20%|██        | 10/50 [00:12<00:52,  1.31s/it] 22%|██▏       | 11/50 [00:13<00:50,  1.30s/it] 24%|██▍       | 12/50 [00:14<00:47,  1.25s/it] 26%|██▌       | 13/50 [00:15<00:47,  1.27s/it] 28%|██▊       | 14/50 [00:17<00:48,  1.35s/it] 30%|███       | 15/50 [00:18<00:48,  1.38s/it] 32%|███▏      | 16/50 [00:20<00:44,  1.30s/it] 34%|███▍      | 17/50 [00:21<00:43,  1.31s/it] 36%|███▌      | 18/50 [00:22<00:40,  1.28s/it] 38%|███▊      | 19/50 [00:23<00:40,  1.31s/it] 40%|████      | 20/50 [00:25<00:39,  1.31s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_13.py", line 14, in <module>
    plt.savefig("results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_13.pdf")
NameError: name 'plt' is not defined
 42%|████▏     | 21/50 [00:26<00:39,  1.36s/it] 44%|████▍     | 22/50 [00:27<00:35,  1.28s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_13.py", line 14, in <module>
    plt.savefig("results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_13.pdf")
NameError: name 'plt' is not defined
 46%|████▌     | 23/50 [00:29<00:34,  1.29s/it] 48%|████▊     | 24/50 [00:30<00:33,  1.29s/it] 50%|█████     | 25/50 [00:31<00:31,  1.25s/it] 52%|█████▏    | 26/50 [00:33<00:31,  1.31s/it] 54%|█████▍    | 27/50 [00:34<00:28,  1.23s/it] 56%|█████▌    | 28/50 [00:35<00:27,  1.24s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_17.py", line 9, in <module>
    plt.savefig("results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_17.pdf")
NameError: name 'plt' is not defined
 58%|█████▊    | 29/50 [00:36<00:27,  1.33s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_17.py", line 9, in <module>
    plt.savefig("results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_17.pdf")
NameError: name 'plt' is not defined
 60%|██████    | 30/50 [00:38<00:27,  1.36s/it] 62%|██████▏   | 31/50 [00:39<00:25,  1.33s/it] 64%|██████▍   | 32/50 [00:40<00:24,  1.33s/it] 66%|██████▌   | 33/50 [00:42<00:22,  1.32s/it] 68%|██████▊   | 34/50 [00:43<00:20,  1.29s/it] 70%|███████   | 35/50 [00:44<00:18,  1.26s/it] 72%|███████▏  | 36/50 [00:45<00:17,  1.28s/it] 74%|███████▍  | 37/50 [00:47<00:16,  1.30s/it] 76%|███████▌  | 38/50 [00:48<00:15,  1.31s/it] 78%|███████▊  | 39/50 [00:49<00:14,  1.28s/it] 80%|████████  | 40/50 [00:50<00:12,  1.25s/it] 82%|████████▏ | 41/50 [00:51<00:10,  1.17s/it] 84%|████████▍ | 42/50 [00:53<00:09,  1.21s/it] 86%|████████▌ | 43/50 [00:54<00:08,  1.24s/it] 88%|████████▊ | 44/50 [00:55<00:07,  1.25s/it] 90%|█████████ | 45/50 [00:57<00:06,  1.35s/it] 92%|█████████▏| 46/50 [00:58<00:05,  1.34s/it] 94%|█████████▍| 47/50 [00:59<00:03,  1.31s/it] 96%|█████████▌| 48/50 [01:01<00:02,  1.22s/it] 98%|█████████▊| 49/50 [01:02<00:01,  1.18s/it]100%|██████████| 50/50 [01:02<00:00,  1.09s/it]100%|██████████| 50/50 [01:02<00:00,  1.26s/it]
args.tasks ['code4evaluation']
args.model qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660
result file: ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results_code4evaluation.json
original_dataset_dir:  ./dataset/ori_500
generated_dataset_dir:  ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results
len dataset: 500
  0%|          | 0/25 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_17_log_texts.py", line 41, in <module>
    all_axes = plt.gcf().get_axes()
NameError: name 'plt' is not defined
cmap is used viridis
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_25.py
  4%|▍         | 1/25 [00:15<06:07, 15.29s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_17_log_layouts.py", line 17, in <module>
    plt.savefig("results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_17.pdf")
NameError: name 'plt' is not defined
cmap is used viridis
cmap is used viridis
cmap is used viridis
cmap is used viridis
  8%|▊         | 2/25 [00:32<06:21, 16.57s/it]cmap is used viridis
cmap is used viridis
cmap is used viridis
cmap is used viridis
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_26.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_7.py
 12%|█▏        | 3/25 [00:51<06:29, 17.70s/it] 16%|█▌        | 4/25 [01:07<05:53, 16.85s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_65.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_44.py
 20%|██        | 5/25 [01:23<05:30, 16.52s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_32.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/contour_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_56.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_41.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_83.py
cmap is used <matplotlib.colors.LinearSegmentedColormap object at 0x72afdc743b50>
 24%|██▍       | 6/25 [01:38<05:07, 16.17s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_6.py
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_texts.py:54: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_chart_types.py:375: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
 28%|██▊       | 7/25 [01:53<04:41, 15.62s/it]/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_colors.py:766: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_layouts.py:31: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/graph_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_47.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_67.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_38.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_60.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_69.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_39.py
 32%|███▏      | 8/25 [02:08<04:22, 15.42s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_98.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_68.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_15.py
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_13_log_texts.py", line 46, in <module>
    all_axes = plt.gcf().get_axes()
NameError: name 'plt' is not defined
 36%|███▌      | 9/25 [02:24<04:09, 15.57s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_13.py
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_13_log_layouts.py", line 22, in <module>
    plt.savefig("results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_13.pdf")
NameError: name 'plt' is not defined
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_36.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_32.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_40.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_49.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_72.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_66.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_48.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_6.py
 40%|████      | 10/25 [02:42<04:08, 16.56s/it]cmap is used viridis
cmap is used magma
cmap is used viridis
cmap is used viridis
cmap is used viridis
 44%|████▍     | 11/25 [03:00<03:56, 16.87s/it]cmap is used viridis
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_74.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_38.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_82.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_40.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/quiver_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_29.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/quiver_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_28.py
 48%|████▊     | 12/25 [03:16<03:36, 16.69s/it]cmap is used spring
cmap is used spring
cmap is used spring
 52%|█████▏    | 13/25 [03:32<03:18, 16.55s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_70.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_46.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_27.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_54.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_92.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_85.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_57.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_68.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_61.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_55.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_27.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_60.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_44.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_43.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_94.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_5.py
 56%|█████▌    | 14/25 [03:48<02:58, 16.21s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_100.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/quiver_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_70.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_30.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_53.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_86.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_63.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_88.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_9.py
 60%|██████    | 15/25 [04:05<02:45, 16.52s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_28.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_1.py
 64%|██████▍   | 16/25 [04:23<02:31, 16.87s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_19.py
 68%|██████▊   | 17/25 [04:39<02:12, 16.57s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_78.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_15.py
 72%|███████▏  | 18/25 [04:58<02:00, 17.26s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_67.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_97.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_73.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_42.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_75.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_45.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_1.py
 76%|███████▌  | 19/25 [05:13<01:40, 16.70s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_30.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_65.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_66.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_29.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_2.py
 80%|████████  | 20/25 [05:32<01:26, 17.26s/it] 84%|████████▍ | 21/25 [05:47<01:07, 16.85s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_39.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_59.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_62.py
 88%|████████▊ | 22/25 [06:03<00:49, 16.60s/it]cmap is used autumn
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_53.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_64.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_76.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_20.py
 92%|█████████▏| 23/25 [06:20<00:33, 16.68s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_45.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_28.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_58.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_33.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/contour_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_37.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_50.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_79.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_28.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_80.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_61.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/graph_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_73.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_62.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_72.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_17.py
cmap is used nipy_spectral
 96%|█████████▌| 24/25 [06:36<00:16, 16.44s/it]cmap is used jet
cmap is used jet
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_69.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_77.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_55.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_51.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_34.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_34.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_56.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_26.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_29.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_79.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_81.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_71.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/contour_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_63.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_36.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_28.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_52.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_49.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_87.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/graph_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_59.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_90.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_93.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_26.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_84.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_24.py
100%|██████████| 25/25 [06:54<00:00, 16.72s/it]100%|██████████| 25/25 [06:54<00:00, 16.56s/it]
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_57.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/graph_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_74.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_29.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_42.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_54.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/graph_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/contour_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_51.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/quiver_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_27.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_30.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_31.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_27.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_31.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_35.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_33.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_78.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_30.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_52.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_46.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_47.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_71.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_95.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_27.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_43.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_75.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_26.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_41.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_48.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_76.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_77.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_96.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_26.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_64.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_30.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_50.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_37.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_99.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_58.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_29.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/contour_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/quiver_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_35.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_80.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_89.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_91.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_5.py
self.results_file ./results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results_code4evaluation.json
Time taken:  439.2123177051544
args.tasks ['gpt4evaluation']
args.model qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_60.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_39.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_86.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_36.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_56.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_33.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_69.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_52.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_92.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_95.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_38.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_52.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_31.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_43.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_78.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_26.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_100.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_70.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_83.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_38.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_63.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/graph_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_42.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_54.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_66.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_88.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_78.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_28.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_45.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_58.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/graph_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_97.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_59.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_72.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_72.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_61.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_79.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_32.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/quiver_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_46.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_90.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_62.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_31.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_46.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_56.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_29.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_57.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/graph_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/quiver_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_79.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_30.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_61.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_70.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_55.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_84.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_27.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_27.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/contour_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_29.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_57.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_50.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/contour_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_73.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_48.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_28.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/graph_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_30.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_34.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_35.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_75.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_41.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_35.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_44.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_43.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_68.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_37.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_42.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_33.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_71.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_89.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_34.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_94.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_30.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_32.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_93.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_67.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_87.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_30.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_74.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_48.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_51.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_80.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_54.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_62.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_49.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/quiver_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_64.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_26.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_73.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_26.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_50.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_91.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_68.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_41.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_69.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_63.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_59.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_75.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_85.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_27.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_60.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_26.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_65.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_29.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_96.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_30.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/quiver_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/contour_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_58.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_76.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/contour_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/quiver_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_99.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_77.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_66.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_27.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_82.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_74.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_71.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_27.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_28.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_28.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_47.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_65.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_77.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_53.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_53.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_29.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_81.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_51.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_49.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_47.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_44.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_29.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_36.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_37.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/contour_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/graph_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_45.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_28.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_76.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_80.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_39.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_40.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/PIP_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorpoint_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_40.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_98.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_26.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/scatter_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_64.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_55.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_67.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_1.pdf
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:03<25:18,  3.04s/it]  0%|          | 2/500 [00:10<48:51,  5.89s/it]  1%|          | 3/500 [00:13<37:56,  4.58s/it]  1%|          | 4/500 [00:17<32:53,  3.98s/it]  1%|          | 5/500 [00:20<29:57,  3.63s/it]  1%|          | 6/500 [00:20<20:11,  2.45s/it]  1%|▏         | 7/500 [00:23<21:42,  2.64s/it]  2%|▏         | 8/500 [00:26<22:41,  2.77s/it]  2%|▏         | 9/500 [00:29<23:18,  2.85s/it]  2%|▏         | 10/500 [00:32<23:45,  2.91s/it]  2%|▏         | 11/500 [00:35<24:01,  2.95s/it]  2%|▏         | 12/500 [00:38<24:10,  2.97s/it]  3%|▎         | 13/500 [00:41<24:12,  2.98s/it]  3%|▎         | 14/500 [00:44<24:17,  3.00s/it]  3%|▎         | 15/500 [00:47<24:24,  3.02s/it]  3%|▎         | 16/500 [00:50<24:21,  3.02s/it]  3%|▎         | 17/500 [00:53<24:22,  3.03s/it]  4%|▎         | 18/500 [00:56<24:17,  3.02s/it]  4%|▍         | 19/500 [00:59<24:11,  3.02s/it]  4%|▍         | 20/500 [01:02<24:12,  3.03s/it]  4%|▍         | 21/500 [01:02<17:36,  2.21s/it]  4%|▍         | 22/500 [01:05<19:37,  2.46s/it]  5%|▍         | 23/500 [01:08<20:53,  2.63s/it]  5%|▍         | 24/500 [01:12<21:46,  2.74s/it]  5%|▌         | 25/500 [01:15<22:26,  2.83s/it]  5%|▌         | 26/500 [01:18<22:49,  2.89s/it]  5%|▌         | 27/500 [01:21<23:05,  2.93s/it]  6%|▌         | 28/500 [01:24<23:17,  2.96s/it]  6%|▌         | 29/500 [01:27<23:23,  2.98s/it]  6%|▌         | 30/500 [01:30<23:26,  2.99s/it]  6%|▌         | 31/500 [01:33<23:31,  3.01s/it]  7%|▋         | 33/500 [01:36<18:13,  2.34s/it]  7%|▋         | 34/500 [01:39<19:29,  2.51s/it]  7%|▋         | 35/500 [01:42<20:31,  2.65s/it]  7%|▋         | 36/500 [01:45<21:08,  2.73s/it]  7%|▋         | 37/500 [01:48<21:37,  2.80s/it]  8%|▊         | 38/500 [01:51<22:02,  2.86s/it]  8%|▊         | 39/500 [01:54<22:16,  2.90s/it]  8%|▊         | 40/500 [01:57<22:29,  2.93s/it]  8%|▊         | 41/500 [01:57<16:11,  2.12s/it]  8%|▊         | 42/500 [02:00<18:04,  2.37s/it]  9%|▊         | 43/500 [02:03<19:30,  2.56s/it]  9%|▉         | 44/500 [02:06<20:31,  2.70s/it]  9%|▉         | 45/500 [02:06<15:09,  2.00s/it]  9%|▉         | 46/500 [02:09<17:25,  2.30s/it]  9%|▉         | 47/500 [02:12<19:04,  2.53s/it] 10%|▉         | 48/500 [02:16<20:11,  2.68s/it] 10%|▉         | 49/500 [02:19<20:58,  2.79s/it] 10%|█         | 50/500 [02:19<15:36,  2.08s/it] 10%|█         | 51/500 [02:22<17:41,  2.36s/it] 10%|█         | 52/500 [02:25<19:09,  2.57s/it] 11%|█         | 53/500 [02:28<20:09,  2.71s/it] 11%|█         | 54/500 [02:31<20:50,  2.80s/it] 11%|█         | 55/500 [02:34<21:10,  2.86s/it] 11%|█         | 56/500 [02:37<21:27,  2.90s/it] 11%|█▏        | 57/500 [02:40<21:36,  2.93s/it] 12%|█▏        | 58/500 [02:43<21:42,  2.95s/it] 12%|█▏        | 59/500 [02:46<21:47,  2.97s/it] 12%|█▏        | 60/500 [02:49<21:50,  2.98s/it] 12%|█▏        | 61/500 [02:52<21:51,  2.99s/it] 12%|█▏        | 62/500 [02:54<20:17,  2.78s/it] 13%|█▎        | 63/500 [02:55<14:54,  2.05s/it] 13%|█▎        | 64/500 [02:58<16:57,  2.33s/it] 13%|█▎        | 65/500 [02:58<12:35,  1.74s/it] 13%|█▎        | 66/500 [03:01<15:17,  2.11s/it] 13%|█▎        | 67/500 [03:04<17:19,  2.40s/it] 14%|█▎        | 68/500 [03:07<18:36,  2.58s/it] 14%|█▍        | 69/500 [03:10<19:25,  2.70s/it] 14%|█▍        | 70/500 [03:13<20:02,  2.80s/it] 14%|█▍        | 71/500 [03:16<20:30,  2.87s/it] 14%|█▍        | 72/500 [03:19<20:45,  2.91s/it] 15%|█▍        | 73/500 [03:22<20:58,  2.95s/it] 15%|█▍        | 74/500 [03:22<15:13,  2.14s/it] 15%|█▌        | 75/500 [03:23<11:57,  1.69s/it] 15%|█▌        | 76/500 [03:26<14:45,  2.09s/it] 15%|█▌        | 77/500 [03:29<16:42,  2.37s/it] 16%|█▌        | 78/500 [03:32<18:02,  2.56s/it] 16%|█▌        | 79/500 [03:35<19:00,  2.71s/it] 16%|█▌        | 80/500 [03:38<19:37,  2.80s/it] 16%|█▌        | 81/500 [03:41<20:02,  2.87s/it] 16%|█▋        | 82/500 [03:44<20:16,  2.91s/it] 17%|█▋        | 83/500 [03:47<20:25,  2.94s/it] 17%|█▋        | 84/500 [03:50<20:30,  2.96s/it] 17%|█▋        | 85/500 [03:51<16:24,  2.37s/it] 17%|█▋        | 86/500 [03:54<17:40,  2.56s/it] 17%|█▋        | 87/500 [03:57<18:30,  2.69s/it] 18%|█▊        | 88/500 [04:00<19:03,  2.77s/it] 18%|█▊        | 89/500 [04:03<19:32,  2.85s/it] 18%|█▊        | 90/500 [04:06<19:49,  2.90s/it] 18%|█▊        | 91/500 [04:08<16:34,  2.43s/it] 18%|█▊        | 92/500 [04:11<17:41,  2.60s/it] 19%|█▊        | 93/500 [04:14<18:30,  2.73s/it] 19%|█▉        | 94/500 [04:17<19:04,  2.82s/it] 19%|█▉        | 95/500 [04:20<19:26,  2.88s/it] 19%|█▉        | 96/500 [04:23<19:40,  2.92s/it] 19%|█▉        | 97/500 [04:26<19:51,  2.96s/it] 20%|█▉        | 98/500 [04:29<19:54,  2.97s/it] 20%|█▉        | 99/500 [04:29<14:36,  2.19s/it] 20%|██        | 100/500 [04:32<16:17,  2.44s/it] 20%|██        | 101/500 [04:35<17:24,  2.62s/it] 20%|██        | 102/500 [04:38<18:08,  2.73s/it] 21%|██        | 103/500 [04:41<18:40,  2.82s/it] 21%|██        | 104/500 [04:44<18:58,  2.87s/it] 21%|██        | 105/500 [04:47<19:12,  2.92s/it] 21%|██        | 106/500 [04:50<19:19,  2.94s/it] 21%|██▏       | 107/500 [04:53<19:24,  2.96s/it] 22%|██▏       | 108/500 [04:56<19:30,  2.99s/it] 22%|██▏       | 109/500 [04:59<19:28,  2.99s/it] 22%|██▏       | 110/500 [05:02<19:33,  3.01s/it] 22%|██▏       | 111/500 [05:05<19:31,  3.01s/it] 22%|██▏       | 112/500 [05:08<19:29,  3.01s/it] 23%|██▎       | 113/500 [05:11<19:25,  3.01s/it] 23%|██▎       | 114/500 [05:14<19:21,  3.01s/it] 23%|██▎       | 115/500 [05:17<19:23,  3.02s/it] 23%|██▎       | 116/500 [05:21<19:24,  3.03s/it] 23%|██▎       | 117/500 [05:24<19:24,  3.04s/it] 24%|██▎       | 118/500 [05:27<19:19,  3.04s/it] 24%|██▍       | 119/500 [05:30<19:20,  3.05s/it] 24%|██▍       | 120/500 [05:33<19:16,  3.04s/it] 24%|██▍       | 121/500 [05:36<19:13,  3.04s/it] 24%|██▍       | 122/500 [05:39<19:09,  3.04s/it] 25%|██▍       | 123/500 [05:39<13:38,  2.17s/it] 25%|██▍       | 124/500 [05:42<15:11,  2.43s/it] 25%|██▌       | 125/500 [05:45<16:15,  2.60s/it] 25%|██▌       | 126/500 [05:48<16:59,  2.73s/it] 25%|██▌       | 127/500 [05:51<17:27,  2.81s/it] 26%|██▌       | 128/500 [05:54<17:48,  2.87s/it] 26%|██▌       | 129/500 [05:57<18:00,  2.91s/it] 26%|██▌       | 130/500 [06:00<18:07,  2.94s/it] 26%|██▌       | 131/500 [06:03<18:16,  2.97s/it] 26%|██▋       | 132/500 [06:06<18:17,  2.98s/it] 27%|██▋       | 133/500 [06:09<18:19,  3.00s/it] 27%|██▋       | 134/500 [06:12<18:19,  3.00s/it] 27%|██▋       | 135/500 [06:15<18:17,  3.01s/it] 27%|██▋       | 136/500 [06:18<18:17,  3.02s/it] 27%|██▋       | 137/500 [06:21<18:16,  3.02s/it] 28%|██▊       | 138/500 [06:24<18:15,  3.02s/it] 28%|██▊       | 139/500 [06:27<18:13,  3.03s/it] 28%|██▊       | 140/500 [06:30<18:09,  3.03s/it] 28%|██▊       | 141/500 [06:30<13:03,  2.18s/it] 28%|██▊       | 142/500 [06:34<14:33,  2.44s/it] 29%|██▊       | 143/500 [06:34<10:43,  1.80s/it] 29%|██▉       | 144/500 [06:37<12:53,  2.17s/it] 29%|██▉       | 145/500 [06:40<14:20,  2.42s/it] 29%|██▉       | 146/500 [06:40<10:20,  1.75s/it] 29%|██▉       | 147/500 [06:43<12:33,  2.13s/it] 30%|██▉       | 148/500 [06:46<14:09,  2.41s/it] 30%|██▉       | 149/500 [06:49<15:13,  2.60s/it] 30%|███       | 150/500 [06:49<10:57,  1.88s/it] 30%|███       | 151/500 [06:52<12:55,  2.22s/it] 30%|███       | 152/500 [06:55<14:17,  2.46s/it] 31%|███       | 153/500 [06:58<15:13,  2.63s/it] 31%|███       | 154/500 [07:02<15:52,  2.75s/it] 31%|███       | 155/500 [07:05<16:18,  2.84s/it] 31%|███       | 156/500 [07:05<11:46,  2.05s/it] 31%|███▏      | 157/500 [07:08<13:25,  2.35s/it] 32%|███▏      | 158/500 [07:11<14:34,  2.56s/it] 32%|███▏      | 159/500 [07:12<11:54,  2.10s/it] 32%|███▏      | 160/500 [07:15<13:29,  2.38s/it] 32%|███▏      | 161/500 [07:18<14:36,  2.58s/it] 32%|███▏      | 162/500 [07:21<15:24,  2.74s/it] 33%|███▎      | 163/500 [07:24<15:49,  2.82s/it] 33%|███▎      | 164/500 [07:27<16:07,  2.88s/it] 33%|███▎      | 165/500 [07:30<16:18,  2.92s/it] 33%|███▎      | 166/500 [07:33<16:25,  2.95s/it] 33%|███▎      | 167/500 [07:36<16:27,  2.96s/it] 34%|███▎      | 168/500 [07:39<16:29,  2.98s/it] 34%|███▍      | 169/500 [07:42<16:24,  2.97s/it] 34%|███▍      | 170/500 [07:45<16:23,  2.98s/it] 34%|███▍      | 171/500 [07:46<12:20,  2.25s/it] 34%|███▍      | 172/500 [07:49<13:32,  2.48s/it] 35%|███▍      | 173/500 [07:49<09:56,  1.83s/it] 35%|███▍      | 174/500 [07:52<11:48,  2.17s/it] 35%|███▌      | 175/500 [07:55<13:06,  2.42s/it] 35%|███▌      | 176/500 [07:58<14:01,  2.60s/it] 35%|███▌      | 177/500 [08:01<14:35,  2.71s/it] 36%|███▌      | 178/500 [08:04<15:03,  2.81s/it] 36%|███▌      | 179/500 [08:06<13:46,  2.58s/it] 36%|███▌      | 180/500 [08:09<14:28,  2.71s/it] 36%|███▌      | 181/500 [08:12<14:54,  2.80s/it] 36%|███▋      | 182/500 [08:15<15:12,  2.87s/it] 37%|███▋      | 183/500 [08:18<15:23,  2.91s/it] 37%|███▋      | 184/500 [08:21<15:33,  2.95s/it] 37%|███▋      | 185/500 [08:24<15:38,  2.98s/it] 37%|███▋      | 186/500 [08:27<15:39,  2.99s/it] 37%|███▋      | 187/500 [08:30<15:37,  3.00s/it] 38%|███▊      | 188/500 [08:33<15:36,  3.00s/it] 38%|███▊      | 189/500 [08:36<15:35,  3.01s/it] 38%|███▊      | 191/500 [08:39<11:59,  2.33s/it] 38%|███▊      | 192/500 [08:42<12:50,  2.50s/it] 39%|███▊      | 193/500 [08:45<13:28,  2.63s/it] 39%|███▉      | 194/500 [08:48<13:56,  2.74s/it] 39%|███▉      | 195/500 [08:51<14:18,  2.81s/it] 39%|███▉      | 196/500 [08:54<14:33,  2.87s/it] 39%|███▉      | 197/500 [08:57<14:44,  2.92s/it] 40%|███▉      | 198/500 [08:58<10:38,  2.12s/it] 40%|███▉      | 199/500 [09:01<11:55,  2.38s/it] 40%|████      | 200/500 [09:04<12:56,  2.59s/it] 40%|████      | 201/500 [09:07<13:27,  2.70s/it] 40%|████      | 202/500 [09:10<13:50,  2.79s/it] 41%|████      | 203/500 [09:13<14:06,  2.85s/it] 41%|████      | 204/500 [09:16<14:17,  2.90s/it] 41%|████      | 205/500 [09:19<14:21,  2.92s/it] 41%|████      | 206/500 [09:19<10:26,  2.13s/it] 41%|████▏     | 207/500 [09:22<11:41,  2.39s/it] 42%|████▏     | 208/500 [09:25<12:36,  2.59s/it] 42%|████▏     | 209/500 [09:28<13:12,  2.72s/it] 42%|████▏     | 210/500 [09:31<13:33,  2.81s/it] 42%|████▏     | 211/500 [09:34<13:44,  2.85s/it] 42%|████▏     | 212/500 [09:37<13:54,  2.90s/it] 43%|████▎     | 213/500 [09:40<13:58,  2.92s/it] 43%|████▎     | 214/500 [09:43<14:02,  2.95s/it] 43%|████▎     | 215/500 [09:46<14:08,  2.98s/it] 43%|████▎     | 216/500 [09:49<14:07,  2.98s/it] 43%|████▎     | 217/500 [09:52<14:07,  2.99s/it] 44%|████▎     | 218/500 [09:55<14:06,  3.00s/it] 44%|████▍     | 219/500 [09:58<14:03,  3.00s/it] 44%|████▍     | 220/500 [10:01<14:01,  3.01s/it] 44%|████▍     | 221/500 [10:04<14:00,  3.01s/it] 44%|████▍     | 222/500 [10:07<13:58,  3.02s/it] 45%|████▍     | 223/500 [10:10<13:53,  3.01s/it] 45%|████▍     | 224/500 [10:13<13:53,  3.02s/it] 45%|████▌     | 225/500 [10:14<10:27,  2.28s/it] 45%|████▌     | 226/500 [10:17<11:24,  2.50s/it] 45%|████▌     | 227/500 [10:20<12:04,  2.65s/it] 46%|████▌     | 228/500 [10:20<08:55,  1.97s/it] 46%|████▌     | 229/500 [10:23<10:18,  2.28s/it] 46%|████▌     | 230/500 [10:26<11:15,  2.50s/it] 46%|████▌     | 231/500 [10:29<11:54,  2.66s/it] 46%|████▋     | 232/500 [10:29<08:39,  1.94s/it] 47%|████▋     | 233/500 [10:32<10:06,  2.27s/it] 47%|████▋     | 234/500 [10:33<08:15,  1.86s/it] 47%|████▋     | 235/500 [10:36<09:45,  2.21s/it] 47%|████▋     | 236/500 [10:39<10:48,  2.46s/it] 47%|████▋     | 237/500 [10:42<11:29,  2.62s/it] 48%|████▊     | 238/500 [10:45<11:56,  2.74s/it] 48%|████▊     | 239/500 [10:48<12:16,  2.82s/it] 48%|████▊     | 240/500 [10:51<12:31,  2.89s/it] 48%|████▊     | 241/500 [10:54<12:36,  2.92s/it] 48%|████▊     | 242/500 [10:57<11:47,  2.74s/it] 49%|████▊     | 243/500 [11:00<12:02,  2.81s/it] 49%|████▉     | 244/500 [11:03<12:25,  2.91s/it] 49%|████▉     | 245/500 [11:03<09:05,  2.14s/it] 49%|████▉     | 246/500 [11:06<10:13,  2.41s/it] 49%|████▉     | 247/500 [11:09<10:55,  2.59s/it] 50%|████▉     | 248/500 [11:12<11:25,  2.72s/it] 50%|████▉     | 249/500 [11:15<11:44,  2.81s/it] 50%|█████     | 250/500 [11:18<11:56,  2.87s/it] 50%|█████     | 251/500 [11:19<09:17,  2.24s/it] 50%|█████     | 252/500 [11:22<10:17,  2.49s/it] 51%|█████     | 253/500 [11:25<10:54,  2.65s/it] 51%|█████     | 254/500 [11:28<11:20,  2.77s/it] 51%|█████     | 255/500 [11:31<11:36,  2.84s/it] 51%|█████     | 256/500 [11:34<11:48,  2.90s/it] 51%|█████▏    | 257/500 [11:37<11:52,  2.93s/it] 52%|█████▏    | 258/500 [11:38<09:14,  2.29s/it] 52%|█████▏    | 259/500 [11:38<06:49,  1.70s/it] 52%|█████▏    | 260/500 [11:39<05:43,  1.43s/it] 52%|█████▏    | 261/500 [11:42<07:37,  1.91s/it] 52%|█████▏    | 262/500 [11:45<08:53,  2.24s/it] 53%|█████▎    | 263/500 [11:45<06:25,  1.63s/it] 53%|█████▎    | 264/500 [11:48<08:00,  2.04s/it] 53%|█████▎    | 265/500 [11:51<09:05,  2.32s/it] 53%|█████▎    | 266/500 [11:52<06:52,  1.76s/it] 53%|█████▎    | 267/500 [11:55<08:19,  2.14s/it] 54%|█████▎    | 268/500 [11:58<09:17,  2.40s/it] 54%|█████▍    | 269/500 [11:58<06:43,  1.75s/it] 54%|█████▍    | 270/500 [12:01<08:09,  2.13s/it] 54%|█████▍    | 271/500 [12:04<09:08,  2.40s/it] 54%|█████▍    | 272/500 [12:07<09:48,  2.58s/it] 55%|█████▍    | 273/500 [12:10<10:14,  2.71s/it] 55%|█████▍    | 274/500 [12:13<10:33,  2.80s/it] 55%|█████▌    | 275/500 [12:16<10:45,  2.87s/it] 55%|█████▌    | 276/500 [12:19<10:53,  2.92s/it] 55%|█████▌    | 277/500 [12:22<10:59,  2.96s/it] 56%|█████▌    | 278/500 [12:25<11:03,  2.99s/it] 56%|█████▌    | 279/500 [12:28<11:02,  3.00s/it] 56%|█████▌    | 280/500 [12:31<11:00,  3.00s/it] 56%|█████▌    | 281/500 [12:34<10:59,  3.01s/it] 56%|█████▋    | 282/500 [12:37<10:57,  3.01s/it] 57%|█████▋    | 283/500 [12:41<10:57,  3.03s/it] 57%|█████▋    | 284/500 [12:44<10:57,  3.04s/it] 57%|█████▋    | 285/500 [12:47<10:51,  3.03s/it] 57%|█████▋    | 286/500 [12:47<08:13,  2.30s/it] 57%|█████▋    | 287/500 [12:50<08:55,  2.52s/it] 58%|█████▊    | 288/500 [12:53<09:25,  2.67s/it] 58%|█████▊    | 289/500 [12:56<09:43,  2.77s/it] 58%|█████▊    | 290/500 [12:59<09:56,  2.84s/it] 58%|█████▊    | 291/500 [13:02<10:03,  2.89s/it] 58%|█████▊    | 292/500 [13:05<10:12,  2.95s/it] 59%|█████▊    | 293/500 [13:09<10:26,  3.02s/it] 59%|█████▉    | 294/500 [13:12<10:21,  3.02s/it] 59%|█████▉    | 295/500 [13:15<10:18,  3.02s/it] 59%|█████▉    | 296/500 [13:18<10:14,  3.01s/it] 59%|█████▉    | 297/500 [13:18<07:32,  2.23s/it] 60%|█████▉    | 298/500 [13:21<08:17,  2.46s/it] 60%|█████▉    | 299/500 [13:24<08:48,  2.63s/it] 60%|██████    | 300/500 [13:27<09:09,  2.75s/it] 60%|██████    | 301/500 [13:30<09:22,  2.82s/it] 60%|██████    | 302/500 [13:33<09:31,  2.88s/it] 61%|██████    | 303/500 [13:36<09:36,  2.92s/it] 61%|██████    | 304/500 [13:39<09:38,  2.95s/it] 61%|██████    | 305/500 [13:42<09:39,  2.97s/it] 61%|██████    | 306/500 [13:45<09:39,  2.99s/it] 61%|██████▏   | 307/500 [13:48<09:36,  2.99s/it] 62%|██████▏   | 308/500 [13:51<09:34,  2.99s/it] 62%|██████▏   | 309/500 [13:52<07:05,  2.23s/it] 62%|██████▏   | 310/500 [13:52<05:29,  1.74s/it] 62%|██████▏   | 311/500 [13:55<06:40,  2.12s/it] 62%|██████▏   | 312/500 [13:58<07:27,  2.38s/it] 63%|██████▎   | 313/500 [14:01<07:58,  2.56s/it] 63%|██████▎   | 314/500 [14:04<08:22,  2.70s/it] 63%|██████▎   | 315/500 [14:07<08:35,  2.79s/it] 63%|██████▎   | 316/500 [14:10<08:46,  2.86s/it] 63%|██████▎   | 317/500 [14:13<08:52,  2.91s/it] 64%|██████▎   | 318/500 [14:16<08:56,  2.95s/it] 64%|██████▍   | 319/500 [14:19<08:57,  2.97s/it] 64%|██████▍   | 320/500 [14:22<08:58,  2.99s/it] 64%|██████▍   | 321/500 [14:25<09:01,  3.03s/it] 64%|██████▍   | 322/500 [14:28<09:00,  3.04s/it] 65%|██████▍   | 323/500 [14:32<08:58,  3.04s/it] 65%|██████▍   | 324/500 [14:35<08:53,  3.03s/it] 65%|██████▌   | 325/500 [14:38<08:48,  3.02s/it] 65%|██████▌   | 326/500 [14:41<08:43,  3.01s/it] 65%|██████▌   | 327/500 [14:44<08:39,  3.00s/it] 66%|██████▌   | 329/500 [14:47<06:39,  2.34s/it] 66%|██████▌   | 330/500 [14:48<05:53,  2.08s/it] 66%|██████▌   | 331/500 [14:51<06:32,  2.32s/it] 66%|██████▋   | 332/500 [14:54<07:07,  2.54s/it] 67%|██████▋   | 333/500 [14:55<05:57,  2.14s/it] 67%|██████▋   | 334/500 [14:58<06:45,  2.44s/it] 67%|██████▋   | 335/500 [15:02<07:16,  2.65s/it] 67%|██████▋   | 336/500 [15:05<07:39,  2.80s/it] 67%|██████▋   | 337/500 [15:08<07:55,  2.92s/it] 68%|██████▊   | 338/500 [15:11<08:07,  3.01s/it] 68%|██████▊   | 339/500 [15:14<08:12,  3.06s/it] 68%|██████▊   | 340/500 [15:17<08:16,  3.10s/it] 68%|██████▊   | 341/500 [15:21<08:22,  3.16s/it] 68%|██████▊   | 342/500 [15:21<06:00,  2.28s/it] 69%|██████▊   | 343/500 [15:24<06:40,  2.55s/it] 69%|██████▉   | 344/500 [15:25<05:34,  2.15s/it] 69%|██████▉   | 345/500 [15:29<06:22,  2.47s/it] 69%|██████▉   | 346/500 [15:32<06:51,  2.67s/it] 69%|██████▉   | 347/500 [15:35<07:11,  2.82s/it] 70%|██████▉   | 348/500 [15:35<05:14,  2.07s/it] 70%|██████▉   | 349/500 [15:38<06:02,  2.40s/it] 70%|███████   | 350/500 [15:42<06:34,  2.63s/it] 70%|███████   | 351/500 [15:42<04:47,  1.93s/it] 70%|███████   | 352/500 [15:45<05:38,  2.28s/it] 71%|███████   | 353/500 [15:48<06:14,  2.55s/it] 71%|███████   | 354/500 [15:50<05:33,  2.29s/it] 71%|███████   | 355/500 [15:53<06:11,  2.56s/it] 71%|███████   | 356/500 [15:56<06:38,  2.77s/it] 71%|███████▏  | 357/500 [15:59<06:47,  2.85s/it] 72%|███████▏  | 358/500 [16:02<06:56,  2.93s/it] 72%|███████▏  | 359/500 [16:06<07:03,  3.01s/it] 72%|███████▏  | 360/500 [16:09<07:07,  3.05s/it] 72%|███████▏  | 361/500 [16:12<07:10,  3.10s/it] 72%|███████▏  | 362/500 [16:15<07:11,  3.13s/it] 73%|███████▎  | 363/500 [16:18<07:11,  3.15s/it] 73%|███████▎  | 364/500 [16:22<07:10,  3.16s/it] 73%|███████▎  | 365/500 [16:22<05:25,  2.41s/it] 73%|███████▎  | 366/500 [16:25<05:54,  2.65s/it] 73%|███████▎  | 367/500 [16:29<06:09,  2.77s/it] 74%|███████▎  | 368/500 [16:32<06:15,  2.85s/it] 74%|███████▍  | 369/500 [16:35<06:20,  2.90s/it] 74%|███████▍  | 370/500 [16:38<06:22,  2.94s/it] 74%|███████▍  | 371/500 [16:38<04:42,  2.19s/it] 74%|███████▍  | 372/500 [16:41<05:12,  2.44s/it] 75%|███████▍  | 373/500 [16:44<05:31,  2.61s/it] 75%|███████▍  | 374/500 [16:47<05:44,  2.74s/it] 75%|███████▌  | 375/500 [16:50<05:52,  2.82s/it] 75%|███████▌  | 376/500 [16:53<05:57,  2.88s/it] 75%|███████▌  | 377/500 [16:56<06:04,  2.97s/it] 76%|███████▌  | 378/500 [16:57<04:35,  2.26s/it] 76%|███████▌  | 379/500 [17:00<05:09,  2.56s/it] 76%|███████▌  | 380/500 [17:03<05:31,  2.77s/it] 76%|███████▌  | 381/500 [17:07<05:44,  2.90s/it] 76%|███████▋  | 382/500 [17:10<05:52,  2.98s/it] 77%|███████▋  | 383/500 [17:13<05:59,  3.07s/it] 77%|███████▋  | 384/500 [17:16<06:01,  3.12s/it] 77%|███████▋  | 385/500 [17:19<06:00,  3.13s/it] 77%|███████▋  | 386/500 [17:23<06:01,  3.17s/it] 77%|███████▋  | 387/500 [17:27<06:31,  3.46s/it] 78%|███████▊  | 388/500 [17:27<04:39,  2.49s/it] 78%|███████▊  | 389/500 [17:27<03:24,  1.84s/it] 78%|███████▊  | 390/500 [17:31<04:06,  2.24s/it] 78%|███████▊  | 391/500 [17:34<04:33,  2.51s/it] 78%|███████▊  | 392/500 [17:37<04:50,  2.69s/it] 79%|███████▊  | 393/500 [17:40<05:03,  2.84s/it] 79%|███████▉  | 394/500 [17:43<05:09,  2.92s/it] 79%|███████▉  | 395/500 [17:46<05:10,  2.96s/it] 79%|███████▉  | 396/500 [17:49<05:12,  3.01s/it] 79%|███████▉  | 397/500 [17:52<05:14,  3.05s/it] 80%|███████▉  | 398/500 [17:56<05:15,  3.09s/it] 80%|███████▉  | 399/500 [17:59<05:15,  3.13s/it] 80%|████████  | 400/500 [18:02<05:12,  3.13s/it] 80%|████████  | 401/500 [18:05<05:10,  3.13s/it] 80%|████████  | 402/500 [18:08<05:07,  3.14s/it] 81%|████████  | 403/500 [18:11<05:05,  3.15s/it] 81%|████████  | 404/500 [18:15<05:02,  3.16s/it] 81%|████████  | 405/500 [18:18<05:01,  3.17s/it] 81%|████████  | 406/500 [18:21<04:54,  3.13s/it] 81%|████████▏ | 407/500 [18:24<04:47,  3.09s/it] 82%|████████▏ | 408/500 [18:27<04:40,  3.05s/it] 82%|████████▏ | 409/500 [18:27<03:19,  2.19s/it] 82%|████████▏ | 410/500 [18:30<03:39,  2.44s/it] 82%|████████▏ | 411/500 [18:30<02:40,  1.80s/it] 82%|████████▏ | 412/500 [18:33<03:10,  2.16s/it] 83%|████████▎ | 413/500 [18:36<03:29,  2.41s/it] 83%|████████▎ | 414/500 [18:37<02:34,  1.79s/it] 83%|████████▎ | 415/500 [18:40<03:03,  2.16s/it] 83%|████████▎ | 416/500 [18:43<03:22,  2.41s/it] 83%|████████▎ | 417/500 [18:46<03:35,  2.59s/it] 84%|████████▎ | 418/500 [18:49<03:41,  2.71s/it] 84%|████████▍ | 419/500 [18:52<03:46,  2.79s/it] 84%|████████▍ | 420/500 [18:55<03:48,  2.85s/it] 84%|████████▍ | 421/500 [18:58<03:48,  2.89s/it] 84%|████████▍ | 422/500 [18:58<02:41,  2.07s/it] 85%|████████▍ | 423/500 [19:01<03:00,  2.35s/it] 85%|████████▍ | 424/500 [19:04<03:13,  2.55s/it] 85%|████████▌ | 425/500 [19:07<03:20,  2.68s/it] 85%|████████▌ | 426/500 [19:08<02:42,  2.20s/it] 85%|████████▌ | 427/500 [19:11<02:57,  2.43s/it] 86%|████████▌ | 428/500 [19:14<03:07,  2.60s/it] 86%|████████▌ | 429/500 [19:17<03:13,  2.72s/it] 86%|████████▌ | 430/500 [19:20<03:15,  2.80s/it] 86%|████████▌ | 431/500 [19:23<03:17,  2.86s/it] 86%|████████▋ | 432/500 [19:26<03:17,  2.90s/it] 87%|████████▋ | 433/500 [19:29<03:16,  2.94s/it] 87%|████████▋ | 434/500 [19:32<03:15,  2.96s/it] 87%|████████▋ | 435/500 [19:35<03:13,  2.97s/it] 87%|████████▋ | 436/500 [19:35<02:16,  2.14s/it] 87%|████████▋ | 437/500 [19:38<02:31,  2.40s/it] 88%|████████▊ | 438/500 [19:41<02:40,  2.59s/it] 88%|████████▊ | 440/500 [19:44<02:08,  2.14s/it] 88%|████████▊ | 441/500 [19:47<02:18,  2.36s/it] 88%|████████▊ | 442/500 [19:50<02:26,  2.53s/it] 89%|████████▊ | 443/500 [19:53<02:31,  2.66s/it] 89%|████████▉ | 444/500 [19:56<02:35,  2.77s/it] 89%|████████▉ | 445/500 [20:00<02:38,  2.88s/it] 89%|████████▉ | 446/500 [20:03<02:40,  2.97s/it] 89%|████████▉ | 447/500 [20:06<02:40,  3.02s/it] 90%|████████▉ | 448/500 [20:09<02:37,  3.03s/it] 90%|████████▉ | 449/500 [20:12<02:34,  3.03s/it] 90%|█████████ | 450/500 [20:15<02:30,  3.02s/it] 90%|█████████ | 451/500 [20:18<02:27,  3.01s/it] 90%|█████████ | 452/500 [20:21<02:24,  3.00s/it] 91%|█████████ | 453/500 [20:24<02:20,  3.00s/it] 91%|█████████ | 454/500 [20:27<02:17,  2.99s/it] 91%|█████████ | 455/500 [20:30<02:14,  2.99s/it] 91%|█████████ | 456/500 [20:33<02:11,  2.98s/it] 91%|█████████▏| 457/500 [20:36<02:08,  2.99s/it] 92%|█████████▏| 458/500 [20:39<02:05,  2.99s/it] 92%|█████████▏| 459/500 [20:42<02:02,  2.98s/it] 92%|█████████▏| 460/500 [20:45<01:59,  2.99s/it] 92%|█████████▏| 461/500 [20:48<01:56,  2.99s/it] 92%|█████████▏| 462/500 [20:49<01:27,  2.31s/it] 93%|█████████▎| 463/500 [20:52<01:33,  2.52s/it] 93%|█████████▎| 464/500 [20:55<01:36,  2.67s/it] 93%|█████████▎| 465/500 [20:58<01:36,  2.77s/it] 93%|█████████▎| 466/500 [21:01<01:36,  2.85s/it] 93%|█████████▎| 467/500 [21:04<01:36,  2.91s/it] 94%|█████████▎| 468/500 [21:07<01:33,  2.94s/it] 94%|█████████▍| 469/500 [21:10<01:31,  2.96s/it] 94%|█████████▍| 470/500 [21:13<01:29,  2.99s/it] 94%|█████████▍| 471/500 [21:16<01:26,  3.00s/it] 94%|█████████▍| 472/500 [21:19<01:24,  3.01s/it] 95%|█████████▍| 473/500 [21:22<01:21,  3.02s/it] 95%|█████████▍| 474/500 [21:25<01:18,  3.03s/it] 95%|█████████▌| 475/500 [21:25<00:54,  2.18s/it] 95%|█████████▌| 476/500 [21:28<00:58,  2.45s/it] 95%|█████████▌| 477/500 [21:31<01:00,  2.64s/it] 96%|█████████▌| 478/500 [21:34<01:00,  2.76s/it] 96%|█████████▌| 479/500 [21:37<00:59,  2.83s/it] 96%|█████████▌| 480/500 [21:40<00:57,  2.89s/it] 96%|█████████▌| 481/500 [21:43<00:55,  2.93s/it] 96%|█████████▋| 482/500 [21:46<00:52,  2.94s/it] 97%|█████████▋| 483/500 [21:49<00:50,  2.96s/it] 97%|█████████▋| 484/500 [21:52<00:47,  2.98s/it] 97%|█████████▋| 485/500 [21:55<00:44,  2.98s/it] 97%|█████████▋| 486/500 [21:56<00:31,  2.23s/it] 97%|█████████▋| 487/500 [21:59<00:31,  2.46s/it] 98%|█████████▊| 488/500 [22:02<00:31,  2.62s/it] 98%|█████████▊| 489/500 [22:05<00:30,  2.73s/it] 98%|█████████▊| 490/500 [22:08<00:28,  2.81s/it] 98%|█████████▊| 491/500 [22:11<00:25,  2.87s/it] 98%|█████████▊| 492/500 [22:11<00:17,  2.13s/it] 99%|█████████▊| 493/500 [22:14<00:16,  2.39s/it] 99%|█████████▉| 494/500 [22:17<00:15,  2.58s/it] 99%|█████████▉| 495/500 [22:20<00:13,  2.71s/it] 99%|█████████▉| 496/500 [22:23<00:11,  2.80s/it] 99%|█████████▉| 497/500 [22:26<00:08,  2.86s/it]100%|█████████▉| 498/500 [22:29<00:05,  2.91s/it]100%|█████████▉| 499/500 [22:32<00:02,  2.94s/it]100%|██████████| 500/500 [22:35<00:00,  2.95s/it]100%|██████████| 500/500 [22:35<00:00,  2.71s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:15<00:47, 15.71s/it]originial_png_file: dataset/ori_500/bar_24.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_24.png
originial_png_file: dataset/ori_500/CB_25.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_25.png
originial_png_file: dataset/ori_500/bar_12.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_12.png
originial_png_file: dataset/ori_500/pie_12.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_12.png
originial_png_file: dataset/ori_500/line_44.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_44.png
originial_png_file: dataset/ori_500/density_4.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_4.png
originial_png_file: dataset/ori_500/density_1.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_1.png
originial_png_file: dataset/ori_500/radar_16.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_16.png
originial_png_file: dataset/ori_500/hist_12.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_12.png
originial_png_file: dataset/ori_500/tree_1.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_1.png
originial_png_file: dataset/ori_500/radar_12.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_12.png
originial_png_file: dataset/ori_500/errorbar_27.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_27.png
originial_png_file: dataset/ori_500/radar_1.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_1.png
originial_png_file: dataset/ori_500/3d_4.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_4.png
originial_png_file: dataset/ori_500/multidiff_1.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_1.png
originial_png_file: dataset/ori_500/HR_16.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_16.png
originial_png_file: dataset/ori_500/CB_15.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_15.png
originial_png_file: dataset/ori_500/HR_8.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_8.png
originial_png_file: dataset/ori_500/bar_5.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_5.png
originial_png_file: dataset/ori_500/CB_24.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_24.png
originial_png_file: dataset/ori_500/HR_15.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_15.png
originial_png_file: dataset/ori_500/pie_1.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_1.png
originial_png_file: dataset/ori_500/tree_3.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_3.png
originial_png_file: dataset/ori_500/HR_5.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_5.png
originial_png_file: dataset/ori_500/tree_4.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_4.png
originial_png_file: dataset/ori_500/line_56.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_56.png
originial_png_file: dataset/ori_500/errorbar_13.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_13.png
originial_png_file: dataset/ori_500/HR_3.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_3.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 5 seconds.'}}
originial_png_file: dataset/ori_500/box_19.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_19.png
originial_png_file: dataset/ori_500/bar_41.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_41.png
originial_png_file: dataset/ori_500/line_6.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_6.png
originial_png_file: dataset/ori_500/violin_8.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_8.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 9 seconds.'}}
originial_png_file: dataset/ori_500/violin_6.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/violin_6.png
originial_png_file: dataset/ori_500/3d_15.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_15.png
originial_png_file: dataset/ori_500/radar_4.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_4.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 4 seconds.'}}
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 3 seconds.'}}
originial_png_file: dataset/ori_500/bar_83.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_83.png
originial_png_file: dataset/ori_500/bar_35.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_35.png
originial_png_file: dataset/ori_500/hist_17.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/hist_17.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 1 seconds.'}}
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 3 seconds.'}}
originial_png_file: dataset/ori_500/tree_2.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/tree_2.png
originial_png_file: dataset/ori_500/bar_28.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_28.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 6 seconds.'}}
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 6 seconds.'}}
originial_png_file: dataset/ori_500/area_2.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/area_2.png
originial_png_file: dataset/ori_500/line_7.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_7.png
originial_png_file: dataset/ori_500/line_9.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_9.png
originial_png_file: dataset/ori_500/bar_50.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_50.png
originial_png_file: dataset/ori_500/radar_17.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_17.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 5 seconds.'}}
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 4 seconds.'}}
originial_png_file: dataset/ori_500/multidiff_16.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/multidiff_16.png
originial_png_file: dataset/ori_500/line_38.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_38.png
originial_png_file: dataset/ori_500/bar_20.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_20.png
originial_png_file: dataset/ori_500/errorbar_26.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_26.png
originial_png_file: dataset/ori_500/line_65.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_65.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 9 seconds.'}}
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 6 seconds.'}}
 50%|█████     | 2/4 [01:20<01:29, 44.81s/it]originial_png_file: dataset/ori_500/HR_12.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_12.png
originial_png_file: dataset/ori_500/bar_19.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_19.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 9 seconds.'}}
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 8 seconds.'}}
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 6 seconds.'}}
originial_png_file: dataset/ori_500/line_19.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_19.png
originial_png_file: dataset/ori_500/3d_2.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/3d_2.png
 75%|███████▌  | 3/4 [01:39<00:32, 32.85s/it]100%|██████████| 4/4 [01:51<00:00, 24.69s/it]100%|██████████| 4/4 [01:51<00:00, 27.92s/it]
originial_png_file: dataset/ori_500/bar_39.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_39.png
originial_png_file: dataset/ori_500/radar_9.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/radar_9.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 5 seconds.'}}
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 4 seconds.'}}
originial_png_file: dataset/ori_500/bar_87.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_87.png
originial_png_file: dataset/ori_500/density_2.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/density_2.png
originial_png_file: dataset/ori_500/bar_52.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_52.png
originial_png_file: dataset/ori_500/line_70.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_70.png
originial_png_file: dataset/ori_500/line_54.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/line_54.png
originial_png_file: dataset/ori_500/pie_6.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/pie_6.png
Request timed out.
originial_png_file: dataset/ori_500/bar_62.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/bar_62.png
originial_png_file: dataset/ori_500/box_15.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/box_15.png
originial_png_file: dataset/ori_500/CB_22.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/CB_22.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 7 seconds.'}}
Request timed out.
originial_png_file: dataset/ori_500/heatmap_23.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/heatmap_23.png
Request timed out.
originial_png_file: dataset/ori_500/HR_13.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/HR_13.png
originial_png_file: dataset/ori_500/errorbar_15.png generated_png_file: results/direct/chart2code_qwen2_vl_mm_only-7b_3072_bsz128_1e3_pretrain_llava_stage2_1M_job_7660_DirectAgent_results/direct/errorbar_15.png
Time taken:  2139.7390999794006
正在处理模型: qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805
INFO 01-17 17:52:46 config.py:350] This model supports multiple tasks: {'generate', 'embedding'}. Defaulting to 'generate'.
INFO 01-17 17:52:46 llm_engine.py:249] Initializing an LLM engine (v0.6.4) with config: model='/mnt/lingjiejiang/multimodal_code/exp/saves/qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072/sft/full/checkpoint-805/', speculative_config=None, tokenizer='/mnt/lingjiejiang/multimodal_code/exp/saves/qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072/sft/full/checkpoint-805/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/mnt/lingjiejiang/multimodal_code/exp/saves/qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072/sft/full/checkpoint-805/, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-17 17:52:47 selector.py:135] Using Flash Attention backend.
INFO 01-17 17:52:48 model_runner.py:1072] Starting to load model /mnt/lingjiejiang/multimodal_code/exp/saves/qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072/sft/full/checkpoint-805/...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.68s/it]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:34<00:36, 18.47s/it]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [02:34<01:05, 65.19s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:38<00:00, 40.75s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:38<00:00, 39.52s/it]

INFO 01-17 17:55:26 model_runner.py:1077] Loading model weights took 15.5083 GB
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
INFO 01-17 17:55:35 worker.py:232] Memory profiling results: total_gpu_memory=79.25GiB initial_memory_usage=16.15GiB peak_torch_memory=20.53GiB memory_usage_post_profile=16.55Gib non_torch_memory=1.04GiB kv_cache_size=49.77GiB gpu_memory_utilization=0.90
INFO 01-17 17:55:35 gpu_executor.py:113] # GPU blocks: 58239, # CPU blocks: 4681
INFO 01-17 17:55:35 gpu_executor.py:117] Maximum concurrency for 32768 tokens per request: 28.44x
INFO 01-17 17:55:39 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-17 17:55:39 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-17 17:55:57 model_runner.py:1518] Graph capturing finished in 18 secs, took 0.37 GiB
Processing 500 files
INFO 01-17 17:55:59 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:00 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:56:01 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:25,  6.64s/it, est. speed input: 112.85 toks/s, output: 18.68 toks/s]Processed prompts:   6%|▋         | 2/32 [00:06<01:27,  2.90s/it, est. speed input: 255.91 toks/s, output: 38.25 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:50,  1.75s/it, est. speed input: 403.72 toks/s, output: 58.61 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:15,  1.63it/s, est. speed input: 776.02 toks/s, output: 125.49 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:10,  2.27it/s, est. speed input: 964.61 toks/s, output: 167.53 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:07,  2.82it/s, est. speed input: 1092.86 toks/s, output: 211.39 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:07,  2.93it/s, est. speed input: 1144.96 toks/s, output: 231.79 toks/s]Processed prompts:  41%|████      | 13/32 [00:09<00:06,  2.74it/s, est. speed input: 1207.79 toks/s, output: 267.55 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:06,  2.99it/s, est. speed input: 1283.08 toks/s, output: 292.94 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:06,  2.75it/s, est. speed input: 1307.38 toks/s, output: 312.24 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:10<00:03,  4.09it/s, est. speed input: 1441.22 toks/s, output: 374.87 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:10<00:04,  3.08it/s, est. speed input: 1461.95 toks/s, output: 410.03 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:11<00:03,  3.54it/s, est. speed input: 1513.88 toks/s, output: 442.35 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:11<00:03,  3.01it/s, est. speed input: 1532.48 toks/s, output: 461.28 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:11<00:03,  3.21it/s, est. speed input: 1563.58 toks/s, output: 490.28 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:12<00:03,  2.87it/s, est. speed input: 1574.26 toks/s, output: 512.03 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:13<00:05,  1.55it/s, est. speed input: 1501.14 toks/s, output: 501.25 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:14<00:05,  1.38it/s, est. speed input: 1452.88 toks/s, output: 513.94 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:15<00:03,  1.63it/s, est. speed input: 1457.06 toks/s, output: 547.86 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:15<00:02,  1.93it/s, est. speed input: 1479.54 toks/s, output: 583.74 toks/s]Processed prompts:  88%|████████▊ | 28/32 [01:03<00:57, 14.39s/it, est. speed input: 376.54 toks/s, output: 205.72 toks/s] Processed prompts: 100%|██████████| 32/32 [01:03<00:00,  1.98s/it, est. speed input: 438.12 toks/s, output: 464.60 toks/s]
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:57:04 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:25,  6.64s/it, est. speed input: 205.42 toks/s, output: 17.31 toks/s]Processed prompts:   6%|▋         | 2/32 [00:06<01:26,  2.90s/it, est. speed input: 301.96 toks/s, output: 35.56 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:49,  1.72s/it, est. speed input: 416.23 toks/s, output: 54.69 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:21,  1.24it/s, est. speed input: 582.99 toks/s, output: 95.40 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:16,  1.55it/s, est. speed input: 690.59 toks/s, output: 115.29 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:12,  2.00it/s, est. speed input: 773.59 toks/s, output: 136.82 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:05,  3.92it/s, est. speed input: 1095.44 toks/s, output: 205.60 toks/s]Processed prompts:  41%|████      | 13/32 [00:08<00:03,  5.51it/s, est. speed input: 1424.76 toks/s, output: 273.46 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:08<00:03,  5.65it/s, est. speed input: 1487.25 toks/s, output: 294.96 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:08<00:03,  5.16it/s, est. speed input: 1529.15 toks/s, output: 313.78 toks/s]Processed prompts:  50%|█████     | 16/32 [00:09<00:04,  3.29it/s, est. speed input: 1501.60 toks/s, output: 321.16 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:09<00:03,  4.00it/s, est. speed input: 1656.13 toks/s, output: 371.54 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:09<00:03,  3.99it/s, est. speed input: 1711.79 toks/s, output: 394.70 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:10<00:03,  3.45it/s, est. speed input: 1740.40 toks/s, output: 412.92 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:10<00:03,  3.40it/s, est. speed input: 1810.06 toks/s, output: 436.02 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:12<00:05,  1.69it/s, est. speed input: 1678.53 toks/s, output: 423.92 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:16<00:14,  1.66s/it, est. speed input: 1269.93 toks/s, output: 356.40 toks/s]Processed prompts:  75%|███████▌  | 24/32 [01:06<02:01, 15.14s/it, est. speed input: 330.60 toks/s, output: 151.56 toks/s] Processed prompts: 100%|██████████| 32/32 [01:06<00:00,  2.07s/it, est. speed input: 443.31 toks/s, output: 647.39 toks/s]
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:58:11 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:44,  7.24s/it, est. speed input: 103.48 toks/s, output: 17.27 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:35,  3.18s/it, est. speed input: 209.38 toks/s, output: 35.60 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:08<00:27,  1.03s/it, est. speed input: 606.97 toks/s, output: 91.32 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:08<00:16,  1.53it/s, est. speed input: 826.42 toks/s, output: 132.60 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:08,  2.63it/s, est. speed input: 1149.29 toks/s, output: 198.42 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:07,  2.77it/s, est. speed input: 1266.80 toks/s, output: 216.98 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:06,  3.01it/s, est. speed input: 1328.72 toks/s, output: 237.30 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:03,  4.58it/s, est. speed input: 1548.30 toks/s, output: 308.02 toks/s]Processed prompts:  50%|█████     | 16/32 [00:09<00:03,  4.53it/s, est. speed input: 1634.28 toks/s, output: 328.20 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:10<00:05,  2.89it/s, est. speed input: 1571.54 toks/s, output: 332.74 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:11<00:06,  2.24it/s, est. speed input: 1585.04 toks/s, output: 342.51 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:11<00:04,  2.71it/s, est. speed input: 1633.13 toks/s, output: 372.12 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:11<00:03,  3.25it/s, est. speed input: 1699.70 toks/s, output: 401.88 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:11<00:03,  3.52it/s, est. speed input: 1739.72 toks/s, output: 428.98 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:15<00:11,  1.18s/it, est. speed input: 1386.28 toks/s, output: 372.12 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:17<00:13,  1.54s/it, est. speed input: 1247.69 toks/s, output: 366.22 toks/s]Processed prompts:  75%|███████▌  | 24/32 [01:06<02:02, 15.35s/it, est. speed input: 338.89 toks/s, output: 157.46 toks/s] Processed prompts: 100%|██████████| 32/32 [01:06<00:00,  2.09s/it, est. speed input: 458.44 toks/s, output: 647.69 toks/s]
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 17:59:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:40,  7.10s/it, est. speed input: 118.04 toks/s, output: 17.89 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:30,  3.03s/it, est. speed input: 230.46 toks/s, output: 36.30 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:53,  1.85s/it, est. speed input: 396.62 toks/s, output: 55.33 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:22,  1.18it/s, est. speed input: 559.89 toks/s, output: 96.86 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:08<00:12,  1.99it/s, est. speed input: 763.79 toks/s, output: 139.45 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:08,  2.87it/s, est. speed input: 901.58 toks/s, output: 181.79 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:05,  3.71it/s, est. speed input: 1105.69 toks/s, output: 224.64 toks/s]Processed prompts:  41%|████      | 13/32 [00:08<00:03,  4.82it/s, est. speed input: 1276.89 toks/s, output: 270.43 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:08<00:03,  5.22it/s, est. speed input: 1338.38 toks/s, output: 292.69 toks/s]Processed prompts:  50%|█████     | 16/32 [00:08<00:02,  6.62it/s, est. speed input: 1460.70 toks/s, output: 340.40 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:09<00:02,  5.30it/s, est. speed input: 1605.31 toks/s, output: 377.29 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:09<00:02,  4.35it/s, est. speed input: 1641.98 toks/s, output: 392.52 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:10<00:03,  3.10it/s, est. speed input: 1627.63 toks/s, output: 401.00 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:10<00:02,  3.54it/s, est. speed input: 1690.75 toks/s, output: 451.28 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:11<00:01,  4.58it/s, est. speed input: 1833.01 toks/s, output: 511.94 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:11<00:01,  4.74it/s, est. speed input: 1904.39 toks/s, output: 539.19 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:12<00:02,  2.12it/s, est. speed input: 1751.36 toks/s, output: 520.43 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:13<00:03,  1.57it/s, est. speed input: 1703.38 toks/s, output: 519.15 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:14<00:02,  1.62it/s, est. speed input: 1705.90 toks/s, output: 542.37 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:21<00:06,  2.32s/it, est. speed input: 1215.43 toks/s, output: 420.20 toks/s]Processed prompts:  94%|█████████▍| 30/32 [01:00<00:24, 12.40s/it, est. speed input: 444.01 toks/s, output: 217.92 toks/s] Processed prompts: 100%|██████████| 32/32 [01:00<00:00,  1.88s/it, est. speed input: 479.76 toks/s, output: 354.21 toks/s]
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:00:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:23,  6.56s/it, est. speed input: 208.21 toks/s, output: 11.44 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:36,  3.22s/it, est. speed input: 368.04 toks/s, output: 27.03 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:34,  1.24s/it, est. speed input: 562.42 toks/s, output: 61.52 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:25,  1.05it/s, est. speed input: 648.32 toks/s, output: 78.46 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:19,  1.33it/s, est. speed input: 767.98 toks/s, output: 96.23 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:08<00:14,  1.76it/s, est. speed input: 834.30 toks/s, output: 115.87 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:11,  2.07it/s, est. speed input: 966.22 toks/s, output: 134.71 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:10,  2.30it/s, est. speed input: 990.45 toks/s, output: 153.86 toks/s]Processed prompts:  41%|████      | 13/32 [00:09<00:03,  4.88it/s, est. speed input: 1389.12 toks/s, output: 244.99 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:04,  4.39it/s, est. speed input: 1409.20 toks/s, output: 263.15 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:04,  4.02it/s, est. speed input: 1460.12 toks/s, output: 282.26 toks/s]Processed prompts:  50%|█████     | 16/32 [00:10<00:03,  4.47it/s, est. speed input: 1540.39 toks/s, output: 306.70 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:10<00:02,  4.95it/s, est. speed input: 1781.43 toks/s, output: 375.86 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:11<00:02,  4.75it/s, est. speed input: 1882.28 toks/s, output: 421.30 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:13<00:05,  1.74it/s, est. speed input: 1680.72 toks/s, output: 402.46 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:14<00:04,  1.90it/s, est. speed input: 1681.92 toks/s, output: 433.23 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:22<00:15,  2.17s/it, est. speed input: 1112.24 toks/s, output: 322.00 toks/s]Processed prompts:  81%|████████▏ | 26/32 [01:05<01:08, 11.46s/it, est. speed input: 398.20 toks/s, output: 173.68 toks/s] Processed prompts: 100%|██████████| 32/32 [01:05<00:00,  2.04s/it, est. speed input: 503.82 toks/s, output: 549.98 toks/s]
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:01:25 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<04:03,  7.86s/it, est. speed input: 104.86 toks/s, output: 16.03 toks/s]Processed prompts:   6%|▋         | 2/32 [00:08<01:41,  3.38s/it, est. speed input: 188.36 toks/s, output: 32.83 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:09<00:33,  1.23s/it, est. speed input: 456.88 toks/s, output: 82.26 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:09<00:18,  1.33it/s, est. speed input: 688.74 toks/s, output: 126.33 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:11,  2.03it/s, est. speed input: 880.67 toks/s, output: 170.95 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:09<00:07,  2.80it/s, est. speed input: 1124.49 toks/s, output: 214.08 toks/s]Processed prompts:  41%|████      | 13/32 [00:09<00:05,  3.66it/s, est. speed input: 1312.05 toks/s, output: 258.38 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:10<00:04,  4.15it/s, est. speed input: 1518.32 toks/s, output: 299.92 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:10<00:03,  4.27it/s, est. speed input: 1704.92 toks/s, output: 340.32 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:11<00:03,  4.04it/s, est. speed input: 1850.02 toks/s, output: 379.74 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:12<00:03,  2.88it/s, est. speed input: 1826.75 toks/s, output: 404.51 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:12<00:02,  3.52it/s, est. speed input: 1946.52 toks/s, output: 462.27 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:13<00:02,  2.69it/s, est. speed input: 1936.42 toks/s, output: 471.47 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:13<00:02,  2.37it/s, est. speed input: 1934.69 toks/s, output: 488.14 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:19<00:06,  1.34s/it, est. speed input: 1473.03 toks/s, output: 418.52 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:40<00:21,  5.45s/it, est. speed input: 736.32 toks/s, output: 262.92 toks/s] Processed prompts:  91%|█████████ | 29/32 [01:02<00:27,  9.23s/it, est. speed input: 497.86 toks/s, output: 236.22 toks/s]Processed prompts: 100%|██████████| 32/32 [01:02<00:00,  1.97s/it, est. speed input: 540.75 toks/s, output: 431.56 toks/s]
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:02:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:24,  6.60s/it, est. speed input: 106.37 toks/s, output: 17.88 toks/s]Processed prompts:   6%|▋         | 2/32 [00:06<01:24,  2.82s/it, est. speed input: 207.34 toks/s, output: 36.33 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:22,  1.19it/s, est. speed input: 533.47 toks/s, output: 93.58 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:16,  1.52it/s, est. speed input: 697.88 toks/s, output: 131.59 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:14,  1.70it/s, est. speed input: 760.61 toks/s, output: 151.33 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:11,  2.03it/s, est. speed input: 811.08 toks/s, output: 174.04 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:09,  2.31it/s, est. speed input: 900.96 toks/s, output: 196.14 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:08<00:06,  3.27it/s, est. speed input: 1100.75 toks/s, output: 245.72 toks/s]Processed prompts:  41%|████      | 13/32 [00:08<00:05,  3.69it/s, est. speed input: 1147.82 toks/s, output: 270.51 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:04,  3.93it/s, est. speed input: 1228.53 toks/s, output: 294.28 toks/s]Processed prompts:  50%|█████     | 16/32 [00:09<00:02,  5.52it/s, est. speed input: 1406.35 toks/s, output: 349.57 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:09<00:02,  5.22it/s, est. speed input: 1440.90 toks/s, output: 372.50 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:09<00:02,  4.99it/s, est. speed input: 1483.06 toks/s, output: 395.96 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:10<00:02,  4.57it/s, est. speed input: 1543.45 toks/s, output: 418.28 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:10<00:03,  3.47it/s, est. speed input: 1569.36 toks/s, output: 433.88 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:10<00:03,  3.34it/s, est. speed input: 1649.99 toks/s, output: 456.37 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:10<00:02,  3.85it/s, est. speed input: 1675.68 toks/s, output: 485.69 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:11<00:03,  2.98it/s, est. speed input: 1672.58 toks/s, output: 501.20 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:12<00:05,  1.58it/s, est. speed input: 1575.63 toks/s, output: 489.59 toks/s]Processed prompts:  81%|████████▏ | 26/32 [01:04<01:12, 12.09s/it, est. speed input: 341.62 toks/s, output: 169.44 toks/s] Processed prompts: 100%|██████████| 32/32 [01:04<00:00,  2.01s/it, est. speed input: 438.23 toks/s, output: 550.73 toks/s]
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:03:34 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:32,  8.79s/it, est. speed input: 157.63 toks/s, output: 20.60 toks/s]Processed prompts:   9%|▉         | 3/32 [00:08<01:07,  2.32s/it, est. speed input: 361.65 toks/s, output: 62.07 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:09<00:47,  1.70s/it, est. speed input: 444.27 toks/s, output: 81.74 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:09<00:35,  1.31s/it, est. speed input: 540.18 toks/s, output: 102.59 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:10<00:25,  1.03it/s, est. speed input: 595.50 toks/s, output: 125.68 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:10<00:12,  1.86it/s, est. speed input: 763.97 toks/s, output: 176.48 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:10<00:09,  2.32it/s, est. speed input: 851.71 toks/s, output: 220.87 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:11<00:07,  2.84it/s, est. speed input: 1012.39 toks/s, output: 268.77 toks/s]Processed prompts:  41%|████      | 13/32 [00:11<00:05,  3.24it/s, est. speed input: 1111.46 toks/s, output: 295.18 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:11<00:06,  2.91it/s, est. speed input: 1158.79 toks/s, output: 314.86 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:12<00:07,  2.26it/s, est. speed input: 1182.88 toks/s, output: 329.20 toks/s]Processed prompts:  50%|█████     | 16/32 [00:12<00:06,  2.44it/s, est. speed input: 1218.64 toks/s, output: 354.91 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:13<00:06,  2.44it/s, est. speed input: 1276.76 toks/s, output: 378.72 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:13<00:05,  2.75it/s, est. speed input: 1324.85 toks/s, output: 407.26 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:14<00:06,  2.12it/s, est. speed input: 1338.13 toks/s, output: 423.08 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:15<00:06,  1.90it/s, est. speed input: 1369.21 toks/s, output: 442.66 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:16<00:07,  1.51it/s, est. speed input: 1337.17 toks/s, output: 455.31 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:25<00:31,  3.19s/it, est. speed input: 892.19 toks/s, output: 338.54 toks/s] Processed prompts:  72%|███████▏  | 23/32 [01:10<02:19, 15.54s/it, est. speed input: 339.66 toks/s, output: 180.34 toks/s]Processed prompts: 100%|██████████| 32/32 [01:10<00:00,  2.19s/it, est. speed input: 482.51 toks/s, output: 705.76 toks/s]
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:04:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:56,  7.62s/it, est. speed input: 77.78 toks/s, output: 17.84 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:36,  3.23s/it, est. speed input: 184.06 toks/s, output: 36.12 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:52,  1.83s/it, est. speed input: 310.98 toks/s, output: 54.81 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:08<00:36,  1.29s/it, est. speed input: 445.37 toks/s, output: 73.32 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:08<00:28,  1.04s/it, est. speed input: 533.27 toks/s, output: 92.60 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:09<00:13,  1.86it/s, est. speed input: 637.68 toks/s, output: 139.94 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:09<00:10,  2.33it/s, est. speed input: 742.04 toks/s, output: 162.82 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:09,  2.41it/s, est. speed input: 854.77 toks/s, output: 182.71 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:10<00:09,  2.39it/s, est. speed input: 955.63 toks/s, output: 202.83 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:10<00:06,  3.03it/s, est. speed input: 1080.33 toks/s, output: 228.76 toks/s]Processed prompts:  41%|████      | 13/32 [00:10<00:03,  4.85it/s, est. speed input: 1278.63 toks/s, output: 283.02 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:11<00:07,  2.56it/s, est. speed input: 1260.48 toks/s, output: 290.36 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:11<00:08,  2.08it/s, est. speed input: 1248.76 toks/s, output: 305.83 toks/s]Processed prompts:  50%|█████     | 16/32 [00:12<00:06,  2.36it/s, est. speed input: 1284.84 toks/s, output: 333.35 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:13<00:08,  1.74it/s, est. speed input: 1231.72 toks/s, output: 345.30 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:13<00:06,  2.09it/s, est. speed input: 1295.94 toks/s, output: 376.43 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:14<00:08,  1.51it/s, est. speed input: 1279.82 toks/s, output: 386.78 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:14<00:04,  2.52it/s, est. speed input: 1411.22 toks/s, output: 461.49 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:15<00:05,  1.98it/s, est. speed input: 1382.77 toks/s, output: 477.51 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:16<00:03,  2.01it/s, est. speed input: 1438.14 toks/s, output: 531.12 toks/s]Processed prompts:  78%|███████▊  | 25/32 [01:06<01:21, 11.66s/it, est. speed input: 379.44 toks/s, output: 194.26 toks/s] Processed prompts: 100%|██████████| 32/32 [01:06<00:00,  2.07s/it, est. speed input: 480.29 toks/s, output: 627.19 toks/s]
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:05:52 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:33,  6.90s/it, est. speed input: 91.17 toks/s, output: 16.09 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:29,  2.98s/it, est. speed input: 178.93 toks/s, output: 33.04 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:49,  1.69s/it, est. speed input: 226.66 toks/s, output: 50.70 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:29,  1.06s/it, est. speed input: 267.82 toks/s, output: 68.92 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:19,  1.37it/s, est. speed input: 346.25 toks/s, output: 87.29 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:15,  1.69it/s, est. speed input: 401.92 toks/s, output: 104.96 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:10,  2.32it/s, est. speed input: 540.51 toks/s, output: 125.36 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:04,  4.87it/s, est. speed input: 831.79 toks/s, output: 189.29 toks/s]Processed prompts:  41%|████      | 13/32 [00:08<00:03,  6.32it/s, est. speed input: 1023.35 toks/s, output: 250.42 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:08<00:02,  6.73it/s, est. speed input: 1263.77 toks/s, output: 292.79 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:09<00:03,  4.59it/s, est. speed input: 1372.99 toks/s, output: 320.66 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:09<00:03,  4.55it/s, est. speed input: 1386.17 toks/s, output: 342.26 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:10<00:04,  2.99it/s, est. speed input: 1415.77 toks/s, output: 348.35 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:10<00:04,  2.88it/s, est. speed input: 1473.38 toks/s, output: 369.01 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:11<00:02,  3.49it/s, est. speed input: 1595.09 toks/s, output: 422.99 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:11<00:01,  4.88it/s, est. speed input: 1820.53 toks/s, output: 487.89 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:11<00:01,  3.63it/s, est. speed input: 1831.54 toks/s, output: 501.66 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:15<00:05,  1.03it/s, est. speed input: 1486.27 toks/s, output: 435.40 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:19<00:05,  1.36s/it, est. speed input: 1322.78 toks/s, output: 430.39 toks/s]Processed prompts:  91%|█████████ | 29/32 [01:01<00:30, 10.23s/it, est. speed input: 437.50 toks/s, output: 202.09 toks/s] Processed prompts: 100%|██████████| 32/32 [01:01<00:00,  1.91s/it, est. speed input: 486.65 toks/s, output: 403.22 toks/s]
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:06:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:18,  6.40s/it, est. speed input: 66.30 toks/s, output: 21.42 toks/s]Processed prompts:   6%|▋         | 2/32 [00:06<01:22,  2.73s/it, est. speed input: 148.18 toks/s, output: 43.25 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:30,  1.07s/it, est. speed input: 551.20 toks/s, output: 87.88 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:21,  1.25it/s, est. speed input: 615.77 toks/s, output: 109.80 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:15,  1.65it/s, est. speed input: 752.83 toks/s, output: 132.34 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:12,  1.94it/s, est. speed input: 760.54 toks/s, output: 153.38 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:11,  1.96it/s, est. speed input: 828.57 toks/s, output: 190.04 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:09,  2.35it/s, est. speed input: 872.81 toks/s, output: 217.76 toks/s]Processed prompts:  41%|████      | 13/32 [00:09<00:05,  3.49it/s, est. speed input: 1173.18 toks/s, output: 300.59 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:05,  3.04it/s, est. speed input: 1169.27 toks/s, output: 319.74 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:10<00:08,  2.06it/s, est. speed input: 1146.15 toks/s, output: 326.04 toks/s]Processed prompts:  50%|█████     | 16/32 [00:10<00:06,  2.33it/s, est. speed input: 1209.96 toks/s, output: 357.02 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:11<00:07,  2.13it/s, est. speed input: 1243.85 toks/s, output: 378.51 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:11<00:06,  2.32it/s, est. speed input: 1255.70 toks/s, output: 408.50 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:12<00:05,  2.36it/s, est. speed input: 1253.54 toks/s, output: 436.38 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:12<00:03,  3.28it/s, est. speed input: 1292.78 toks/s, output: 508.19 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:13<00:04,  2.09it/s, est. speed input: 1264.66 toks/s, output: 513.59 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:14<00:04,  1.84it/s, est. speed input: 1252.05 toks/s, output: 532.42 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:14<00:04,  1.81it/s, est. speed input: 1269.42 toks/s, output: 558.11 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:32<00:37,  5.34s/it, est. speed input: 604.11 toks/s, output: 311.82 toks/s] Processed prompts:  81%|████████▏ | 26/32 [01:04<01:16, 12.73s/it, est. speed input: 319.88 toks/s, output: 222.74 toks/s]Processed prompts: 100%|██████████| 32/32 [01:04<00:00,  2.01s/it, est. speed input: 388.39 toks/s, output: 605.67 toks/s]
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:07:58 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:53,  7.52s/it, est. speed input: 163.03 toks/s, output: 15.43 toks/s]Processed prompts:   6%|▋         | 2/32 [00:08<01:42,  3.41s/it, est. speed input: 320.22 toks/s, output: 32.63 toks/s]Processed prompts:   9%|▉         | 3/32 [00:08<00:58,  2.01s/it, est. speed input: 373.05 toks/s, output: 51.13 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:08<00:25,  1.07it/s, est. speed input: 662.24 toks/s, output: 89.96 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:18,  1.42it/s, est. speed input: 694.91 toks/s, output: 109.93 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:09<00:18,  1.35it/s, est. speed input: 722.37 toks/s, output: 125.06 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:10<00:16,  1.43it/s, est. speed input: 797.05 toks/s, output: 144.29 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:10<00:12,  1.88it/s, est. speed input: 902.77 toks/s, output: 169.58 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:10<00:08,  2.45it/s, est. speed input: 943.78 toks/s, output: 195.22 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:10<00:06,  3.12it/s, est. speed input: 1066.37 toks/s, output: 220.99 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:10<00:05,  3.49it/s, est. speed input: 1157.08 toks/s, output: 245.29 toks/s]Processed prompts:  41%|████      | 13/32 [00:11<00:06,  2.80it/s, est. speed input: 1150.85 toks/s, output: 264.12 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:11<00:05,  3.41it/s, est. speed input: 1239.16 toks/s, output: 291.34 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:11<00:05,  2.99it/s, est. speed input: 1240.54 toks/s, output: 312.50 toks/s]Processed prompts:  50%|█████     | 16/32 [00:12<00:05,  3.13it/s, est. speed input: 1305.79 toks/s, output: 337.65 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:12<00:04,  3.47it/s, est. speed input: 1396.31 toks/s, output: 364.79 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:12<00:03,  3.51it/s, est. speed input: 1474.41 toks/s, output: 390.54 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:13<00:05,  2.45it/s, est. speed input: 1460.18 toks/s, output: 405.54 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:13<00:05,  2.05it/s, est. speed input: 1487.62 toks/s, output: 422.87 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:14<00:05,  2.09it/s, est. speed input: 1515.49 toks/s, output: 447.52 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:14<00:04,  2.29it/s, est. speed input: 1547.33 toks/s, output: 475.65 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:14<00:03,  2.75it/s, est. speed input: 1566.21 toks/s, output: 508.46 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:16<00:05,  1.38it/s, est. speed input: 1476.10 toks/s, output: 501.90 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:17<00:03,  1.56it/s, est. speed input: 1520.38 toks/s, output: 554.02 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:18<00:03,  1.29it/s, est. speed input: 1487.13 toks/s, output: 564.52 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:20<00:04,  1.03s/it, est. speed input: 1412.55 toks/s, output: 564.07 toks/s]Processed prompts:  91%|█████████ | 29/32 [01:02<00:36, 12.12s/it, est. speed input: 484.84 toks/s, output: 251.74 toks/s] Processed prompts: 100%|██████████| 32/32 [01:02<00:00,  1.95s/it, est. speed input: 528.35 toks/s, output: 448.69 toks/s]
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:09:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:20,  8.40s/it, est. speed input: 119.95 toks/s, output: 14.65 toks/s]Processed prompts:   6%|▋         | 2/32 [00:09<01:56,  3.90s/it, est. speed input: 224.75 toks/s, output: 31.59 toks/s]Processed prompts:   9%|▉         | 3/32 [00:09<01:06,  2.29s/it, est. speed input: 304.24 toks/s, output: 50.02 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:10<00:44,  1.58s/it, est. speed input: 389.43 toks/s, output: 69.06 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:10<00:32,  1.21s/it, est. speed input: 498.94 toks/s, output: 88.95 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:10<00:21,  1.19it/s, est. speed input: 570.95 toks/s, output: 111.65 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:10<00:16,  1.51it/s, est. speed input: 604.98 toks/s, output: 133.45 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:11<00:10,  2.18it/s, est. speed input: 709.30 toks/s, output: 178.15 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:11<00:09,  2.37it/s, est. speed input: 775.89 toks/s, output: 200.57 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:12<00:09,  2.27it/s, est. speed input: 826.79 toks/s, output: 221.04 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:12<00:04,  4.22it/s, est. speed input: 1104.05 toks/s, output: 303.40 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:12<00:04,  3.94it/s, est. speed input: 1155.20 toks/s, output: 325.62 toks/s]Processed prompts:  50%|█████     | 16/32 [00:12<00:03,  4.51it/s, est. speed input: 1252.71 toks/s, output: 352.91 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:13<00:03,  4.69it/s, est. speed input: 1339.25 toks/s, output: 378.48 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:13<00:04,  3.41it/s, est. speed input: 1388.62 toks/s, output: 395.83 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:14<00:03,  3.72it/s, est. speed input: 1509.80 toks/s, output: 446.86 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:14<00:03,  3.41it/s, est. speed input: 1541.73 toks/s, output: 469.17 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:15<00:04,  2.33it/s, est. speed input: 1546.84 toks/s, output: 479.28 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:15<00:03,  2.73it/s, est. speed input: 1615.06 toks/s, output: 509.49 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:18<00:09,  1.16s/it, est. speed input: 1405.57 toks/s, output: 462.51 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:35<00:39,  5.60s/it, est. speed input: 775.21 toks/s, output: 297.39 toks/s] Processed prompts:  81%|████████▏ | 26/32 [01:07<01:17, 12.99s/it, est. speed input: 426.97 toks/s, output: 219.22 toks/s]Processed prompts: 100%|██████████| 32/32 [01:07<00:00,  2.10s/it, est. speed input: 515.26 toks/s, output: 585.18 toks/s]
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:10:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:16,  6.35s/it, est. speed input: 79.00 toks/s, output: 19.51 toks/s]Processed prompts:   9%|▉         | 3/32 [00:06<00:49,  1.70s/it, est. speed input: 276.52 toks/s, output: 58.69 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:23,  1.13it/s, est. speed input: 535.42 toks/s, output: 98.20 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:14,  1.73it/s, est. speed input: 830.04 toks/s, output: 138.13 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:08,  2.62it/s, est. speed input: 1024.68 toks/s, output: 183.54 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:04,  4.34it/s, est. speed input: 1261.58 toks/s, output: 253.44 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:07<00:04,  4.15it/s, est. speed input: 1320.54 toks/s, output: 287.41 toks/s]Processed prompts:  50%|█████     | 16/32 [00:08<00:03,  4.09it/s, est. speed input: 1476.05 toks/s, output: 327.18 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:08<00:03,  3.83it/s, est. speed input: 1558.49 toks/s, output: 365.17 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:09<00:02,  4.63it/s, est. speed input: 1754.86 toks/s, output: 420.97 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:02,  3.97it/s, est. speed input: 1782.22 toks/s, output: 458.36 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:09<00:02,  4.24it/s, est. speed input: 1806.14 toks/s, output: 486.99 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:10<00:02,  3.30it/s, est. speed input: 1779.27 toks/s, output: 498.42 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:11<00:02,  2.66it/s, est. speed input: 1729.55 toks/s, output: 510.05 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:11<00:02,  2.40it/s, est. speed input: 1713.47 toks/s, output: 527.67 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:11<00:01,  2.81it/s, est. speed input: 1775.60 toks/s, output: 561.37 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:14<00:01,  1.50it/s, est. speed input: 1689.32 toks/s, output: 557.00 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:59<00:21, 10.98s/it, est. speed input: 410.81 toks/s, output: 201.77 toks/s] Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  1.85s/it, est. speed input: 444.07 toks/s, output: 340.24 toks/s]
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:11:09 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:35,  6.96s/it, est. speed input: 81.16 toks/s, output: 16.81 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:29,  2.97s/it, est. speed input: 220.34 toks/s, output: 34.20 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:55,  1.92s/it, est. speed input: 271.05 toks/s, output: 52.52 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:19,  1.31it/s, est. speed input: 532.83 toks/s, output: 113.38 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:09<00:19,  1.31it/s, est. speed input: 605.25 toks/s, output: 130.63 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:09<00:18,  1.29it/s, est. speed input: 640.60 toks/s, output: 149.18 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:10<00:15,  1.49it/s, est. speed input: 657.26 toks/s, output: 173.90 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:10<00:12,  1.71it/s, est. speed input: 713.81 toks/s, output: 199.50 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:11<00:12,  1.74it/s, est. speed input: 754.95 toks/s, output: 222.75 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:11<00:09,  2.15it/s, est. speed input: 863.98 toks/s, output: 252.49 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:11<00:06,  2.91it/s, est. speed input: 1049.61 toks/s, output: 311.39 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:12<00:06,  2.67it/s, est. speed input: 1064.23 toks/s, output: 335.08 toks/s]Processed prompts:  50%|█████     | 16/32 [00:12<00:07,  2.12it/s, est. speed input: 1107.41 toks/s, output: 352.85 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:15<00:14,  1.00it/s, est. speed input: 994.16 toks/s, output: 339.30 toks/s] Processed prompts:  56%|█████▋    | 18/32 [00:18<00:22,  1.58s/it, est. speed input: 896.55 toks/s, output: 328.04 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:21<00:25,  1.98s/it, est. speed input: 835.91 toks/s, output: 331.00 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:24<00:26,  2.25s/it, est. speed input: 765.11 toks/s, output: 342.04 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:36<00:56,  5.17s/it, est. speed input: 547.46 toks/s, output: 282.94 toks/s]Processed prompts:  69%|██████▉   | 22/32 [01:09<02:13, 13.38s/it, est. speed input: 304.70 toks/s, output: 207.47 toks/s]Processed prompts: 100%|██████████| 32/32 [01:09<00:00,  2.18s/it, est. speed input: 427.38 toks/s, output: 794.93 toks/s]
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 18:12:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:04<01:30,  4.75s/it, est. speed input: 289.07 toks/s, output: 22.33 toks/s]Processed prompts:  10%|█         | 2/20 [00:04<00:37,  2.07s/it, est. speed input: 429.78 toks/s, output: 45.39 toks/s]Processed prompts:  15%|█▌        | 3/20 [00:05<00:24,  1.43s/it, est. speed input: 516.78 toks/s, output: 68.73 toks/s]Processed prompts:  20%|██        | 4/20 [00:05<00:14,  1.08it/s, est. speed input: 725.14 toks/s, output: 96.57 toks/s]Processed prompts:  25%|██▌       | 5/20 [00:05<00:09,  1.54it/s, est. speed input: 797.69 toks/s, output: 124.62 toks/s]Processed prompts:  35%|███▌      | 7/20 [00:06<00:06,  2.12it/s, est. speed input: 1035.48 toks/s, output: 175.88 toks/s]Processed prompts:  40%|████      | 8/20 [00:08<00:11,  1.04it/s, est. speed input: 811.46 toks/s, output: 172.42 toks/s] Processed prompts:  50%|█████     | 10/20 [00:09<00:06,  1.54it/s, est. speed input: 996.62 toks/s, output: 248.27 toks/s]Processed prompts:  60%|██████    | 12/20 [00:09<00:03,  2.23it/s, est. speed input: 1183.37 toks/s, output: 329.99 toks/s]Processed prompts:  65%|██████▌   | 13/20 [00:10<00:03,  2.14it/s, est. speed input: 1256.71 toks/s, output: 358.61 toks/s]Processed prompts:  70%|███████   | 14/20 [00:10<00:02,  2.13it/s, est. speed input: 1329.95 toks/s, output: 389.67 toks/s]Processed prompts:  75%|███████▌  | 15/20 [00:11<00:02,  1.96it/s, est. speed input: 1376.71 toks/s, output: 416.13 toks/s]Processed prompts:  80%|████████  | 16/20 [00:12<00:03,  1.31it/s, est. speed input: 1259.65 toks/s, output: 419.15 toks/s]Processed prompts:  85%|████████▌ | 17/20 [00:13<00:02,  1.29it/s, est. speed input: 1227.19 toks/s, output: 447.36 toks/s]Processed prompts:  90%|█████████ | 18/20 [00:57<00:26, 13.06s/it, est. speed input: 298.25 toks/s, output: 174.66 toks/s] Processed prompts: 100%|██████████| 20/20 [00:57<00:00,  2.90s/it, est. speed input: 331.16 toks/s, output: 315.95 toks/s]
[rank0]:[W117 18:13:18.714760184 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
input_file results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results.json
output_dir results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker
  0%|          | 0/25 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/CB_2.py", line 11, in <module>
    ax.plot(x, y, 'm--')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (22,) and (21,)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/3d_3.py", line 15, in <module>
    ax.plot_trisurf(x, y, z, cmap=plt.cm.viridis)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py", line 2003, in plot_trisurf
    Triangulation.get_from_args_and_kwargs(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/tri/_triangulation.py", line 167, in get_from_args_and_kwargs
    triangulation = Triangulation(x, y, triangles, mask)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/tri/_triangulation.py", line 60, in __init__
    self.triangles, self._neighbors = _qhull.delaunay(x, y, sys.flags.verbose)
RuntimeError: Error in qhull Delaunay triangulation calculation: singular input data (exitcode=2); use python verbose option (-v) to see original qhull error.
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/3d_10.py", line 16, in <module>
    ax.set_zticks(np.arange(0.5, 4.0, 1.0))
AttributeError: 'Axes' object has no attribute 'set_zticks'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/3d_13.py", line 32, in <module>
    ax.view_init(elev=30, azim=45)
AttributeError: 'Axes' object has no attribute 'view_init'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/3d_7.py", line 14, in <module>
    ax.set_zlim(0, 12)
AttributeError: 'Axes' object has no attribute 'set_zlim'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/CB_13.py", line 21, in <module>
    ax.set_yticklabels(['snakes', 'navigate', 'question_selection', 'object_counting'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (5), usually from a call to set_ticks, does not match the number of labels (4).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/3d_8.py", line 31, in <module>
    ax.set_zticklabels(['-10', '-9', '-8', '-7', '-6', '-5', '-4', '-3', '-2', '-1', '0'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (5), usually from a call to set_ticks, does not match the number of labels (11).
  4%|▍         | 1/25 [00:01<00:31,  1.32s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/HR_24.py", line 17, in <module>
    c = ax.tripcolor(X, Y, Z, shading='flat', cmap=plt.cm.viridis)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/tri/_tripcolor.py", line 62, in tripcolor
    tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/tri/_triangulation.py", line 167, in get_from_args_and_kwargs
    triangulation = Triangulation(x, y, triangles, mask)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/tri/_triangulation.py", line 48, in __init__
    raise ValueError("x and y must be equal-length 1D arrays, but "
ValueError: x and y must be equal-length 1D arrays, but found shapes (100, 100) and (100, 100)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_3.py", line 15, in <module>
    ax.bar(models, data, color=['blue', 'orange', 'cyan', 'gold'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2524, in bar
    r = mpatches.Rectangle(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 718, in __init__
    super().__init__(**kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 91, in __init__
    self.set_linewidth(linewidth)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 391, in set_linewidth
    self._linewidth = float(w)
TypeError: only length-1 arrays can be converted to Python scalars
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_21.py", line 15, in <module>
    ax.barh(list(value.keys()), list(value.values()), color='blue')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2701, in barh
    patches = self.bar(x=left, height=height, width=width, bottom=y,
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 2 with shape (4, 5) and arg 3 with shape (4,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/CB_14.py", line 8, in <module>
    ax.hist(h, bins=20, color='lightblue', alpha=0.7)
NameError: name 'h' is not defined
/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/HR_2.py:16: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('viridis', 10)
  8%|▊         | 2/25 [00:02<00:27,  1.19s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_48.py", line 16, in <module>
    ax.bar(x_labels, accuracy, color='blue')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (2,) and arg 1 with shape (3,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_4.py", line 15, in <module>
    ax.bar(x, y2, color='orange')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (9,) and arg 1 with shape (4,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_1.py", line 23, in <module>
    ax.set_yticklabels(['0.0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (10), usually from a call to set_ticks, does not match the number of labels (9).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_16.py", line 19, in <module>
    ax.set_yticklabels(['human', 'gpt4', 'gpt4-cot'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (5), usually from a call to set_ticks, does not match the number of labels (3).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_79.py", line 13, in <module>
    ax.bar(labels, x, color='blue')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (5,) and arg 1 with shape (9,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_72.py", line 33, in <module>
    ax.bar(x - width/2, [3.5, 2.3, 4.4, 1.3], width, label='EN', color=colors[0])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (5,) and arg 1 with shape (4,).
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_58.py", line 12, in <module>
    ax.bar(labels, data, color=['r', 'orange', 'grey', 'b', 'blue'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (5,) and arg 1 with shape (8,).
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_93.py", line 18, in <module>
    ax.bar(eye_labels, eye_data, color=eye_colors)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (6,) and arg 1 with shape (5,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_37.py", line 35, in <module>
    ax.set_xticklabels(['ResNet18', 'AlexNet', 'ResNet50'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (5), usually from a call to set_ticks, does not match the number of labels (3).
 12%|█▏        | 3/25 [00:04<00:33,  1.50s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_70.py", line 13, in <module>
    ax.barh(labels, scores, color=colors)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2701, in barh
    patches = self.bar(x=left, height=height, width=width, bottom=y,
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 2 with shape (6,) and arg 3 with shape (5,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/errorbar_18.py", line 18, in <module>
    axs[2].barh(['Africa', 'South America', 'North America', 'Asia', 'Europe'], [18, 28, 25, 34, 45], color=['lightgrey', 'yellow', 'lightblue', 'lightcoral', 'lightpink'])
IndexError: index 2 is out of bounds for axis 0 with size 2
 16%|█▌        | 4/25 [00:05<00:31,  1.49s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/box_10.py", line 20, in <module>
    ax.set_xticklabels(['20', '30', '40', '50', '60', '70', '80', '90'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (7), usually from a call to set_ticks, does not match the number of labels (8).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/area_5.py", line 11, in <module>
    ax.plot(years, populations, 'b-')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (61,) and (21,)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/errorbar_9.py", line 19, in <module>
    ax.set_xticklabels(['-3.5', '-3.25', '-3.0', '-2.75', '-2.5', '-2.25', '-2.0', '-1.75', '-1.50'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (2), usually from a call to set_ticks, does not match the number of labels (9).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/box_22.py", line 10, in <module>
    data[:, 0] = np.random.normal(loc=50.0, scale=10.0, size=10)
ValueError: could not broadcast input array from shape (10,) into shape (3,)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/heatmap_20.py", line 17, in <module>
    ax.set_xticklabels(['angry', 'sad', 'disgust', 'contempt', 'anger', 'neutral', 'surprise', 'happy'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (7), usually from a call to set_ticks, does not match the number of labels (8).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_53.py", line 41, in <module>
    ax.bar(index + i * width, [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], width, color=colors[i])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (18,) and arg 1 with shape (17,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/heatmap_29.py", line 23, in <module>
    ax.set_xticklabels(['Low', 'Medium', 'High'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (3).
 20%|██        | 5/25 [00:07<00:30,  1.51s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/heatmap_6.py:14: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('viridis', 10)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/heatmap_6.py", line 33, in <module>
    cbar = plt.colorbar(ax.images[0], ax=ax)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 1450, in __getitem__
    return [artist
IndexError: list index out of range
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/heatmap_30.py", line 18, in <module>
    ax.set_xticklabels(['0', '2', '4', '6', '8', '10', '12'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (13), usually from a call to set_ticks, does not match the number of labels (7).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_88.py", line 20, in <module>
    ax.set_xticklabels(['-3.5', '-3.0', '-2.5', '-2.0', '-1.5', '-1.0', '-0.5'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (7).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_86.py", line 23, in <module>
    ax.set_yticklabels(['0', '5', '10', '15', '20', '25', '30'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (8), usually from a call to set_ticks, does not match the number of labels (7).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_96.py", line 12, in <module>
    ax.bar(range(len(truthful_data)), truthful_data, color='blue', alpha=0.5)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (2,) and arg 1 with shape (2, 3).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/hist_20.py", line 17, in <module>
    ax.hist(x, bins=10, color=data[i]['color'], alpha=0.7)
IndexError: list index out of range
 24%|██▍       | 6/25 [00:09<00:29,  1.57s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 1769, in convert_units
    ret = self.converter.convert(x, self.units, self)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/category.py", line 57, in convert
    unit.update(values)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/category.py", line 214, in update
    for val in OrderedDict.fromkeys(data):
TypeError: unhashable type: 'numpy.ndarray'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/box_14.py", line 38, in <module>
    ax.scatter([np.random.normal(0.88, 0.02, 10), np.random.normal(0.87, 0.02, 10), np.random.normal(0.83, 0.02, 10)], [np.random.normal(0.88, 0.02, 10), np.random.normal(0.87, 0.02, 10), np.random.normal(0.83, 0.02, 10)], color='black', marker='^')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4649, in scatter
    x, y = self._process_unit_info([("x", x), ("y", y)], kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 2573, in _process_unit_info
    return [axis_map[axis_name].convert_units(data)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 2573, in <listcomp>
    return [axis_map[axis_name].convert_units(data)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 1771, in convert_units
    raise munits.ConversionError('Failed to convert value(s) to axis '
matplotlib.units.ConversionError: Failed to convert value(s) to axis units: [array([0.91339357, 0.91456605, 0.85272188, 0.91074481, 0.86519372,
       0.88263584, 0.88645525, 0.90718885, 0.89983526, 0.85337038]), array([0.85742029, 0.84554914, 0.84561653, 0.89654612, 0.86594076,
       0.86487008, 0.87516159, 0.89353021, 0.87700307, 0.83935562]), array([0.85993657, 0.84957309, 0.80840199, 0.83706852, 0.82280793,
       0.81916799, 0.83889537, 0.80310958, 0.80444665, 0.8357691 ])]
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/hist_13.py", line 29, in <module>
    ax.set_color_cycle(['blue', 'orange'])
AttributeError: 'Axes' object has no attribute 'set_color_cycle'
/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/multidiff_11.py:20: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('Greens')
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/multidiff_11.py", line 22, in <module>
    cbar = plt.colorbar(cmap(norm), ax=ax[1])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/colors.py", line 737, in __call__
    mask_under = xa < 0
TypeError: '<' not supported between instances of 'Normalize' and 'int'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/errorbar_24.py", line 13, in <module>
    ax.plot([i, i], [values[i], values[i]], 'k-')
IndexError: list index out of range
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/errorbar_29.py", line 20, in <module>
    axs[0, 0].bar(nyc_labels, nyc_values, color=['green', 'blue', 'red'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (3,) and arg 1 with shape (4,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/line_20.py", line 8, in <module>
    ax.plot(ratio, performance, 'o-', color='orange')
NameError: name 'ratio' is not defined
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_40.py", line 12, in <module>
    ax.barh(categories, values, color='lightgrey')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2701, in barh
    patches = self.bar(x=left, height=height, width=width, bottom=y,
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 2 with shape (21,) and arg 3 with shape (18,).
 28%|██▊       | 7/25 [00:10<00:25,  1.44s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/heatmap_1.py", line 43, in <module>
    ax.set_yticklabels(labels)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (6), usually from a call to set_ticks, does not match the number of labels (5).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/multidiff_24.py", line 25, in <module>
    ax.set_rticks([0.2, 0.4, 0.6, 0.8, 1.0])
AttributeError: 'Axes' object has no attribute 'set_rticks'
/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/heatmap_24.py:17: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('Greens')
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/errorpoint_6.py", line 12, in <module>
    ax.errorbar(x, y, fmt='o', ecolor='black')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 3572, in errorbar
    raise ValueError("'x' and 'y' must have the same size")
ValueError: 'x' and 'y' must have the same size
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/heatmap_24.py", line 25, in <module>
    cbar = fig.colorbar(ax.images[0], ax=ax, orientation='vertical', fraction=0.046, pad=0.04)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 1450, in __getitem__
    return [artist
IndexError: list index out of range
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/hist_19.py", line 22, in <module>
    ax.plot(np.arange(0, 1, 0.01), mnist_data, 'b-', label='Non-defective')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (100,) and (1000,)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/multidiff_21.py", line 12, in <module>
    ax1.plot(years, values, 'o-', color='r')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (4,) and (6,)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/bar_99.py", line 15, in <module>
    plt.xticks(range(len(y)), ['Traffic Flow', 'Accident Rate', 'Public Transport Usage', 'Road Conditions', 'Public Satisfaction'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/pyplot.py", line 2068, in xticks
    labels_out = ax.set_xticklabels(labels, minor=minor, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (5).
 32%|███▏      | 8/25 [00:11<00:25,  1.47s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/heatmap_2.py", line 32, in <module>
    cbar = plt.colorbar(ax.images[0])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 1450, in __getitem__
    return [artist
IndexError: list index out of range
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/pie_2.py", line 14, in <module>
    ax.pie(dogs, labels=['Dogs 45%', 'Logs 10%', 'Frogs 15%', 'Hogs 30%'], colors=['green', 'blue', 'red', 'cyan'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 3240, in pie
    raise ValueError("'label' must be of length 'x'")
ValueError: 'label' must be of length 'x'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/heatmap_27.py", line 24, in <module>
    axs[0].set_xticklabels(['0', '2', '4', '6', '8', '10'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (10), usually from a call to set_ticks, does not match the number of labels (6).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/multidiff_6.py", line 20, in <module>
    ax.set_xticklabels(['1000', '1200', '1400', '1600', '1800', '2000'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (1), usually from a call to set_ticks, does not match the number of labels (6).
 36%|███▌      | 9/25 [00:13<00:22,  1.43s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/violin_7.py", line 15, in <module>
    axs[0].bar(x[i], y[i], color=colors[i], label=labels[i])
IndexError: index 2 is out of bounds for axis 0 with size 2
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/line_72.py", line 19, in <module>
    ax.set_yticklabels(['-80', '-70', '-60', '-50', '-40', '-30', '-20', '-10', '0', '10', '20', '30'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (11), usually from a call to set_ticks, does not match the number of labels (12).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/radar_5.py", line 28, in <module>
    ax.plot(angles, radii, 'o-', linewidth=2)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (10,) and (13,)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/scatter_24.py", line 8, in <module>
    axs[0, 0].scatter(x, y, color='cyan')
NameError: name 'x' is not defined
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/line_78.py", line 18, in <module>
    ax.plot(data[i]['sales'], color=data[i]['color'])
IndexError: list index out of range
 44%|████▍     | 11/25 [00:14<00:15,  1.08s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
 64%|██████▍   | 16/25 [00:15<00:04,  1.97it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/radar_10.py", line 21, in <module>
    ax.set_yticklabels(labels)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of labels (15).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct_checker/radar_13.py", line 24, in <module>
    ax.plot([0, x], [0, y], color=colors[i])
IndexError: list index out of range
 76%|███████▌  | 19/25 [00:16<00:02,  2.31it/s] 84%|████████▍ | 21/25 [00:16<00:01,  2.36it/s] 88%|████████▊ | 22/25 [00:17<00:01,  2.22it/s] 92%|█████████▏| 23/25 [00:18<00:00,  2.07it/s]100%|██████████| 25/25 [00:18<00:00,  1.37it/s]
Total Python Files 221
Total PDF Files 161
input_file results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results.json
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:01<01:09,  1.41s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  4%|▍         | 2/50 [00:02<01:06,  1.38s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  6%|▌         | 3/50 [00:03<01:00,  1.29s/it]  8%|▊         | 4/50 [00:05<00:59,  1.29s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_2.py:17: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('viridis', 10)
 10%|█         | 5/50 [00:07<01:07,  1.49s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_2.py:17: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('viridis', 10)
 12%|█▏        | 6/50 [00:08<01:03,  1.44s/it] 14%|█▍        | 7/50 [00:09<01:02,  1.45s/it] 16%|█▌        | 8/50 [00:10<00:56,  1.34s/it] 18%|█▊        | 9/50 [00:12<00:57,  1.41s/it] 20%|██        | 10/50 [00:14<00:57,  1.43s/it] 22%|██▏       | 11/50 [00:15<00:59,  1.52s/it] 24%|██▍       | 12/50 [00:17<00:55,  1.45s/it] 26%|██▌       | 13/50 [00:18<00:54,  1.47s/it] 28%|██▊       | 14/50 [00:19<00:51,  1.42s/it] 30%|███       | 15/50 [00:21<00:48,  1.39s/it] 32%|███▏      | 16/50 [00:22<00:47,  1.40s/it] 34%|███▍      | 17/50 [00:24<00:46,  1.41s/it] 36%|███▌      | 18/50 [00:25<00:46,  1.46s/it] 38%|███▊      | 19/50 [00:26<00:43,  1.40s/it] 40%|████      | 20/50 [00:28<00:43,  1.47s/it] 42%|████▏     | 21/50 [00:29<00:42,  1.46s/it] 44%|████▍     | 22/50 [00:31<00:39,  1.40s/it] 46%|████▌     | 23/50 [00:32<00:36,  1.35s/it] 48%|████▊     | 24/50 [00:33<00:35,  1.36s/it] 50%|█████     | 25/50 [00:35<00:32,  1.32s/it] 52%|█████▏    | 26/50 [00:36<00:31,  1.30s/it] 54%|█████▍    | 27/50 [00:37<00:28,  1.24s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_24.py:18: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('Greens')
/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_24.py:18: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('Greens')
 56%|█████▌    | 28/50 [00:38<00:27,  1.26s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_6.py:15: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('viridis', 10)
 58%|█████▊    | 29/50 [00:40<00:26,  1.28s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_6.py:15: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('viridis', 10)
 60%|██████    | 30/50 [00:41<00:25,  1.26s/it] 62%|██████▏   | 31/50 [00:42<00:23,  1.26s/it] 64%|██████▍   | 32/50 [00:43<00:22,  1.23s/it] 66%|██████▌   | 33/50 [00:44<00:20,  1.18s/it] 68%|██████▊   | 34/50 [00:46<00:20,  1.28s/it] 70%|███████   | 35/50 [00:47<00:19,  1.29s/it] 72%|███████▏  | 36/50 [00:48<00:17,  1.23s/it] 74%|███████▍  | 37/50 [00:50<00:17,  1.31s/it] 76%|███████▌  | 38/50 [00:51<00:15,  1.29s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_11.py:21: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('Greens')
 78%|███████▊  | 39/50 [00:52<00:14,  1.28s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_11.py:21: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('Greens')
 80%|████████  | 40/50 [00:55<00:16,  1.61s/it] 82%|████████▏ | 41/50 [00:56<00:14,  1.60s/it] 84%|████████▍ | 42/50 [00:58<00:13,  1.70s/it] 86%|████████▌ | 43/50 [00:59<00:11,  1.58s/it] 88%|████████▊ | 44/50 [01:01<00:09,  1.53s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
 90%|█████████ | 45/50 [01:02<00:07,  1.53s/it] 92%|█████████▏| 46/50 [01:04<00:06,  1.54s/it] 94%|█████████▍| 47/50 [01:05<00:04,  1.42s/it] 96%|█████████▌| 48/50 [01:06<00:02,  1.27s/it] 98%|█████████▊| 49/50 [01:06<00:01,  1.05s/it]100%|██████████| 50/50 [01:07<00:00,  1.12it/s]100%|██████████| 50/50 [01:07<00:00,  1.35s/it]
args.tasks ['code4evaluation']
args.model qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805
result file: ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results_code4evaluation.json
original_dataset_dir:  ./dataset/ori_500
generated_dataset_dir:  ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results
len dataset: 500
  0%|          | 0/25 [00:00<?, ?it/s]cmap is used viridis
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_36.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_67.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_25.py
  4%|▍         | 1/25 [00:16<06:34, 16.42s/it]cmap is used viridis
cmap is used viridis
cmap is used viridis
cmap is used viridis
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_32.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_92.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_26.py
  8%|▊         | 2/25 [00:34<06:37, 17.29s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_98.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_32.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_41.py
 12%|█▏        | 3/25 [00:54<06:44, 18.40s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_20.py
cmap is used viridis
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_28.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_26.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_41.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_18.py
 16%|█▌        | 4/25 [01:10<06:06, 17.44s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_82.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_33.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/graph_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_47.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_67.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_38.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_68.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
 20%|██        | 5/25 [01:26<05:40, 17.02s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_80.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_78.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_10.py
cmap is used coolwarm
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_83.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_3.py
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_texts.py:54: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
cmap is used <matplotlib.colors.LinearSegmentedColormap object at 0x75125a384b50>
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_70.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_6.py
 24%|██▍       | 6/25 [01:44<05:30, 17.37s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_4.py
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_chart_types.py:375: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_colors.py:766: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_17.py
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_layouts.py:31: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_25.py
 28%|██▊       | 7/25 [01:59<05:01, 16.75s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_46.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_44.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/tree_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_43.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_97.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_73.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_8.py
 32%|███▏      | 8/25 [02:16<04:45, 16.80s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_56.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_48.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_76.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_85.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_65.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_61.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_40.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_49.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_72.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_66.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_48.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_3.py
 36%|███▌      | 9/25 [02:32<04:24, 16.52s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_44.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_30.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_100.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_77.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_60.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_69.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_39.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/tree_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/tree_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_30.py
cmap is used viridis
cmap is used viridis
cmap is used viridis
 40%|████      | 10/25 [02:52<04:23, 17.54s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_71.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_51.py
cmap is used viridis
cmap is used magma
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_2.py
 44%|████▍     | 11/25 [03:09<04:01, 17.25s/it]cmap is used viridis
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_57.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_7.py
cmap is used spring
cmap is used spring
cmap is used spring
 48%|████▊     | 12/25 [03:29<03:56, 18.18s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_69.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_77.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_55.py
 52%|█████▏    | 13/25 [03:47<03:37, 18.11s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_96.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_30.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_3.py
 56%|█████▌    | 14/25 [04:03<03:12, 17.48s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/tree_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_42.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_75.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_45.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_45.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/quiver_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_40.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/quiver_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_29.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/quiver_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_28.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_54.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_23.py
 60%|██████    | 15/25 [04:21<02:55, 17.54s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_68.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_78.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_74.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_38.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_70.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_60.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_55.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_27.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_94.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_3.py
 64%|██████▍   | 16/25 [04:39<02:39, 17.72s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_65.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_66.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_27.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_28.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_57.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_51.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_63.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_36.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/graph_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_59.py
 68%|██████▊   | 17/25 [04:57<02:22, 17.83s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_29.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_39.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_42.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_54.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/graph_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_53.py
 72%|███████▏  | 18/25 [05:14<02:04, 17.73s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_99.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_79.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/quiver_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_27.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/quiver_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_35.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_28.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/tree_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_90.py
 76%|███████▌  | 19/25 [05:33<01:48, 18.04s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_64.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_25.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_61.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/graph_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_73.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_62.py
cmap is used viridis
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_7.py
 80%|████████  | 20/25 [06:01<01:45, 21.07s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_59.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_26.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_64.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_30.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_50.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_6.py
 84%|████████▍ | 21/25 [06:16<01:16, 19.11s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/graph_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_30.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_62.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_9.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_37.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_95.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_27.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_43.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_75.py
 88%|████████▊ | 22/25 [06:34<00:56, 18.93s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_93.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_26.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_58.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_52.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_49.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_18.py
 92%|█████████▏| 23/25 [06:55<00:39, 19.64s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_24.py
cmap is used nipy_spectral
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_74.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_29.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_84.py
cmap is used autumn
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_16.py
 96%|█████████▌| 24/25 [07:13<00:18, 18.92s/it]genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_72.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_34.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_91.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_89.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_23.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_1.py
cmap is used jet
cmap is used jet
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_53.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_86.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_63.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_88.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_34.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_56.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_26.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_29.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_79.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_81.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_71.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_76.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_15.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_24.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_29.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_11.py
100%|██████████| 25/25 [07:29<00:00, 18.24s/it]100%|██████████| 25/25 [07:29<00:00, 17.99s/it]
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_87.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_14.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_6.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_19.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_9.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_80.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_8.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_52.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_4.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_46.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_47.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_10.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_31.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_27.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_31.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_17.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_12.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_20.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_3.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_2.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_22.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_28.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_58.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_16.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_11.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_33.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_13.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_1.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_18.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_37.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_50.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_7.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_21.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_5.py
genearion_code_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_35.py
self.results_file ./results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results_code4evaluation.json
Time taken:  473.3865523338318
args.tasks ['gpt4evaluation']
args.model qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_60.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_39.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_86.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_36.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_56.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_33.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_69.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_52.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_92.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_95.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_38.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_52.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_31.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_43.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_78.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_26.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_100.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_70.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/tree_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_83.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_38.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_63.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/graph_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_42.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_54.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/tree_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_66.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_88.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_78.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_28.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_45.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_58.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/graph_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_97.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_59.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_72.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_72.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_61.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_79.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_32.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/quiver_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_46.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_90.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_62.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_31.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_46.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_56.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_29.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_57.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/graph_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/quiver_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_79.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_30.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_61.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_70.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_55.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_84.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/tree_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_27.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_27.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_29.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_57.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_50.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_73.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_48.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_28.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/graph_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_30.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_34.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_35.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_75.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_41.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_35.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_44.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_43.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_68.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_37.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_42.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_33.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_24.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_71.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_89.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_34.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_94.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_30.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_32.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_93.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_67.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_87.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_30.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_74.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_48.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_51.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_80.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_54.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_62.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_49.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/quiver_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_64.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_26.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_73.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_26.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_50.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_91.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_68.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_41.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_69.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_63.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_59.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_75.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_85.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_27.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_60.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_26.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_10.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_65.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_29.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_96.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_30.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_25.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/quiver_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_58.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/tree_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_76.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/quiver_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_99.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_15.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_18.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_77.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_66.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_27.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_82.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_74.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_71.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_27.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_28.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_28.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_47.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_65.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/tree_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_77.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_53.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_53.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_17.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_29.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_81.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_21.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_51.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_49.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_47.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_44.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_29.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_36.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_3.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_37.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_19.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_13.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_20.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/graph_5.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_12.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_2.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_45.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_14.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_28.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_76.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_80.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_11.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_39.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_40.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_22.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_6.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_7.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_40.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_98.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_26.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_9.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_8.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_1.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_64.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_55.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_16.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_4.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_23.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_67.pdf
Converting pdf to png:  results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_1.pdf
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 2/500 [00:03<12:45,  1.54s/it]  1%|          | 3/500 [00:03<09:13,  1.11s/it]  1%|          | 4/500 [00:04<07:10,  1.15it/s]  1%|          | 5/500 [00:04<05:28,  1.50it/s]  1%|          | 6/500 [00:07<11:50,  1.44s/it]  1%|▏         | 7/500 [00:07<09:43,  1.18s/it]  2%|▏         | 8/500 [00:08<07:13,  1.13it/s]  2%|▏         | 9/500 [00:11<12:33,  1.54s/it]  2%|▏         | 10/500 [00:14<16:10,  1.98s/it]  2%|▏         | 11/500 [00:17<18:32,  2.28s/it]  2%|▏         | 12/500 [00:17<13:50,  1.70s/it]  3%|▎         | 14/500 [00:18<08:36,  1.06s/it]  3%|▎         | 15/500 [00:18<07:20,  1.10it/s]  3%|▎         | 16/500 [00:21<11:39,  1.45s/it]  3%|▎         | 17/500 [00:24<14:56,  1.86s/it]  4%|▎         | 18/500 [00:24<11:30,  1.43s/it]  4%|▍         | 19/500 [00:27<14:59,  1.87s/it]  4%|▍         | 20/500 [00:30<17:30,  2.19s/it]  4%|▍         | 21/500 [00:33<19:16,  2.41s/it]  4%|▍         | 22/500 [00:36<20:31,  2.58s/it]  5%|▍         | 24/500 [00:39<16:43,  2.11s/it]  5%|▌         | 25/500 [00:40<13:35,  1.72s/it]  5%|▌         | 26/500 [00:43<16:09,  2.05s/it]  5%|▌         | 27/500 [00:43<12:31,  1.59s/it]  6%|▌         | 28/500 [00:46<15:30,  1.97s/it]  6%|▌         | 29/500 [00:46<11:44,  1.50s/it]  6%|▌         | 30/500 [00:49<15:05,  1.93s/it]  6%|▌         | 31/500 [00:50<11:10,  1.43s/it]  6%|▋         | 32/500 [00:53<14:38,  1.88s/it]  7%|▋         | 33/500 [00:56<17:05,  2.20s/it]  7%|▋         | 34/500 [00:59<18:52,  2.43s/it]  7%|▋         | 35/500 [01:02<20:05,  2.59s/it]  7%|▋         | 36/500 [01:04<20:57,  2.71s/it]  7%|▋         | 37/500 [01:07<21:31,  2.79s/it]  8%|▊         | 38/500 [01:08<15:20,  1.99s/it]  8%|▊         | 39/500 [01:08<11:03,  1.44s/it]  8%|▊         | 40/500 [01:08<08:50,  1.15s/it]  8%|▊         | 41/500 [01:08<06:31,  1.17it/s]  8%|▊         | 42/500 [01:09<06:21,  1.20it/s]  9%|▊         | 43/500 [01:12<11:14,  1.48s/it]  9%|▉         | 44/500 [01:13<09:25,  1.24s/it]  9%|▉         | 45/500 [01:16<13:19,  1.76s/it]  9%|▉         | 46/500 [01:19<16:05,  2.13s/it]  9%|▉         | 47/500 [01:22<18:04,  2.39s/it] 10%|▉         | 48/500 [01:25<19:19,  2.57s/it] 10%|▉         | 49/500 [01:25<14:15,  1.90s/it] 10%|█         | 50/500 [01:28<16:37,  2.22s/it] 10%|█         | 51/500 [01:28<12:20,  1.65s/it] 10%|█         | 52/500 [01:29<09:02,  1.21s/it] 11%|█         | 53/500 [01:32<13:00,  1.75s/it] 11%|█         | 55/500 [01:32<07:46,  1.05s/it] 11%|█         | 56/500 [01:35<11:17,  1.53s/it] 11%|█▏        | 57/500 [01:38<14:05,  1.91s/it] 12%|█▏        | 58/500 [01:41<16:16,  2.21s/it] 12%|█▏        | 59/500 [01:42<13:09,  1.79s/it] 12%|█▏        | 60/500 [01:42<10:34,  1.44s/it] 12%|█▏        | 61/500 [01:43<07:58,  1.09s/it] 12%|█▏        | 62/500 [01:45<11:57,  1.64s/it] 13%|█▎        | 63/500 [01:48<14:48,  2.03s/it] 13%|█▎        | 64/500 [01:49<11:46,  1.62s/it] 13%|█▎        | 65/500 [01:52<14:39,  2.02s/it] 13%|█▎        | 66/500 [01:53<11:23,  1.57s/it] 13%|█▎        | 67/500 [01:53<08:46,  1.21s/it] 14%|█▎        | 68/500 [01:56<12:34,  1.75s/it] 14%|█▍        | 69/500 [01:57<10:12,  1.42s/it] 14%|█▍        | 70/500 [02:00<13:31,  1.89s/it] 14%|█▍        | 71/500 [02:00<09:47,  1.37s/it] 14%|█▍        | 72/500 [02:03<13:14,  1.86s/it] 15%|█▍        | 73/500 [02:03<09:39,  1.36s/it] 15%|█▍        | 74/500 [02:06<13:05,  1.84s/it] 15%|█▌        | 75/500 [02:09<15:32,  2.19s/it] 15%|█▌        | 76/500 [02:11<14:30,  2.05s/it] 15%|█▌        | 77/500 [02:11<11:00,  1.56s/it] 16%|█▌        | 78/500 [02:11<08:19,  1.18s/it] 16%|█▌        | 79/500 [02:14<12:07,  1.73s/it] 16%|█▌        | 80/500 [02:17<14:52,  2.13s/it] 16%|█▌        | 81/500 [02:19<12:59,  1.86s/it] 16%|█▋        | 82/500 [02:22<15:23,  2.21s/it] 17%|█▋        | 83/500 [02:25<16:56,  2.44s/it] 17%|█▋        | 84/500 [02:28<18:02,  2.60s/it] 17%|█▋        | 85/500 [02:28<13:44,  1.99s/it] 17%|█▋        | 86/500 [02:31<15:50,  2.30s/it] 17%|█▋        | 87/500 [02:32<12:02,  1.75s/it] 18%|█▊        | 88/500 [02:35<14:31,  2.12s/it] 18%|█▊        | 89/500 [02:35<11:09,  1.63s/it] 18%|█▊        | 90/500 [02:38<13:58,  2.05s/it] 18%|█▊        | 91/500 [02:41<15:59,  2.35s/it] 18%|█▊        | 92/500 [02:44<17:18,  2.55s/it] 19%|█▊        | 93/500 [02:47<18:12,  2.68s/it] 19%|█▉        | 94/500 [02:48<14:12,  2.10s/it] 19%|█▉        | 95/500 [02:48<10:49,  1.60s/it] 19%|█▉        | 96/500 [02:51<13:37,  2.02s/it] 19%|█▉        | 97/500 [02:54<15:31,  2.31s/it] 20%|█▉        | 98/500 [02:57<16:58,  2.53s/it] 20%|█▉        | 99/500 [03:00<17:53,  2.68s/it] 20%|██        | 100/500 [03:01<14:23,  2.16s/it] 20%|██        | 101/500 [03:04<16:03,  2.42s/it] 20%|██        | 102/500 [03:07<17:10,  2.59s/it] 21%|██        | 103/500 [03:10<17:53,  2.70s/it] 21%|██        | 104/500 [03:13<18:23,  2.79s/it] 21%|██        | 106/500 [03:16<14:29,  2.21s/it] 21%|██▏       | 107/500 [03:19<15:41,  2.40s/it] 22%|██▏       | 109/500 [03:22<13:17,  2.04s/it] 22%|██▏       | 110/500 [03:23<11:15,  1.73s/it] 22%|██▏       | 111/500 [03:26<13:10,  2.03s/it] 22%|██▏       | 112/500 [03:29<14:41,  2.27s/it] 23%|██▎       | 113/500 [03:30<11:26,  1.77s/it] 23%|██▎       | 114/500 [03:32<13:33,  2.11s/it] 23%|██▎       | 115/500 [03:33<10:35,  1.65s/it] 23%|██▎       | 116/500 [03:33<08:03,  1.26s/it] 23%|██▎       | 117/500 [03:36<11:12,  1.76s/it] 24%|██▎       | 118/500 [03:37<08:46,  1.38s/it] 24%|██▍       | 119/500 [03:37<06:45,  1.06s/it] 24%|██▍       | 120/500 [03:40<10:19,  1.63s/it] 24%|██▍       | 121/500 [03:40<07:56,  1.26s/it] 24%|██▍       | 122/500 [03:43<11:09,  1.77s/it] 25%|██▍       | 123/500 [03:46<13:22,  2.13s/it] 25%|██▍       | 124/500 [03:47<10:06,  1.61s/it] 25%|██▌       | 125/500 [03:50<12:37,  2.02s/it] 25%|██▌       | 126/500 [03:50<09:30,  1.53s/it] 25%|██▌       | 127/500 [03:53<12:11,  1.96s/it] 26%|██▌       | 128/500 [03:56<14:03,  2.27s/it] 26%|██▌       | 129/500 [03:57<10:41,  1.73s/it] 26%|██▌       | 130/500 [03:59<12:57,  2.10s/it] 26%|██▌       | 131/500 [04:02<14:34,  2.37s/it] 26%|██▋       | 132/500 [04:05<15:40,  2.56s/it] 27%|██▋       | 133/500 [04:08<16:24,  2.68s/it] 27%|██▋       | 134/500 [04:11<16:55,  2.77s/it] 27%|██▋       | 135/500 [04:12<12:33,  2.07s/it] 27%|██▋       | 136/500 [04:12<08:57,  1.48s/it] 27%|██▋       | 137/500 [04:15<11:39,  1.93s/it] 28%|██▊       | 138/500 [04:18<13:31,  2.24s/it] 28%|██▊       | 139/500 [04:21<14:52,  2.47s/it] 28%|██▊       | 140/500 [04:22<12:00,  2.00s/it] 28%|██▊       | 142/500 [04:26<12:52,  2.16s/it] 29%|██▊       | 143/500 [04:29<14:02,  2.36s/it] 29%|██▉       | 144/500 [04:32<14:58,  2.52s/it] 29%|██▉       | 145/500 [04:35<15:40,  2.65s/it] 29%|██▉       | 146/500 [04:39<16:26,  2.79s/it] 29%|██▉       | 147/500 [04:39<12:27,  2.12s/it] 30%|██▉       | 148/500 [04:40<09:48,  1.67s/it] 30%|██▉       | 149/500 [04:43<12:04,  2.06s/it] 30%|███       | 150/500 [04:46<13:34,  2.33s/it] 30%|███       | 151/500 [04:46<10:16,  1.77s/it] 30%|███       | 152/500 [04:46<07:47,  1.34s/it] 31%|███       | 153/500 [04:47<05:57,  1.03s/it] 31%|███       | 154/500 [04:50<09:17,  1.61s/it] 31%|███       | 155/500 [04:50<07:21,  1.28s/it] 31%|███       | 156/500 [04:50<05:31,  1.04it/s] 31%|███▏      | 157/500 [04:50<04:06,  1.39it/s] 32%|███▏      | 158/500 [04:53<07:58,  1.40s/it] 32%|███▏      | 159/500 [04:56<10:38,  1.87s/it] 32%|███▏      | 160/500 [04:59<12:28,  2.20s/it] 32%|███▏      | 161/500 [05:02<13:48,  2.44s/it] 32%|███▏      | 162/500 [05:03<10:41,  1.90s/it] 33%|███▎      | 163/500 [05:03<07:48,  1.39s/it] 33%|███▎      | 164/500 [05:06<10:27,  1.87s/it] 33%|███▎      | 165/500 [05:09<12:18,  2.21s/it] 33%|███▎      | 166/500 [05:12<13:34,  2.44s/it] 33%|███▎      | 167/500 [05:12<09:40,  1.74s/it] 34%|███▍      | 169/500 [05:13<06:27,  1.17s/it] 34%|███▍      | 171/500 [05:16<07:08,  1.30s/it] 34%|███▍      | 172/500 [05:19<09:08,  1.67s/it] 35%|███▍      | 173/500 [05:22<10:48,  1.98s/it] 35%|███▍      | 174/500 [05:25<12:08,  2.24s/it] 35%|███▌      | 175/500 [05:28<13:09,  2.43s/it] 35%|███▌      | 177/500 [05:28<07:35,  1.41s/it] 36%|███▌      | 178/500 [05:31<09:33,  1.78s/it] 36%|███▌      | 179/500 [05:34<11:09,  2.08s/it] 36%|███▌      | 180/500 [05:37<12:22,  2.32s/it] 36%|███▌      | 181/500 [05:40<13:18,  2.50s/it] 36%|███▋      | 182/500 [05:43<13:59,  2.64s/it] 37%|███▋      | 183/500 [05:44<10:20,  1.96s/it] 37%|███▋      | 184/500 [05:47<11:53,  2.26s/it] 37%|███▋      | 185/500 [05:47<08:35,  1.64s/it] 37%|███▋      | 186/500 [05:50<10:38,  2.03s/it] 38%|███▊      | 188/500 [05:50<06:10,  1.19s/it] 38%|███▊      | 189/500 [05:51<05:25,  1.05s/it] 38%|███▊      | 190/500 [05:54<08:02,  1.56s/it] 38%|███▊      | 191/500 [05:54<06:24,  1.24s/it] 38%|███▊      | 192/500 [05:54<04:51,  1.06it/s] 39%|███▉      | 194/500 [05:57<06:07,  1.20s/it] 39%|███▉      | 195/500 [06:00<08:17,  1.63s/it] 39%|███▉      | 196/500 [06:03<10:02,  1.98s/it] 39%|███▉      | 197/500 [06:06<11:23,  2.26s/it] 40%|███▉      | 198/500 [06:09<12:24,  2.46s/it] 40%|███▉      | 199/500 [06:12<13:06,  2.61s/it] 40%|████      | 200/500 [06:15<13:37,  2.73s/it] 40%|████      | 201/500 [06:18<13:56,  2.80s/it] 40%|████      | 202/500 [06:19<10:26,  2.10s/it] 41%|████      | 203/500 [06:19<08:06,  1.64s/it] 41%|████      | 204/500 [06:22<10:04,  2.04s/it] 41%|████      | 205/500 [06:23<07:43,  1.57s/it] 41%|████      | 206/500 [06:26<09:47,  2.00s/it] 41%|████▏     | 207/500 [06:29<11:13,  2.30s/it] 42%|████▏     | 208/500 [06:32<12:13,  2.51s/it] 42%|████▏     | 209/500 [06:35<12:53,  2.66s/it] 42%|████▏     | 210/500 [06:38<13:21,  2.76s/it] 42%|████▏     | 211/500 [06:41<13:41,  2.84s/it] 42%|████▏     | 212/500 [06:44<13:51,  2.89s/it] 43%|████▎     | 213/500 [06:45<10:59,  2.30s/it] 43%|████▎     | 214/500 [06:48<11:55,  2.50s/it] 43%|████▎     | 215/500 [06:51<12:34,  2.65s/it] 43%|████▎     | 216/500 [06:52<10:32,  2.23s/it] 43%|████▎     | 217/500 [06:53<08:21,  1.77s/it] 44%|████▎     | 218/500 [06:56<10:04,  2.14s/it] 44%|████▍     | 219/500 [06:56<07:10,  1.53s/it] 44%|████▍     | 220/500 [06:57<07:09,  1.53s/it] 44%|████▍     | 222/500 [06:57<03:58,  1.17it/s] 45%|████▍     | 224/500 [06:58<02:37,  1.76it/s] 45%|████▌     | 225/500 [06:58<02:35,  1.77it/s] 45%|████▌     | 226/500 [06:59<02:28,  1.85it/s] 45%|████▌     | 227/500 [06:59<02:01,  2.24it/s] 46%|████▌     | 228/500 [06:59<01:49,  2.49it/s] 46%|████▌     | 229/500 [07:02<05:02,  1.11s/it] 46%|████▌     | 230/500 [07:02<04:03,  1.11it/s] 46%|████▌     | 231/500 [07:05<06:44,  1.50s/it] 46%|████▋     | 232/500 [07:08<08:40,  1.94s/it] 47%|████▋     | 233/500 [07:11<09:59,  2.25s/it] 47%|████▋     | 234/500 [07:14<10:56,  2.47s/it] 47%|████▋     | 236/500 [07:16<07:44,  1.76s/it] 47%|████▋     | 237/500 [07:17<06:22,  1.45s/it] 48%|████▊     | 238/500 [07:20<08:03,  1.85s/it] 48%|████▊     | 239/500 [07:20<06:03,  1.39s/it] 48%|████▊     | 240/500 [07:23<07:59,  1.85s/it] 48%|████▊     | 241/500 [07:23<06:09,  1.43s/it] 48%|████▊     | 242/500 [07:26<08:09,  1.90s/it] 49%|████▉     | 244/500 [07:27<04:37,  1.08s/it] 49%|████▉     | 245/500 [07:30<06:42,  1.58s/it] 49%|████▉     | 246/500 [07:33<08:27,  2.00s/it] 50%|████▉     | 248/500 [07:36<07:41,  1.83s/it] 50%|████▉     | 249/500 [07:39<08:56,  2.14s/it] 50%|█████     | 250/500 [07:40<07:11,  1.72s/it] 50%|█████     | 251/500 [07:43<08:50,  2.13s/it] 50%|█████     | 252/500 [07:46<10:04,  2.44s/it] 51%|█████     | 253/500 [07:47<07:42,  1.87s/it] 51%|█████     | 254/500 [07:47<05:45,  1.41s/it] 51%|█████     | 255/500 [07:50<07:53,  1.93s/it] 51%|█████     | 256/500 [07:53<09:27,  2.33s/it] 51%|█████▏    | 257/500 [07:54<06:59,  1.72s/it] 52%|█████▏    | 258/500 [07:57<08:49,  2.19s/it] 52%|█████▏    | 259/500 [08:00<10:04,  2.51s/it] 52%|█████▏    | 260/500 [08:03<10:58,  2.74s/it] 52%|█████▏    | 261/500 [08:04<08:25,  2.12s/it] 52%|█████▏    | 262/500 [08:07<09:49,  2.48s/it] 53%|█████▎    | 263/500 [08:11<10:42,  2.71s/it] 53%|█████▎    | 264/500 [08:14<11:20,  2.88s/it] 53%|█████▎    | 265/500 [08:17<11:46,  3.01s/it] 53%|█████▎    | 266/500 [08:21<11:58,  3.07s/it] 53%|█████▎    | 267/500 [08:24<12:08,  3.13s/it] 54%|█████▍    | 269/500 [08:24<06:48,  1.77s/it] 54%|█████▍    | 270/500 [08:27<08:11,  2.14s/it] 54%|█████▍    | 271/500 [08:28<06:16,  1.64s/it] 54%|█████▍    | 272/500 [08:31<07:53,  2.07s/it] 55%|█████▍    | 273/500 [08:32<06:35,  1.74s/it] 55%|█████▍    | 274/500 [08:32<05:16,  1.40s/it] 55%|█████▌    | 275/500 [08:36<07:14,  1.93s/it] 55%|█████▌    | 276/500 [08:39<08:41,  2.33s/it] 55%|█████▌    | 277/500 [08:42<09:44,  2.62s/it] 56%|█████▌    | 278/500 [08:42<07:03,  1.91s/it] 56%|█████▌    | 279/500 [08:43<05:21,  1.45s/it] 56%|█████▌    | 281/500 [08:44<03:54,  1.07s/it] 56%|█████▋    | 282/500 [08:45<03:34,  1.02it/s] 57%|█████▋    | 283/500 [08:45<02:46,  1.30it/s] 57%|█████▋    | 284/500 [08:48<05:16,  1.46s/it] 57%|█████▋    | 285/500 [08:52<07:07,  1.99s/it] 57%|█████▋    | 286/500 [08:55<08:28,  2.38s/it] 58%|█████▊    | 288/500 [08:58<07:21,  2.08s/it] 58%|█████▊    | 289/500 [09:02<08:19,  2.37s/it] 58%|█████▊    | 290/500 [09:02<06:21,  1.82s/it] 58%|█████▊    | 291/500 [09:05<07:37,  2.19s/it] 58%|█████▊    | 292/500 [09:08<08:25,  2.43s/it] 59%|█████▊    | 293/500 [09:09<06:54,  2.00s/it] 59%|█████▉    | 294/500 [09:12<07:54,  2.30s/it] 59%|█████▉    | 295/500 [09:13<06:02,  1.77s/it] 59%|█████▉    | 296/500 [09:16<07:15,  2.13s/it] 59%|█████▉    | 297/500 [09:19<08:06,  2.39s/it] 60%|█████▉    | 298/500 [09:22<08:41,  2.58s/it] 60%|█████▉    | 299/500 [09:22<06:34,  1.96s/it] 60%|██████    | 300/500 [09:22<04:47,  1.44s/it] 60%|██████    | 301/500 [09:25<06:17,  1.90s/it] 60%|██████    | 302/500 [09:28<07:22,  2.23s/it] 61%|██████    | 303/500 [09:30<06:28,  1.97s/it] 61%|██████    | 304/500 [09:33<07:27,  2.28s/it] 61%|██████    | 305/500 [09:34<06:08,  1.89s/it] 61%|██████    | 306/500 [09:37<07:13,  2.24s/it] 61%|██████▏   | 307/500 [09:40<07:58,  2.48s/it] 62%|██████▏   | 308/500 [09:43<08:26,  2.64s/it] 62%|██████▏   | 309/500 [09:46<08:44,  2.75s/it] 62%|██████▏   | 310/500 [09:49<08:57,  2.83s/it] 62%|██████▏   | 311/500 [09:49<06:26,  2.05s/it] 62%|██████▏   | 312/500 [09:52<07:19,  2.34s/it] 63%|██████▎   | 313/500 [09:55<07:56,  2.55s/it] 63%|██████▎   | 314/500 [09:58<08:20,  2.69s/it] 63%|██████▎   | 315/500 [09:59<06:41,  2.17s/it] 63%|██████▎   | 316/500 [09:59<04:47,  1.57s/it] 63%|██████▎   | 317/500 [09:59<03:29,  1.15s/it] 64%|██████▎   | 318/500 [10:02<05:11,  1.71s/it] 64%|██████▍   | 319/500 [10:03<04:00,  1.33s/it] 64%|██████▍   | 320/500 [10:06<05:31,  1.84s/it] 64%|██████▍   | 321/500 [10:06<04:01,  1.35s/it] 64%|██████▍   | 322/500 [10:06<03:09,  1.06s/it] 65%|██████▍   | 323/500 [10:09<04:53,  1.66s/it] 65%|██████▍   | 324/500 [10:13<06:05,  2.08s/it] 65%|██████▌   | 325/500 [10:16<06:53,  2.36s/it] 65%|██████▌   | 326/500 [10:19<07:26,  2.57s/it] 65%|██████▌   | 327/500 [10:22<07:49,  2.71s/it] 66%|██████▌   | 328/500 [10:25<08:02,  2.80s/it] 66%|██████▌   | 329/500 [10:28<08:11,  2.87s/it] 66%|██████▌   | 330/500 [10:31<08:16,  2.92s/it] 66%|██████▌   | 331/500 [10:31<06:01,  2.14s/it] 66%|██████▋   | 332/500 [10:34<06:46,  2.42s/it] 67%|██████▋   | 333/500 [10:37<07:15,  2.61s/it] 67%|██████▋   | 334/500 [10:38<05:52,  2.12s/it] 67%|██████▋   | 335/500 [10:38<04:12,  1.53s/it] 67%|██████▋   | 336/500 [10:41<05:25,  1.99s/it] 67%|██████▋   | 337/500 [10:44<06:12,  2.29s/it] 68%|██████▊   | 338/500 [10:47<06:45,  2.50s/it] 68%|██████▊   | 339/500 [10:50<07:07,  2.66s/it] 68%|██████▊   | 340/500 [10:51<05:12,  1.95s/it] 68%|██████▊   | 341/500 [10:54<06:00,  2.27s/it] 68%|██████▊   | 342/500 [10:57<06:33,  2.49s/it] 69%|██████▊   | 343/500 [11:00<06:56,  2.65s/it] 69%|██████▉   | 344/500 [11:03<07:09,  2.75s/it] 69%|██████▉   | 345/500 [11:06<07:17,  2.82s/it] 69%|██████▉   | 346/500 [11:06<05:28,  2.13s/it] 69%|██████▉   | 347/500 [11:09<06:07,  2.40s/it] 70%|██████▉   | 348/500 [11:12<06:32,  2.58s/it] 70%|██████▉   | 349/500 [11:15<06:48,  2.71s/it] 70%|███████   | 350/500 [11:18<07:00,  2.80s/it] 70%|███████   | 351/500 [11:21<07:07,  2.87s/it] 71%|███████   | 353/500 [11:24<05:30,  2.25s/it] 71%|███████   | 354/500 [11:26<04:58,  2.05s/it] 71%|███████   | 355/500 [11:29<05:33,  2.30s/it] 71%|███████   | 356/500 [11:29<04:19,  1.80s/it] 71%|███████▏  | 357/500 [11:32<05:05,  2.13s/it] 72%|███████▏  | 358/500 [11:35<05:38,  2.39s/it] 72%|███████▏  | 359/500 [11:38<06:01,  2.57s/it] 72%|███████▏  | 360/500 [11:38<04:21,  1.86s/it] 72%|███████▏  | 361/500 [11:39<03:21,  1.45s/it] 72%|███████▏  | 362/500 [11:39<02:32,  1.10s/it] 73%|███████▎  | 364/500 [11:39<01:27,  1.55it/s] 73%|███████▎  | 365/500 [11:40<01:21,  1.66it/s] 73%|███████▎  | 366/500 [11:40<01:06,  2.02it/s] 73%|███████▎  | 367/500 [11:43<02:36,  1.18s/it] 74%|███████▎  | 368/500 [11:43<02:01,  1.09it/s] 74%|███████▍  | 369/500 [11:46<03:18,  1.52s/it] 74%|███████▍  | 370/500 [11:49<04:14,  1.96s/it] 74%|███████▍  | 371/500 [11:52<04:52,  2.27s/it] 74%|███████▍  | 372/500 [11:55<05:18,  2.49s/it] 75%|███████▍  | 373/500 [11:56<04:16,  2.02s/it] 75%|███████▍  | 374/500 [11:59<04:52,  2.32s/it] 75%|███████▌  | 375/500 [12:00<03:38,  1.75s/it] 75%|███████▌  | 376/500 [12:00<02:54,  1.41s/it] 75%|███████▌  | 377/500 [12:03<03:52,  1.89s/it] 76%|███████▌  | 378/500 [12:06<04:32,  2.23s/it] 76%|███████▌  | 379/500 [12:07<03:32,  1.75s/it] 76%|███████▌  | 380/500 [12:08<02:47,  1.40s/it] 76%|███████▌  | 381/500 [12:11<03:44,  1.89s/it] 76%|███████▋  | 382/500 [12:12<03:21,  1.71s/it] 77%|███████▋  | 383/500 [12:12<02:35,  1.33s/it] 77%|███████▋  | 384/500 [12:15<03:33,  1.84s/it] 77%|███████▋  | 385/500 [12:18<04:13,  2.21s/it] 77%|███████▋  | 387/500 [12:19<02:24,  1.28s/it] 78%|███████▊  | 388/500 [12:22<03:12,  1.72s/it] 78%|███████▊  | 389/500 [12:25<03:47,  2.05s/it] 78%|███████▊  | 390/500 [12:25<02:53,  1.58s/it] 78%|███████▊  | 391/500 [12:28<03:35,  1.98s/it] 78%|███████▊  | 392/500 [12:29<02:51,  1.59s/it] 79%|███████▊  | 393/500 [12:29<02:03,  1.16s/it] 79%|███████▉  | 394/500 [12:32<03:00,  1.70s/it] 79%|███████▉  | 395/500 [12:35<03:39,  2.09s/it] 79%|███████▉  | 396/500 [12:38<04:05,  2.36s/it] 79%|███████▉  | 397/500 [12:39<03:08,  1.83s/it] 80%|███████▉  | 398/500 [12:39<02:17,  1.35s/it] 80%|███████▉  | 399/500 [12:42<03:06,  1.84s/it] 80%|████████  | 400/500 [12:42<02:18,  1.39s/it] 80%|████████  | 401/500 [12:43<01:54,  1.16s/it] 80%|████████  | 402/500 [12:46<02:47,  1.71s/it] 81%|████████  | 403/500 [12:46<02:15,  1.40s/it] 81%|████████  | 404/500 [12:47<01:46,  1.11s/it] 81%|████████  | 405/500 [12:50<02:38,  1.67s/it] 81%|████████  | 406/500 [12:53<03:13,  2.06s/it] 81%|████████▏ | 407/500 [12:53<02:20,  1.52s/it] 82%|████████▏ | 408/500 [12:56<03:00,  1.96s/it] 82%|████████▏ | 409/500 [12:59<03:27,  2.27s/it] 82%|████████▏ | 410/500 [13:02<03:43,  2.49s/it] 82%|████████▏ | 411/500 [13:05<03:55,  2.64s/it] 82%|████████▏ | 412/500 [13:08<04:01,  2.74s/it] 83%|████████▎ | 413/500 [13:11<04:05,  2.82s/it] 83%|████████▎ | 414/500 [13:14<04:07,  2.88s/it] 83%|████████▎ | 415/500 [13:14<02:56,  2.07s/it] 83%|████████▎ | 416/500 [13:17<03:17,  2.35s/it] 83%|████████▎ | 417/500 [13:18<02:31,  1.83s/it] 84%|████████▎ | 418/500 [13:18<01:50,  1.35s/it] 84%|████████▍ | 420/500 [13:21<01:54,  1.44s/it] 84%|████████▍ | 421/500 [13:22<01:34,  1.19s/it] 84%|████████▍ | 422/500 [13:25<02:10,  1.67s/it] 85%|████████▍ | 423/500 [13:28<02:37,  2.04s/it] 85%|████████▍ | 424/500 [13:31<02:55,  2.31s/it] 85%|████████▌ | 425/500 [13:34<03:08,  2.51s/it] 85%|████████▌ | 426/500 [13:35<02:32,  2.05s/it] 85%|████████▌ | 427/500 [13:38<02:50,  2.34s/it] 86%|████████▌ | 428/500 [13:41<03:03,  2.54s/it] 86%|████████▌ | 429/500 [13:44<03:11,  2.70s/it] 86%|████████▌ | 431/500 [13:44<01:42,  1.49s/it] 86%|████████▋ | 432/500 [13:47<02:09,  1.90s/it] 87%|████████▋ | 433/500 [13:50<02:29,  2.23s/it] 87%|████████▋ | 434/500 [13:53<02:43,  2.48s/it] 87%|████████▋ | 435/500 [13:56<02:52,  2.65s/it] 87%|████████▋ | 436/500 [13:59<02:55,  2.74s/it] 87%|████████▋ | 437/500 [14:00<02:12,  2.10s/it] 88%|████████▊ | 439/500 [14:03<01:52,  1.85s/it] 88%|████████▊ | 440/500 [14:03<01:26,  1.44s/it] 88%|████████▊ | 441/500 [14:06<01:48,  1.84s/it] 88%|████████▊ | 442/500 [14:07<01:27,  1.51s/it] 89%|████████▊ | 443/500 [14:10<01:49,  1.93s/it] 89%|████████▉ | 444/500 [14:11<01:30,  1.61s/it] 89%|████████▉ | 445/500 [14:14<01:50,  2.01s/it] 89%|████████▉ | 446/500 [14:14<01:29,  1.66s/it] 90%|████████▉ | 448/500 [14:15<00:50,  1.03it/s] 90%|████████▉ | 449/500 [14:18<01:15,  1.47s/it] 90%|█████████ | 450/500 [14:21<01:33,  1.87s/it] 90%|█████████ | 451/500 [14:24<01:46,  2.17s/it] 90%|█████████ | 452/500 [14:24<01:18,  1.64s/it] 91%|█████████ | 453/500 [14:27<01:35,  2.03s/it] 91%|█████████ | 454/500 [14:30<01:46,  2.31s/it] 91%|█████████ | 455/500 [14:33<01:52,  2.50s/it] 91%|█████████ | 456/500 [14:36<01:56,  2.65s/it] 91%|█████████▏| 457/500 [14:39<01:59,  2.78s/it] 92%|█████████▏| 458/500 [14:39<01:27,  2.08s/it] 92%|█████████▏| 459/500 [14:42<01:36,  2.36s/it] 92%|█████████▏| 460/500 [14:43<01:15,  1.89s/it] 92%|█████████▏| 461/500 [14:43<00:53,  1.38s/it] 92%|█████████▏| 462/500 [14:46<01:10,  1.86s/it] 93%|█████████▎| 463/500 [14:47<00:54,  1.47s/it] 93%|█████████▎| 464/500 [14:50<01:09,  1.92s/it] 93%|█████████▎| 465/500 [14:53<01:18,  2.25s/it] 93%|█████████▎| 466/500 [14:54<01:02,  1.83s/it] 93%|█████████▎| 467/500 [14:54<00:48,  1.48s/it] 94%|█████████▎| 468/500 [14:56<00:47,  1.48s/it] 94%|█████████▍| 469/500 [14:59<01:00,  1.94s/it] 94%|█████████▍| 470/500 [14:59<00:43,  1.46s/it] 94%|█████████▍| 471/500 [15:02<00:56,  1.93s/it] 94%|█████████▍| 472/500 [15:05<01:03,  2.27s/it] 95%|█████████▍| 473/500 [15:06<00:47,  1.74s/it] 95%|█████████▍| 474/500 [15:07<00:39,  1.51s/it] 95%|█████████▌| 475/500 [15:10<00:49,  1.97s/it] 95%|█████████▌| 477/500 [15:13<00:40,  1.77s/it] 96%|█████████▌| 478/500 [15:16<00:45,  2.08s/it] 96%|█████████▌| 479/500 [15:16<00:34,  1.64s/it] 96%|█████████▌| 480/500 [15:17<00:28,  1.41s/it] 96%|█████████▌| 481/500 [15:18<00:22,  1.20s/it] 96%|█████████▋| 482/500 [15:18<00:17,  1.02it/s] 97%|█████████▋| 483/500 [15:21<00:26,  1.57s/it] 97%|█████████▋| 484/500 [15:22<00:21,  1.36s/it] 97%|█████████▋| 485/500 [15:25<00:27,  1.82s/it] 97%|█████████▋| 486/500 [15:28<00:30,  2.15s/it] 97%|█████████▋| 487/500 [15:31<00:31,  2.40s/it] 98%|█████████▊| 488/500 [15:31<00:21,  1.80s/it] 98%|█████████▊| 489/500 [15:32<00:15,  1.40s/it] 98%|█████████▊| 490/500 [15:35<00:18,  1.85s/it] 98%|█████████▊| 491/500 [15:35<00:13,  1.46s/it] 98%|█████████▊| 492/500 [15:38<00:15,  1.90s/it] 99%|█████████▊| 493/500 [15:41<00:15,  2.22s/it] 99%|█████████▉| 494/500 [15:42<00:10,  1.72s/it] 99%|█████████▉| 495/500 [15:45<00:10,  2.10s/it] 99%|█████████▉| 496/500 [15:45<00:06,  1.55s/it] 99%|█████████▉| 497/500 [15:48<00:05,  1.98s/it]100%|█████████▉| 498/500 [15:48<00:03,  1.52s/it]100%|█████████▉| 499/500 [15:49<00:01,  1.33s/it]100%|██████████| 500/500 [15:50<00:00,  1.15s/it]100%|██████████| 500/500 [15:50<00:00,  1.90s/it]
  0%|          | 0/11 [00:00<?, ?it/s]  9%|▉         | 1/11 [00:06<01:06,  6.60s/it] 18%|█▊        | 2/11 [00:15<01:11,  7.96s/it] 27%|██▋       | 3/11 [00:25<01:10,  8.83s/it] 36%|███▋      | 4/11 [00:32<00:57,  8.28s/it] 45%|████▌     | 5/11 [00:39<00:45,  7.62s/it] 55%|█████▍    | 6/11 [00:47<00:38,  7.75s/it] 64%|██████▎   | 7/11 [01:01<00:38,  9.73s/it] 73%|███████▎  | 8/11 [01:12<00:30, 10.13s/it] 82%|████████▏ | 9/11 [01:24<00:21, 10.84s/it] 91%|█████████ | 10/11 [01:34<00:10, 10.68s/it]originial_png_file: dataset/ori_500/bar_31.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_31.png
originial_png_file: dataset/ori_500/pie_2.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_2.png
originial_png_file: dataset/ori_500/bar_16.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_16.png
originial_png_file: dataset/ori_500/scatter_9.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_9.png
originial_png_file: dataset/ori_500/bar_41.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_41.png
originial_png_file: dataset/ori_500/bar_22.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_22.png
originial_png_file: dataset/ori_500/line_50.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_50.png
originial_png_file: dataset/ori_500/heatmap_7.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_7.png
originial_png_file: dataset/ori_500/violin_7.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_7.png
originial_png_file: dataset/ori_500/3d_1.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_1.png
originial_png_file: dataset/ori_500/hist_1.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_1.png
originial_png_file: dataset/ori_500/bar_63.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_63.png
originial_png_file: dataset/ori_500/multidiff_17.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_17.png
originial_png_file: dataset/ori_500/box_16.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_16.png
originial_png_file: dataset/ori_500/multidiff_24.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_24.png
originial_png_file: dataset/ori_500/multidiff_8.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_8.png
originial_png_file: dataset/ori_500/multidiff_2.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_2.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 3 seconds.'}}
originial_png_file: dataset/ori_500/bar_2.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_2.png
originial_png_file: dataset/ori_500/bar_58.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_58.png
originial_png_file: dataset/ori_500/line_51.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_51.png
originial_png_file: dataset/ori_500/bar_64.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_64.png
originial_png_file: dataset/ori_500/radar_14.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_14.png
originial_png_file: dataset/ori_500/pie_14.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_14.png
originial_png_file: dataset/ori_500/bar_21.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_21.png
originial_png_file: dataset/ori_500/errorbar_18.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_18.png
originial_png_file: dataset/ori_500/hist_3.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_3.png
originial_png_file: dataset/ori_500/errorbar_24.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_24.png
originial_png_file: dataset/ori_500/errorpoint_10.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_10.png
originial_png_file: dataset/ori_500/errorbar_27.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_27.png
originial_png_file: dataset/ori_500/contour_3.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_3.png
originial_png_file: dataset/ori_500/heatmap_8.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_8.png
originial_png_file: dataset/ori_500/multidiff_23.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_23.png
originial_png_file: dataset/ori_500/bar_36.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_36.png
originial_png_file: dataset/ori_500/line_26.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_26.png
originial_png_file: dataset/ori_500/line_78.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_78.png
originial_png_file: dataset/ori_500/heatmap_2.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_2.png
originial_png_file: dataset/ori_500/hist_6.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_6.png
originial_png_file: dataset/ori_500/bar_68.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_68.png
originial_png_file: dataset/ori_500/radar_5.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_5.png
originial_png_file: dataset/ori_500/violin_10.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_10.png
originial_png_file: dataset/ori_500/scatter_2.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_2.png
originial_png_file: dataset/ori_500/bar_13.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_13.png
originial_png_file: dataset/ori_500/bar_80.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_80.png
100%|██████████| 11/11 [02:06<00:00, 17.09s/it]100%|██████████| 11/11 [02:06<00:00, 11.49s/it]
originial_png_file: dataset/ori_500/bar_6.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_6.png
originial_png_file: dataset/ori_500/scatter_24.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_24.png
originial_png_file: dataset/ori_500/radar_1.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_1.png
originial_png_file: dataset/ori_500/bar_90.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_90.png
originial_png_file: dataset/ori_500/radar_8.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_8.png
originial_png_file: dataset/ori_500/hist_14.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_14.png
originial_png_file: dataset/ori_500/bar_94.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_94.png
originial_png_file: dataset/ori_500/density_3.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/density_3.png
originial_png_file: dataset/ori_500/CB_14.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_14.png
originial_png_file: dataset/ori_500/bar_82.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_82.png
originial_png_file: dataset/ori_500/line_20.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_20.png
originial_png_file: dataset/ori_500/multidiff_19.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_19.png
originial_png_file: dataset/ori_500/bar_43.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_43.png
originial_png_file: dataset/ori_500/pie_9.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_9.png
originial_png_file: dataset/ori_500/bar_62.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_62.png
originial_png_file: dataset/ori_500/3d_13.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_13.png
originial_png_file: dataset/ori_500/bar_35.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_35.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 6 seconds.'}}
originial_png_file: dataset/ori_500/radar_19.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_19.png
originial_png_file: dataset/ori_500/box_10.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_10.png
originial_png_file: dataset/ori_500/pie_7.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_7.png
originial_png_file: dataset/ori_500/bar_74.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_74.png
originial_png_file: dataset/ori_500/pie_8.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_8.png
originial_png_file: dataset/ori_500/multidiff_18.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_18.png
originial_png_file: dataset/ori_500/bar_38.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_38.png
originial_png_file: dataset/ori_500/line_72.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_72.png
originial_png_file: dataset/ori_500/line_61.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_61.png
originial_png_file: dataset/ori_500/line_35.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_35.png
originial_png_file: dataset/ori_500/multidiff_3.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_3.png
originial_png_file: dataset/ori_500/line_49.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_49.png
originial_png_file: dataset/ori_500/bar_85.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_85.png
originial_png_file: dataset/ori_500/heatmap_18.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_18.png
originial_png_file: dataset/ori_500/heatmap_29.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_29.png
originial_png_file: dataset/ori_500/errorbar_9.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_9.png
originial_png_file: dataset/ori_500/CB_18.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_18.png
originial_png_file: dataset/ori_500/heatmap_6.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_6.png
originial_png_file: dataset/ori_500/bar_10.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_10.png
originial_png_file: dataset/ori_500/bar_84.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_84.png
originial_png_file: dataset/ori_500/errorbar_3.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_3.png
originial_png_file: dataset/ori_500/CB_25.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_25.png
originial_png_file: dataset/ori_500/bar_26.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_26.png
originial_png_file: dataset/ori_500/box_22.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_22.png
originial_png_file: dataset/ori_500/heatmap_27.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_27.png
originial_png_file: dataset/ori_500/bar_37.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_37.png
originial_png_file: dataset/ori_500/area_1.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_1.png
originial_png_file: dataset/ori_500/HR_14.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_14.png
originial_png_file: dataset/ori_500/errorpoint_6.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorpoint_6.png
originial_png_file: dataset/ori_500/multidiff_5.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_5.png
originial_png_file: dataset/ori_500/HR_23.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_23.png
originial_png_file: dataset/ori_500/3d_5.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_5.png
originial_png_file: dataset/ori_500/CB_13.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_13.png
originial_png_file: dataset/ori_500/line_62.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_62.png
originial_png_file: dataset/ori_500/hist_2.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_2.png
originial_png_file: dataset/ori_500/contour_5.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_5.png
originial_png_file: dataset/ori_500/line_17.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_17.png
originial_png_file: dataset/ori_500/bar_98.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_98.png
originial_png_file: dataset/ori_500/area_4.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_4.png
originial_png_file: dataset/ori_500/multidiff_9.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_9.png
originial_png_file: dataset/ori_500/bar_88.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_88.png
originial_png_file: dataset/ori_500/PIP_3.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_3.png
originial_png_file: dataset/ori_500/CB_29.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_29.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 4 seconds.'}}
originial_png_file: dataset/ori_500/hist_13.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_13.png
originial_png_file: dataset/ori_500/bar_32.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_32.png
originial_png_file: dataset/ori_500/errorbar_19.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_19.png
originial_png_file: dataset/ori_500/3d_8.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_8.png
originial_png_file: dataset/ori_500/line_28.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_28.png
originial_png_file: dataset/ori_500/box_1.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_1.png
originial_png_file: dataset/ori_500/bar_33.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_33.png
originial_png_file: dataset/ori_500/bar_9.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_9.png
originial_png_file: dataset/ori_500/multidiff_7.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_7.png
originial_png_file: dataset/ori_500/bar_57.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_57.png
originial_png_file: dataset/ori_500/bar_73.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_73.png
originial_png_file: dataset/ori_500/CB_5.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_5.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 6 seconds.'}}
originial_png_file: dataset/ori_500/bar_93.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_93.png
originial_png_file: dataset/ori_500/bar_4.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_4.png
originial_png_file: dataset/ori_500/bar_17.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_17.png
originial_png_file: dataset/ori_500/scatter_14.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_14.png
originial_png_file: dataset/ori_500/pie_11.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_11.png
originial_png_file: dataset/ori_500/area_5.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/area_5.png
originial_png_file: dataset/ori_500/bar_70.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_70.png
originial_png_file: dataset/ori_500/bar_59.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_59.png
originial_png_file: dataset/ori_500/hist_15.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_15.png
originial_png_file: dataset/ori_500/3d_10.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_10.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 4 seconds.'}}
originial_png_file: dataset/ori_500/radar_10.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_10.png
originial_png_file: dataset/ori_500/bar_51.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_51.png
originial_png_file: dataset/ori_500/scatter_20.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/scatter_20.png
originial_png_file: dataset/ori_500/bar_30.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_30.png
originial_png_file: dataset/ori_500/line_53.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_53.png
originial_png_file: dataset/ori_500/multidiff_22.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_22.png
originial_png_file: dataset/ori_500/multidiff_25.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_25.png
originial_png_file: dataset/ori_500/3d_7.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_7.png
originial_png_file: dataset/ori_500/bar_72.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_72.png
originial_png_file: dataset/ori_500/bar_79.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_79.png
originial_png_file: dataset/ori_500/3d_9.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_9.png
originial_png_file: dataset/ori_500/radar_11.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_11.png
originial_png_file: dataset/ori_500/line_80.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_80.png
originial_png_file: dataset/ori_500/heatmap_1.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_1.png
originial_png_file: dataset/ori_500/hist_9.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_9.png
originial_png_file: dataset/ori_500/heatmap_20.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_20.png
originial_png_file: dataset/ori_500/bar_40.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_40.png
originial_png_file: dataset/ori_500/hist_4.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_4.png
originial_png_file: dataset/ori_500/bar_100.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_100.png
originial_png_file: dataset/ori_500/CB_17.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_17.png
originial_png_file: dataset/ori_500/multidiff_21.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_21.png
originial_png_file: dataset/ori_500/line_48.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_48.png
originial_png_file: dataset/ori_500/CB_2.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_2.png
originial_png_file: dataset/ori_500/line_30.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_30.png
originial_png_file: dataset/ori_500/line_59.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_59.png
originial_png_file: dataset/ori_500/bar_15.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_15.png
originial_png_file: dataset/ori_500/bar_77.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_77.png
originial_png_file: dataset/ori_500/line_39.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_39.png
originial_png_file: dataset/ori_500/bar_1.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_1.png
originial_png_file: dataset/ori_500/pie_10.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_10.png
originial_png_file: dataset/ori_500/pie_5.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_5.png
originial_png_file: dataset/ori_500/3d_12.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_12.png
originial_png_file: dataset/ori_500/bar_75.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_75.png
originial_png_file: dataset/ori_500/pie_4.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_4.png
originial_png_file: dataset/ori_500/pie_15.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_15.png
originial_png_file: dataset/ori_500/multidiff_11.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_11.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 3 seconds.'}}
originial_png_file: dataset/ori_500/line_76.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_76.png
originial_png_file: dataset/ori_500/errorbar_29.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_29.png
originial_png_file: dataset/ori_500/heatmap_16.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_16.png
originial_png_file: dataset/ori_500/heatmap_24.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_24.png
Request timed out.
originial_png_file: dataset/ori_500/hist_19.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_19.png
originial_png_file: dataset/ori_500/bar_97.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_97.png
originial_png_file: dataset/ori_500/bar_24.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_24.png
originial_png_file: dataset/ori_500/box_23.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_23.png
originial_png_file: dataset/ori_500/errorbar_17.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_17.png
originial_png_file: dataset/ori_500/bar_48.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_48.png
originial_png_file: dataset/ori_500/multidiff_1.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_1.png
originial_png_file: dataset/ori_500/bar_96.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_96.png
originial_png_file: dataset/ori_500/bar_53.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_53.png
originial_png_file: dataset/ori_500/PIP_4.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/PIP_4.png
originial_png_file: dataset/ori_500/pie_1.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_1.png
Request timed out.
originial_png_file: dataset/ori_500/3d_14.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_14.png
originial_png_file: dataset/ori_500/line_46.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_46.png
originial_png_file: dataset/ori_500/contour_4.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/contour_4.png
originial_png_file: dataset/ori_500/errorbar_16.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_16.png
originial_png_file: dataset/ori_500/hist_20.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_20.png
originial_png_file: dataset/ori_500/bar_91.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_91.png
originial_png_file: dataset/ori_500/CB_9.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_9.png
originial_png_file: dataset/ori_500/HR_19.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_19.png
originial_png_file: dataset/ori_500/pie_13.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_13.png
originial_png_file: dataset/ori_500/bar_86.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_86.png
originial_png_file: dataset/ori_500/HR_2.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_2.png
originial_png_file: dataset/ori_500/HR_24.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/HR_24.png
originial_png_file: dataset/ori_500/bar_29.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_29.png
originial_png_file: dataset/ori_500/CB_20.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/CB_20.png
originial_png_file: dataset/ori_500/3d_3.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_3.png
originial_png_file: dataset/ori_500/3d_6.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/3d_6.png
Error code: 429 - {'error': {'code': '429', 'message': 'Rate limit is exceeded. Try again in 7 seconds.'}}
originial_png_file: dataset/ori_500/hist_8.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_8.png
Request timed out.
originial_png_file: dataset/ori_500/bar_65.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_65.png
originial_png_file: dataset/ori_500/line_23.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/line_23.png
originial_png_file: dataset/ori_500/multidiff_14.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_14.png
originial_png_file: dataset/ori_500/heatmap_9.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_9.png
Request timed out.
originial_png_file: dataset/ori_500/multidiff_13.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_13.png
originial_png_file: dataset/ori_500/radar_7.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_7.png
originial_png_file: dataset/ori_500/bar_55.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_55.png
originial_png_file: dataset/ori_500/hist_16.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_16.png
originial_png_file: dataset/ori_500/hist_5.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/hist_5.png
originial_png_file: dataset/ori_500/violin_9.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/violin_9.png
originial_png_file: dataset/ori_500/radar_13.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_13.png
Request timed out.
originial_png_file: dataset/ori_500/bar_99.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_99.png
originial_png_file: dataset/ori_500/pie_3.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_3.png
originial_png_file: dataset/ori_500/bar_67.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_67.png
originial_png_file: dataset/ori_500/radar_15.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/radar_15.png
originial_png_file: dataset/ori_500/bar_78.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_78.png
originial_png_file: dataset/ori_500/multidiff_6.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/multidiff_6.png
Request timed out.
originial_png_file: dataset/ori_500/errorbar_21.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_21.png
originial_png_file: dataset/ori_500/errorbar_5.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/errorbar_5.png
originial_png_file: dataset/ori_500/bar_23.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_23.png
originial_png_file: dataset/ori_500/heatmap_30.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/heatmap_30.png
Request timed out.
originial_png_file: dataset/ori_500/bar_3.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_3.png
Request timed out.
originial_png_file: dataset/ori_500/box_14.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/box_14.png
originial_png_file: dataset/ori_500/pie_6.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/pie_6.png
originial_png_file: dataset/ori_500/bar_45.png generated_png_file: results/direct/chart2code_qwen2_vl_coder_mn_only-7b_3072_bsz128_1e3_pretrain_mix_114k_job_3072_805_DirectAgent_results/direct/bar_45.png
Time taken:  3295.019240140915
正在处理模型: pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000
INFO 01-17 19:18:02 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.
INFO 01-17 19:18:02 llm_engine.py:249] Initializing an LLM engine (v0.6.4) with config: model='/mnt/lingjiejiang/multimodal_code/exp/saves/pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k/sft/full/checkpoint-1000/', speculative_config=None, tokenizer='/mnt/lingjiejiang/multimodal_code/exp/saves/pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k/sft/full/checkpoint-1000/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/mnt/lingjiejiang/multimodal_code/exp/saves/pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k/sft/full/checkpoint-1000/, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-17 19:18:07 selector.py:135] Using Flash Attention backend.
INFO 01-17 19:18:08 model_runner.py:1072] Starting to load model /mnt/lingjiejiang/multimodal_code/exp/saves/pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k/sft/full/checkpoint-1000/...
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:15<00:45, 15.18s/it]
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:25<00:25, 12.59s/it]
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:41<00:14, 14.11s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:44<00:00,  9.67s/it]
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:44<00:00, 11.18s/it]

INFO 01-17 19:18:53 model_runner.py:1077] Loading model weights took 15.5083 GB
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
INFO 01-17 19:18:57 worker.py:232] Memory profiling results: total_gpu_memory=79.25GiB initial_memory_usage=16.15GiB peak_torch_memory=20.53GiB memory_usage_post_profile=16.55Gib non_torch_memory=1.04GiB kv_cache_size=49.77GiB gpu_memory_utilization=0.90
INFO 01-17 19:18:57 gpu_executor.py:113] # GPU blocks: 58239, # CPU blocks: 4681
INFO 01-17 19:18:57 gpu_executor.py:117] Maximum concurrency for 32768 tokens per request: 28.44x
INFO 01-17 19:19:03 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-17 19:19:03 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-17 19:19:15 model_runner.py:1518] Graph capturing finished in 12 secs, took 0.37 GiB
Processing 500 files
INFO 01-17 19:19:17 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:19:19 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:31,  4.90s/it, est. speed input: 278.46 toks/s, output: 5.92 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:12,  2.42s/it, est. speed input: 427.98 toks/s, output: 17.56 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:05<00:19,  1.41it/s, est. speed input: 940.52 toks/s, output: 55.43 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:05<00:11,  2.24it/s, est. speed input: 1214.90 toks/s, output: 81.57 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:06<00:07,  2.90it/s, est. speed input: 1451.69 toks/s, output: 107.72 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:06<00:04,  4.32it/s, est. speed input: 1824.16 toks/s, output: 154.19 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:06<00:03,  5.51it/s, est. speed input: 2019.56 toks/s, output: 189.91 toks/s]Processed prompts:  50%|█████     | 16/32 [00:06<00:02,  6.28it/s, est. speed input: 2184.10 toks/s, output: 223.96 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:06<00:01,  7.84it/s, est. speed input: 2350.71 toks/s, output: 263.75 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:07<00:01,  8.63it/s, est. speed input: 2569.03 toks/s, output: 302.84 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:07<00:01,  7.75it/s, est. speed input: 2669.48 toks/s, output: 338.54 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:07<00:00,  8.05it/s, est. speed input: 2787.86 toks/s, output: 379.06 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:07<00:00,  6.79it/s, est. speed input: 2816.08 toks/s, output: 416.37 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:08<00:00,  5.43it/s, est. speed input: 2785.65 toks/s, output: 429.08 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:08<00:00,  5.56it/s, est. speed input: 2830.98 toks/s, output: 452.17 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:20<00:08,  2.83s/it, est. speed input: 1206.39 toks/s, output: 244.90 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:58<00:22, 11.36s/it, est. speed input: 439.83 toks/s, output: 155.61 toks/s] Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.83s/it, est. speed input: 472.72 toks/s, output: 295.27 toks/s]
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:18 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:30,  4.86s/it, est. speed input: 207.21 toks/s, output: 3.29 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:10,  2.34s/it, est. speed input: 322.10 toks/s, output: 12.13 toks/s]Processed prompts:   9%|▉         | 3/32 [00:05<00:38,  1.33s/it, est. speed input: 458.57 toks/s, output: 22.12 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:05<00:24,  1.13it/s, est. speed input: 603.07 toks/s, output: 33.32 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:05<00:17,  1.57it/s, est. speed input: 709.28 toks/s, output: 45.79 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:06<00:12,  2.00it/s, est. speed input: 791.74 toks/s, output: 59.40 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:06<00:06,  3.55it/s, est. speed input: 1069.53 toks/s, output: 90.47 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:06<00:04,  4.65it/s, est. speed input: 1343.23 toks/s, output: 121.36 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:06<00:03,  6.20it/s, est. speed input: 1596.08 toks/s, output: 155.57 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:06<00:02,  7.26it/s, est. speed input: 1788.76 toks/s, output: 191.34 toks/s]Processed prompts:  50%|█████     | 16/32 [00:07<00:01,  8.70it/s, est. speed input: 2031.34 toks/s, output: 228.35 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:07<00:01,  9.59it/s, est. speed input: 2190.94 toks/s, output: 266.61 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:07<00:01, 10.59it/s, est. speed input: 2410.60 toks/s, output: 306.20 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:07<00:01,  8.48it/s, est. speed input: 2655.07 toks/s, output: 357.67 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:07<00:00,  9.74it/s, est. speed input: 2923.19 toks/s, output: 403.94 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:09<00:01,  4.36it/s, est. speed input: 2741.56 toks/s, output: 414.58 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:09<00:00,  3.76it/s, est. speed input: 2763.10 toks/s, output: 449.53 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:10<00:00,  2.76it/s, est. speed input: 2616.40 toks/s, output: 472.54 toks/s]Processed prompts: 100%|██████████| 32/32 [00:13<00:00,  1.48it/s, est. speed input: 2237.17 toks/s, output: 440.30 toks/s]Processed prompts: 100%|██████████| 32/32 [00:13<00:00,  2.44it/s, est. speed input: 2237.17 toks/s, output: 440.30 toks/s]
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:20:32 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:58,  5.76s/it, est. speed input: 178.61 toks/s, output: 7.47 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:14,  2.48s/it, est. speed input: 354.75 toks/s, output: 16.32 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:27,  1.00it/s, est. speed input: 619.85 toks/s, output: 35.59 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:20,  1.35it/s, est. speed input: 722.15 toks/s, output: 46.93 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:10,  2.39it/s, est. speed input: 948.15 toks/s, output: 71.62 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:06<00:06,  3.53it/s, est. speed input: 1215.34 toks/s, output: 98.10 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:06<00:04,  4.59it/s, est. speed input: 1447.79 toks/s, output: 126.47 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:04,  4.38it/s, est. speed input: 1624.51 toks/s, output: 152.17 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:07<00:02,  5.67it/s, est. speed input: 1896.24 toks/s, output: 188.32 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:07<00:02,  7.06it/s, est. speed input: 2115.63 toks/s, output: 225.77 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:02,  5.97it/s, est. speed input: 2337.44 toks/s, output: 259.33 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:08<00:01,  7.60it/s, est. speed input: 2534.23 toks/s, output: 303.57 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:08<00:01,  5.64it/s, est. speed input: 2547.69 toks/s, output: 336.69 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:08<00:01,  5.85it/s, est. speed input: 2568.65 toks/s, output: 358.72 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:08<00:00,  7.33it/s, est. speed input: 2776.73 toks/s, output: 408.52 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:09<00:00,  4.45it/s, est. speed input: 2745.27 toks/s, output: 434.03 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:09<00:00,  4.68it/s, est. speed input: 2817.11 toks/s, output: 459.45 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:10<00:00,  3.80it/s, est. speed input: 2777.01 toks/s, output: 474.45 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:10<00:00,  3.74it/s, est. speed input: 2795.13 toks/s, output: 497.80 toks/s]Processed prompts: 100%|██████████| 32/32 [00:58<00:00, 12.02s/it, est. speed input: 527.90 toks/s, output: 162.28 toks/s] Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.81s/it, est. speed input: 527.90 toks/s, output: 162.28 toks/s]
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:52,  5.57s/it, est. speed input: 150.34 toks/s, output: 10.23 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:10,  2.36s/it, est. speed input: 278.34 toks/s, output: 21.14 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:05<00:25,  1.09it/s, est. speed input: 502.43 toks/s, output: 44.05 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:23,  1.16it/s, est. speed input: 626.75 toks/s, output: 56.63 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:14,  1.74it/s, est. speed input: 880.59 toks/s, output: 89.45 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:07<00:07,  3.12it/s, est. speed input: 1103.54 toks/s, output: 149.26 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:04,  4.42it/s, est. speed input: 1561.13 toks/s, output: 209.67 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:08<00:04,  3.64it/s, est. speed input: 1614.12 toks/s, output: 238.56 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:02,  6.13it/s, est. speed input: 2085.79 toks/s, output: 344.58 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:08<00:01,  6.08it/s, est. speed input: 2231.67 toks/s, output: 388.08 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:09<00:02,  3.71it/s, est. speed input: 2176.44 toks/s, output: 406.23 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:10<00:02,  3.46it/s, est. speed input: 2131.79 toks/s, output: 425.99 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:10<00:01,  4.19it/s, est. speed input: 2194.70 toks/s, output: 487.23 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:10<00:00,  4.98it/s, est. speed input: 2377.99 toks/s, output: 576.24 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:11<00:00,  4.10it/s, est. speed input: 2363.95 toks/s, output: 591.88 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00,  3.20it/s, est. speed input: 2320.13 toks/s, output: 603.19 toks/s]Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  9.85s/it, est. speed input: 497.14 toks/s, output: 196.11 toks/s] Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.81s/it, est. speed input: 497.14 toks/s, output: 196.11 toks/s]
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:24,  6.60s/it, est. speed input: 80.67 toks/s, output: 9.40 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:29,  2.97s/it, est. speed input: 270.97 toks/s, output: 21.20 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:31,  1.14s/it, est. speed input: 480.69 toks/s, output: 46.43 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:17,  1.51it/s, est. speed input: 653.56 toks/s, output: 72.60 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:08,  2.66it/s, est. speed input: 1012.31 toks/s, output: 115.38 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:04,  4.61it/s, est. speed input: 1607.98 toks/s, output: 178.93 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:08<00:03,  5.24it/s, est. speed input: 1750.04 toks/s, output: 210.48 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:08<00:02,  6.42it/s, est. speed input: 1985.60 toks/s, output: 245.69 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:01,  7.18it/s, est. speed input: 2199.20 toks/s, output: 280.44 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:08<00:01,  8.16it/s, est. speed input: 2392.66 toks/s, output: 317.61 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:09<00:01,  6.48it/s, est. speed input: 2572.53 toks/s, output: 346.43 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:09<00:01,  6.57it/s, est. speed input: 2623.87 toks/s, output: 365.77 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:09<00:01,  6.33it/s, est. speed input: 2718.77 toks/s, output: 384.31 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:09<00:00,  6.03it/s, est. speed input: 2733.51 toks/s, output: 403.08 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:11<00:02,  2.11it/s, est. speed input: 2494.19 toks/s, output: 382.50 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:11<00:01,  2.11it/s, est. speed input: 2511.00 toks/s, output: 400.97 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:11<00:01,  2.52it/s, est. speed input: 2543.75 toks/s, output: 429.77 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:11<00:00,  2.88it/s, est. speed input: 2595.85 toks/s, output: 457.70 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00,  2.25it/s, est. speed input: 2546.56 toks/s, output: 470.69 toks/s]Processed prompts: 100%|██████████| 32/32 [00:15<00:00,  1.14s/it, est. speed input: 2131.04 toks/s, output: 429.26 toks/s]Processed prompts: 100%|██████████| 32/32 [00:15<00:00,  2.07it/s, est. speed input: 2131.04 toks/s, output: 429.26 toks/s]
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:22:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:37,  7.00s/it, est. speed input: 78.40 toks/s, output: 11.14 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:28,  1.07s/it, est. speed input: 751.26 toks/s, output: 56.73 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:18,  1.34it/s, est. speed input: 933.72 toks/s, output: 81.59 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:11,  1.96it/s, est. speed input: 1225.79 toks/s, output: 111.33 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:07<00:07,  2.69it/s, est. speed input: 1517.98 toks/s, output: 141.87 toks/s]Processed prompts:  41%|████      | 13/32 [00:08<00:05,  3.60it/s, est. speed input: 1700.14 toks/s, output: 174.07 toks/s]Processed prompts:  50%|█████     | 16/32 [00:08<00:03,  5.06it/s, est. speed input: 2031.93 toks/s, output: 223.16 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:08<00:02,  5.42it/s, est. speed input: 2153.95 toks/s, output: 254.97 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:09<00:03,  3.46it/s, est. speed input: 2053.66 toks/s, output: 272.94 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:10<00:03,  3.20it/s, est. speed input: 2066.14 toks/s, output: 289.12 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:10<00:02,  4.35it/s, est. speed input: 2271.87 toks/s, output: 341.52 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:10<00:01,  4.07it/s, est. speed input: 2331.26 toks/s, output: 360.80 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:11<00:01,  4.12it/s, est. speed input: 2435.01 toks/s, output: 404.85 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:12<00:01,  3.05it/s, est. speed input: 2401.24 toks/s, output: 434.97 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:13<00:01,  2.21it/s, est. speed input: 2326.37 toks/s, output: 440.18 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:14<00:01,  1.64it/s, est. speed input: 2214.51 toks/s, output: 444.55 toks/s]Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  8.96s/it, est. speed input: 574.48 toks/s, output: 185.71 toks/s] Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  1.85s/it, est. speed input: 574.48 toks/s, output: 185.71 toks/s]
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:23:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:27,  4.76s/it, est. speed input: 157.35 toks/s, output: 2.73 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:12,  2.43s/it, est. speed input: 309.96 toks/s, output: 13.13 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:05<00:26,  1.04it/s, est. speed input: 637.61 toks/s, output: 36.14 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:05<00:19,  1.37it/s, est. speed input: 769.36 toks/s, output: 48.78 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:10,  2.28it/s, est. speed input: 996.72 toks/s, output: 76.61 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:06<00:08,  2.71it/s, est. speed input: 1073.37 toks/s, output: 91.37 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:06<00:06,  3.63it/s, est. speed input: 1289.53 toks/s, output: 122.33 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:06<00:04,  4.13it/s, est. speed input: 1504.15 toks/s, output: 155.57 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:04,  3.95it/s, est. speed input: 1558.46 toks/s, output: 172.20 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:07<00:04,  4.14it/s, est. speed input: 1711.64 toks/s, output: 209.91 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:07<00:02,  5.45it/s, est. speed input: 1885.26 toks/s, output: 257.30 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:08<00:02,  5.30it/s, est. speed input: 1969.49 toks/s, output: 277.87 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:08<00:01,  8.67it/s, est. speed input: 2351.36 toks/s, output: 380.41 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:08<00:00,  7.95it/s, est. speed input: 2573.99 toks/s, output: 446.54 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:09<00:00,  7.68it/s, est. speed input: 2696.96 toks/s, output: 493.95 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:09<00:00,  7.18it/s, est. speed input: 2743.77 toks/s, output: 516.42 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:09<00:00,  4.16it/s, est. speed input: 2625.18 toks/s, output: 515.86 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:10<00:00,  2.61it/s, est. speed input: 2488.63 toks/s, output: 510.78 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:58<00:11, 11.07s/it, est. speed input: 475.68 toks/s, output: 165.34 toks/s] Processed prompts: 100%|██████████| 32/32 [00:58<00:00,  1.82s/it, est. speed input: 485.10 toks/s, output: 235.68 toks/s]
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:24:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:17,  6.37s/it, est. speed input: 184.42 toks/s, output: 7.53 toks/s]Processed prompts:   6%|▋         | 2/32 [00:06<01:22,  2.76s/it, est. speed input: 325.75 toks/s, output: 16.52 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:29,  1.07s/it, est. speed input: 655.51 toks/s, output: 35.73 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:22,  1.22it/s, est. speed input: 798.20 toks/s, output: 46.36 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:12,  2.04it/s, est. speed input: 1065.63 toks/s, output: 70.75 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:07<00:04,  4.38it/s, est. speed input: 1585.42 toks/s, output: 124.98 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:03,  5.28it/s, est. speed input: 1826.69 toks/s, output: 152.08 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:07<00:02,  5.96it/s, est. speed input: 1987.97 toks/s, output: 180.72 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:07<00:01,  8.94it/s, est. speed input: 2483.16 toks/s, output: 246.17 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:08<00:01,  7.83it/s, est. speed input: 2641.01 toks/s, output: 274.48 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:08<00:01,  7.67it/s, est. speed input: 2802.41 toks/s, output: 307.95 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:08<00:01,  6.83it/s, est. speed input: 2905.79 toks/s, output: 340.68 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:10<00:01,  3.94it/s, est. speed input: 2798.62 toks/s, output: 355.74 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:10<00:01,  2.97it/s, est. speed input: 2712.02 toks/s, output: 363.07 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:11<00:01,  2.54it/s, est. speed input: 2616.06 toks/s, output: 377.54 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:13<00:01,  1.21it/s, est. speed input: 2260.59 toks/s, output: 354.20 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:14<00:00,  1.18it/s, est. speed input: 2203.82 toks/s, output: 376.06 toks/s]Processed prompts: 100%|██████████| 32/32 [00:17<00:00,  1.34s/it, est. speed input: 1930.71 toks/s, output: 365.96 toks/s]Processed prompts: 100%|██████████| 32/32 [00:17<00:00,  1.82it/s, est. speed input: 1930.71 toks/s, output: 365.96 toks/s]
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:25:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<02:46,  5.37s/it, est. speed input: 255.57 toks/s, output: 2.23 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:15,  2.51s/it, est. speed input: 468.52 toks/s, output: 9.17 toks/s]Processed prompts:   9%|▉         | 3/32 [00:06<00:46,  1.62s/it, est. speed input: 559.02 toks/s, output: 19.89 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:33,  1.19s/it, est. speed input: 665.87 toks/s, output: 33.54 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:09,  2.49it/s, est. speed input: 1215.02 toks/s, output: 94.47 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:07<00:06,  3.21it/s, est. speed input: 1433.15 toks/s, output: 125.87 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:07<00:05,  3.59it/s, est. speed input: 1484.55 toks/s, output: 142.38 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:03,  4.94it/s, est. speed input: 1590.81 toks/s, output: 178.50 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:07<00:01,  8.50it/s, est. speed input: 2096.86 toks/s, output: 254.01 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:02,  5.29it/s, est. speed input: 2119.87 toks/s, output: 276.43 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:09<00:02,  5.00it/s, est. speed input: 2290.35 toks/s, output: 314.40 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:03,  3.32it/s, est. speed input: 2156.61 toks/s, output: 318.66 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:11<00:05,  1.77it/s, est. speed input: 1911.24 toks/s, output: 308.09 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:11<00:03,  2.06it/s, est. speed input: 1965.76 toks/s, output: 339.29 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:12<00:03,  2.05it/s, est. speed input: 1958.14 toks/s, output: 363.50 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:13<00:02,  1.84it/s, est. speed input: 1925.55 toks/s, output: 405.39 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:14<00:03,  1.33it/s, est. speed input: 1828.99 toks/s, output: 409.76 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:17<00:03,  1.12s/it, est. speed input: 1634.76 toks/s, output: 404.27 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:19<00:02,  1.36s/it, est. speed input: 1531.19 toks/s, output: 412.67 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:59<00:11, 11.79s/it, est. speed input: 516.06 toks/s, output: 202.47 toks/s] Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  1.86s/it, est. speed input: 533.44 toks/s, output: 271.16 toks/s]
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:26:02 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<03:05,  5.99s/it, est. speed input: 233.87 toks/s, output: 11.69 toks/s]Processed prompts:   6%|▋         | 2/32 [00:06<01:16,  2.55s/it, est. speed input: 295.88 toks/s, output: 24.17 toks/s]Processed prompts:   9%|▉         | 3/32 [00:06<00:42,  1.48s/it, est. speed input: 502.29 toks/s, output: 37.60 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:26,  1.05it/s, est. speed input: 640.72 toks/s, output: 51.99 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:06<00:12,  2.05it/s, est. speed input: 760.77 toks/s, output: 82.32 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:10,  2.47it/s, est. speed input: 835.60 toks/s, output: 97.57 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:06,  3.43it/s, est. speed input: 1019.15 toks/s, output: 130.40 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:04,  4.79it/s, est. speed input: 1273.80 toks/s, output: 182.66 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:07<00:02,  7.24it/s, est. speed input: 1633.09 toks/s, output: 244.79 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:07<00:01,  9.77it/s, est. speed input: 1978.38 toks/s, output: 326.34 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:08<00:01,  5.91it/s, est. speed input: 2047.72 toks/s, output: 347.16 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:10<00:03,  2.86it/s, est. speed input: 1876.05 toks/s, output: 353.10 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:11<00:03,  2.30it/s, est. speed input: 1779.64 toks/s, output: 361.62 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:12<00:02,  2.10it/s, est. speed input: 1837.56 toks/s, output: 402.99 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:12<00:02,  2.22it/s, est. speed input: 1897.46 toks/s, output: 433.61 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:13<00:01,  2.04it/s, est. speed input: 1907.94 toks/s, output: 455.34 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:24<00:08,  3.00s/it, est. speed input: 1075.34 toks/s, output: 301.07 toks/s]Processed prompts:  94%|█████████▍| 30/32 [01:00<00:21, 10.80s/it, est. speed input: 470.46 toks/s, output: 193.53 toks/s] Processed prompts: 100%|██████████| 32/32 [01:00<00:00,  1.88s/it, est. speed input: 495.51 toks/s, output: 330.06 toks/s]
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:03 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:04<02:10,  4.20s/it, est. speed input: 231.81 toks/s, output: 3.33 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:14,  2.47s/it, est. speed input: 231.56 toks/s, output: 18.84 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:05<00:28,  1.01s/it, est. speed input: 445.75 toks/s, output: 51.98 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:05<00:19,  1.37it/s, est. speed input: 531.93 toks/s, output: 70.23 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:06<00:09,  2.66it/s, est. speed input: 775.27 toks/s, output: 125.71 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:06<00:04,  4.32it/s, est. speed input: 1042.06 toks/s, output: 187.66 toks/s]Processed prompts:  41%|████      | 13/32 [00:06<00:04,  4.57it/s, est. speed input: 1191.56 toks/s, output: 224.89 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:06<00:02,  5.91it/s, est. speed input: 1362.33 toks/s, output: 271.44 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:07<00:02,  6.43it/s, est. speed input: 1628.57 toks/s, output: 315.45 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:07<00:01,  6.92it/s, est. speed input: 1863.17 toks/s, output: 360.68 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:07<00:01,  7.96it/s, est. speed input: 1996.90 toks/s, output: 409.98 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:07<00:01,  6.20it/s, est. speed input: 2065.62 toks/s, output: 443.47 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:08<00:01,  6.64it/s, est. speed input: 2285.20 toks/s, output: 493.54 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:08<00:00,  6.20it/s, est. speed input: 2363.70 toks/s, output: 538.22 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:09<00:00,  4.08it/s, est. speed input: 2327.54 toks/s, output: 557.86 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00,  1.44it/s, est. speed input: 1881.25 toks/s, output: 484.80 toks/s]Processed prompts: 100%|██████████| 32/32 [00:13<00:00,  1.68it/s, est. speed input: 1903.16 toks/s, output: 529.04 toks/s]Processed prompts: 100%|██████████| 32/32 [00:13<00:00,  2.44it/s, est. speed input: 1903.16 toks/s, output: 529.04 toks/s]
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:16 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:42,  7.19s/it, est. speed input: 149.43 toks/s, output: 12.80 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:57,  1.97s/it, est. speed input: 376.90 toks/s, output: 39.31 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:38,  1.37s/it, est. speed input: 413.91 toks/s, output: 54.02 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:08<00:28,  1.06s/it, est. speed input: 515.88 toks/s, output: 69.37 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:08<00:14,  1.73it/s, est. speed input: 769.48 toks/s, output: 105.42 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:08,  2.60it/s, est. speed input: 1053.24 toks/s, output: 141.38 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:07,  3.02it/s, est. speed input: 1132.35 toks/s, output: 159.58 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:08<00:04,  4.04it/s, est. speed input: 1310.31 toks/s, output: 197.21 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:04,  4.32it/s, est. speed input: 1522.12 toks/s, output: 233.28 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:03,  4.56it/s, est. speed input: 1642.35 toks/s, output: 253.34 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:09<00:02,  5.71it/s, est. speed input: 1785.30 toks/s, output: 297.52 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:09<00:01,  7.52it/s, est. speed input: 1992.62 toks/s, output: 344.93 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:09<00:01,  8.81it/s, est. speed input: 2124.95 toks/s, output: 391.44 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:10<00:01,  8.57it/s, est. speed input: 2306.08 toks/s, output: 435.79 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:10<00:00,  7.47it/s, est. speed input: 2394.94 toks/s, output: 478.51 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:11<00:01,  4.79it/s, est. speed input: 2329.94 toks/s, output: 485.82 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:11<00:01,  4.22it/s, est. speed input: 2362.54 toks/s, output: 503.16 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:11<00:00,  4.03it/s, est. speed input: 2424.73 toks/s, output: 523.93 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:12<00:00,  3.46it/s, est. speed input: 2423.32 toks/s, output: 540.47 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:12<00:00,  3.56it/s, est. speed input: 2513.71 toks/s, output: 587.12 toks/s]Processed prompts: 100%|██████████| 32/32 [00:14<00:00,  1.61it/s, est. speed input: 2289.64 toks/s, output: 556.50 toks/s]Processed prompts: 100%|██████████| 32/32 [00:14<00:00,  2.22it/s, est. speed input: 2289.64 toks/s, output: 556.50 toks/s]
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:31 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:32,  6.85s/it, est. speed input: 78.83 toks/s, output: 8.61 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:27,  2.92s/it, est. speed input: 196.32 toks/s, output: 18.22 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:49,  1.71s/it, est. speed input: 292.23 toks/s, output: 29.11 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:21,  1.26it/s, est. speed input: 537.61 toks/s, output: 52.48 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:11,  2.17it/s, est. speed input: 890.95 toks/s, output: 78.32 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:06,  3.32it/s, est. speed input: 1144.57 toks/s, output: 105.19 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:05,  3.55it/s, est. speed input: 1321.77 toks/s, output: 129.79 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:08<00:03,  5.62it/s, est. speed input: 1748.94 toks/s, output: 179.67 toks/s]Processed prompts:  50%|█████     | 16/32 [00:08<00:02,  6.00it/s, est. speed input: 1904.79 toks/s, output: 211.03 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:09<00:02,  4.95it/s, est. speed input: 2061.14 toks/s, output: 241.64 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:09<00:01,  5.77it/s, est. speed input: 2370.92 toks/s, output: 299.17 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:01,  6.08it/s, est. speed input: 2419.94 toks/s, output: 320.02 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:09<00:01,  6.43it/s, est. speed input: 2553.52 toks/s, output: 360.88 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:10<00:01,  5.86it/s, est. speed input: 2596.80 toks/s, output: 379.19 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:10<00:01,  5.79it/s, est. speed input: 2667.32 toks/s, output: 400.10 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:10<00:01,  4.72it/s, est. speed input: 2675.19 toks/s, output: 416.16 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:12<00:02,  1.42it/s, est. speed input: 2319.96 toks/s, output: 381.02 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:14<00:02,  1.08it/s, est. speed input: 2143.79 toks/s, output: 380.81 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:14<00:01,  1.35it/s, est. speed input: 2167.01 toks/s, output: 416.29 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:16<00:01,  1.01s/it, est. speed input: 2024.81 toks/s, output: 418.18 toks/s]Processed prompts: 100%|██████████| 32/32 [00:18<00:00,  1.37s/it, est. speed input: 1850.86 toks/s, output: 416.42 toks/s]Processed prompts: 100%|██████████| 32/32 [00:18<00:00,  1.71it/s, est. speed input: 1850.86 toks/s, output: 416.42 toks/s]
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:27:51 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:07,  6.04s/it, est. speed input: 194.55 toks/s, output: 18.88 toks/s]Processed prompts:   9%|▉         | 3/32 [00:06<00:46,  1.61s/it, est. speed input: 516.59 toks/s, output: 57.47 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:22,  1.22it/s, est. speed input: 748.00 toks/s, output: 96.60 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:06<00:13,  1.91it/s, est. speed input: 951.36 toks/s, output: 136.76 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:06<00:05,  3.83it/s, est. speed input: 1489.33 toks/s, output: 222.16 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:06<00:03,  5.49it/s, est. speed input: 1792.23 toks/s, output: 287.85 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:07<00:01,  8.81it/s, est. speed input: 2474.34 toks/s, output: 400.03 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:07<00:01,  9.83it/s, est. speed input: 2700.35 toks/s, output: 464.50 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:07<00:00,  9.33it/s, est. speed input: 2768.32 toks/s, output: 503.23 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:08<00:01,  4.77it/s, est. speed input: 2579.42 toks/s, output: 500.74 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:15<00:03,  1.03it/s, est. speed input: 1563.84 toks/s, output: 358.00 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:45<00:16,  5.50s/it, est. speed input: 527.69 toks/s, output: 185.68 toks/s] Processed prompts:  94%|█████████▍| 30/32 [00:59<00:13,  6.86s/it, est. speed input: 418.07 toks/s, output: 213.65 toks/s]Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  1.84s/it, est. speed input: 445.15 toks/s, output: 352.45 toks/s]
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:28:50 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<03:00,  5.81s/it, est. speed input: 144.28 toks/s, output: 10.16 toks/s]Processed prompts:   6%|▋         | 2/32 [00:05<01:14,  2.49s/it, est. speed input: 280.47 toks/s, output: 21.41 toks/s]Processed prompts:   9%|▉         | 3/32 [00:06<00:44,  1.54s/it, est. speed input: 379.78 toks/s, output: 34.60 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:27,  1.01it/s, est. speed input: 519.82 toks/s, output: 49.38 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:06<00:19,  1.39it/s, est. speed input: 612.23 toks/s, output: 64.78 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:15,  1.63it/s, est. speed input: 708.84 toks/s, output: 80.65 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:11,  2.17it/s, est. speed input: 790.08 toks/s, output: 99.32 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:08,  2.85it/s, est. speed input: 875.00 toks/s, output: 118.73 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:06,  3.61it/s, est. speed input: 1003.87 toks/s, output: 138.50 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:07<00:04,  4.92it/s, est. speed input: 1187.51 toks/s, output: 178.32 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:03,  5.33it/s, est. speed input: 1250.72 toks/s, output: 198.67 toks/s]Processed prompts:  41%|████      | 13/32 [00:08<00:03,  5.44it/s, est. speed input: 1348.23 toks/s, output: 218.85 toks/s]Processed prompts:  50%|█████     | 16/32 [00:08<00:02,  7.69it/s, est. speed input: 1584.88 toks/s, output: 286.01 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:01,  8.87it/s, est. speed input: 1816.91 toks/s, output: 354.23 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:08<00:01,  8.75it/s, est. speed input: 1939.55 toks/s, output: 399.34 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:01,  5.70it/s, est. speed input: 1990.50 toks/s, output: 409.28 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:09<00:01,  5.83it/s, est. speed input: 2140.48 toks/s, output: 455.72 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:11<00:03,  2.10it/s, est. speed input: 1918.24 toks/s, output: 422.72 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:11<00:02,  2.34it/s, est. speed input: 1986.63 toks/s, output: 451.90 toks/s]Processed prompts:  84%|████████▍ | 27/32 [01:03<01:02, 12.55s/it, est. speed input: 381.81 toks/s, output: 146.75 toks/s] Processed prompts: 100%|██████████| 32/32 [01:03<00:00,  2.00s/it, est. speed input: 466.37 toks/s, output: 467.27 toks/s]
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 19:29:54 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:03<01:14,  3.94s/it, est. speed input: 139.49 toks/s, output: 14.48 toks/s]Processed prompts:  10%|█         | 2/20 [00:04<00:30,  1.68s/it, est. speed input: 452.36 toks/s, output: 29.93 toks/s]Processed prompts:  20%|██        | 4/20 [00:04<00:11,  1.40it/s, est. speed input: 652.36 toks/s, output: 62.27 toks/s]Processed prompts:  25%|██▌       | 5/20 [00:04<00:08,  1.82it/s, est. speed input: 931.16 toks/s, output: 80.67 toks/s]Processed prompts:  30%|███       | 6/20 [00:04<00:06,  2.32it/s, est. speed input: 1056.02 toks/s, output: 100.33 toks/s]Processed prompts:  35%|███▌      | 7/20 [00:04<00:05,  2.56it/s, est. speed input: 1269.87 toks/s, output: 119.57 toks/s]Processed prompts:  40%|████      | 8/20 [00:05<00:05,  2.22it/s, est. speed input: 1269.41 toks/s, output: 136.54 toks/s]Processed prompts:  50%|█████     | 10/20 [00:05<00:03,  3.00it/s, est. speed input: 1646.56 toks/s, output: 187.68 toks/s]Processed prompts:  55%|█████▌    | 11/20 [00:06<00:02,  3.45it/s, est. speed input: 1693.51 toks/s, output: 216.03 toks/s]Processed prompts:  65%|██████▌   | 13/20 [00:06<00:01,  4.62it/s, est. speed input: 1950.68 toks/s, output: 275.87 toks/s]Processed prompts:  75%|███████▌  | 15/20 [00:06<00:00,  5.99it/s, est. speed input: 2278.26 toks/s, output: 338.78 toks/s]Processed prompts:  85%|████████▌ | 17/20 [00:06<00:00,  7.20it/s, est. speed input: 2443.98 toks/s, output: 401.98 toks/s]Processed prompts:  90%|█████████ | 18/20 [00:07<00:00,  2.92it/s, est. speed input: 2180.17 toks/s, output: 384.98 toks/s]Processed prompts:  95%|█████████▌| 19/20 [00:10<00:00,  1.19it/s, est. speed input: 1712.02 toks/s, output: 340.98 toks/s]Processed prompts: 100%|██████████| 20/20 [00:56<00:00, 11.61s/it, est. speed input: 342.17 toks/s, output: 136.27 toks/s] Processed prompts: 100%|██████████| 20/20 [00:56<00:00,  2.81s/it, est. speed input: 342.17 toks/s, output: 136.27 toks/s]
[rank0]:[W117 19:30:51.009841970 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
input_file results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results.json
output_dir results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct_checker
  0%|          | 0/25 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct_checker/HR_7.py", line 14, in <module>
    ax.plot(user_values, utility_values, 'b-')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (11,) and (10,)
 24%|██▍       | 6/25 [00:01<00:03,  4.94it/s]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct_checker/heatmap_11.py:8: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('viridis')
 64%|██████▍   | 16/25 [00:02<00:01,  7.10it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct_checker/line_56.py", line 11, in <module>
    axs[0].plot(x, y1, 'r-')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (9,) and (10,)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct_checker/line_14.py", line 8, in <module>
    plt.plot(x, y1, 'r-')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/pyplot.py", line 3590, in plot
    return gca().plot(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (28,) and (27,)
 68%|██████▊   | 17/25 [00:03<00:01,  4.75it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct_checker/errorbar_18.py", line 9, in <module>
    plt.bar(labels, emissions, color=colors)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/pyplot.py", line 2754, in bar
    return gca().bar(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (4,) and arg 1 with shape (6,).
 76%|███████▌  | 19/25 [00:04<00:01,  3.70it/s] 80%|████████  | 20/25 [00:05<00:01,  2.99it/s] 84%|████████▍ | 21/25 [00:05<00:01,  2.54it/s] 96%|█████████▌| 24/25 [00:06<00:00,  2.86it/s]100%|██████████| 25/25 [00:06<00:00,  3.79it/s]
Total Python Files 72
Total PDF Files 68
input_file results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results.json
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:00<00:45,  1.08it/s]  4%|▍         | 2/50 [00:01<00:46,  1.02it/s]  6%|▌         | 3/50 [00:02<00:47,  1.01s/it]  8%|▊         | 4/50 [00:04<00:47,  1.03s/it] 10%|█         | 5/50 [00:05<00:48,  1.07s/it] 12%|█▏        | 6/50 [00:06<00:50,  1.15s/it] 14%|█▍        | 7/50 [00:07<00:49,  1.14s/it] 16%|█▌        | 8/50 [00:08<00:49,  1.19s/it] 18%|█▊        | 9/50 [00:10<00:48,  1.17s/it] 20%|██        | 10/50 [00:11<00:46,  1.17s/it] 22%|██▏       | 11/50 [00:12<00:51,  1.31s/it] 24%|██▍       | 12/50 [00:14<00:49,  1.30s/it] 26%|██▌       | 13/50 [00:15<00:48,  1.31s/it] 28%|██▊       | 14/50 [00:16<00:45,  1.28s/it] 30%|███       | 15/50 [00:17<00:41,  1.18s/it] 32%|███▏      | 16/50 [00:18<00:41,  1.22s/it] 34%|███▍      | 17/50 [00:20<00:40,  1.24s/it] 36%|███▌      | 18/50 [00:21<00:40,  1.26s/it] 38%|███▊      | 19/50 [00:22<00:37,  1.22s/it] 40%|████      | 20/50 [00:23<00:35,  1.19s/it] 42%|████▏     | 21/50 [00:25<00:35,  1.24s/it] 44%|████▍     | 22/50 [00:26<00:32,  1.18s/it] 46%|████▌     | 23/50 [00:27<00:31,  1.18s/it] 48%|████▊     | 24/50 [00:28<00:31,  1.21s/it] 50%|█████     | 25/50 [00:29<00:30,  1.23s/it] 52%|█████▏    | 26/50 [00:31<00:30,  1.26s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_11.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('viridis')
 54%|█████▍    | 27/50 [00:32<00:29,  1.28s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_11.py:9: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.
  cmap = plt.cm.get_cmap('viridis')
 56%|█████▌    | 28/50 [00:33<00:28,  1.31s/it] 58%|█████▊    | 29/50 [00:35<00:26,  1.25s/it] 60%|██████    | 30/50 [00:36<00:26,  1.30s/it] 62%|██████▏   | 31/50 [00:37<00:25,  1.34s/it] 64%|██████▍   | 32/50 [00:39<00:23,  1.31s/it] 66%|██████▌   | 33/50 [00:40<00:23,  1.40s/it] 68%|██████▊   | 34/50 [00:41<00:21,  1.35s/it] 70%|███████   | 35/50 [00:43<00:19,  1.29s/it] 72%|███████▏  | 36/50 [00:44<00:16,  1.18s/it] 74%|███████▍  | 37/50 [00:45<00:15,  1.21s/it] 76%|███████▌  | 38/50 [00:46<00:14,  1.20s/it] 78%|███████▊  | 39/50 [00:48<00:14,  1.29s/it] 80%|████████  | 40/50 [00:49<00:13,  1.36s/it] 82%|████████▏ | 41/50 [00:50<00:12,  1.37s/it] 84%|████████▍ | 42/50 [00:52<00:10,  1.33s/it] 86%|████████▌ | 43/50 [00:53<00:08,  1.28s/it] 88%|████████▊ | 44/50 [00:54<00:07,  1.23s/it] 90%|█████████ | 45/50 [00:55<00:06,  1.21s/it] 92%|█████████▏| 46/50 [00:56<00:04,  1.19s/it] 94%|█████████▍| 47/50 [00:58<00:03,  1.27s/it] 96%|█████████▌| 48/50 [00:59<00:02,  1.27s/it] 98%|█████████▊| 49/50 [01:00<00:01,  1.23s/it]100%|██████████| 50/50 [01:01<00:00,  1.18s/it]100%|██████████| 50/50 [01:01<00:00,  1.23s/it]
args.tasks ['code4evaluation']
args.model pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000
result file: ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results_code4evaluation.json
original_dataset_dir:  ./dataset/ori_500
generated_dataset_dir:  ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results
len dataset: 500
  0%|          | 0/25 [00:00<?, ?it/s]cmap is used viridis
  4%|▍         | 1/25 [00:15<06:02, 15.11s/it]cmap is used viridis
cmap is used viridis
cmap is used viridis
cmap is used viridis
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/graph_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_47.py
  8%|▊         | 2/25 [00:30<05:54, 15.40s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_67.py
 12%|█▏        | 3/25 [00:49<06:10, 16.82s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_25.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_14.py
 16%|█▌        | 4/25 [01:04<05:42, 16.30s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_65.py
 20%|██        | 5/25 [01:21<05:27, 16.36s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_26.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_41.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_48.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_28.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_80.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_44.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/tree_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_43.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_33.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_78.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_98.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_68.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_15.py
 24%|██▍       | 6/25 [01:36<05:02, 15.90s/it]cmap is used <matplotlib.colors.LinearSegmentedColormap object at 0x7dca0a783b50>
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_texts.py:54: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_chart_types.py:375: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_colors.py:766: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_38.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_60.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_69.py
 28%|██▊       | 7/25 [01:52<04:48, 16.04s/it]/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_layouts.py:31: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_22.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_15.py
 32%|███▏      | 8/25 [02:06<04:23, 15.48s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_39.py
 36%|███▌      | 9/25 [02:23<04:15, 15.97s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_92.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_85.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_57.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_25.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_26.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_25.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/tree_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/tree_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_70.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_46.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_27.py
cmap is used viridis
cmap is used viridis
cmap is used viridis
 40%|████      | 10/25 [02:43<04:16, 17.10s/it]cmap is used viridis
cmap is used magma
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_44.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_22.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_30.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_23.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_53.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_10.py
cmap is used viridis
 44%|████▍     | 11/25 [02:59<03:55, 16.83s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_41.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_83.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_21.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_74.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_25.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_38.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_67.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_97.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_73.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/area_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/area_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_42.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_75.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_45.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_32.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/density_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/contour_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_56.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_100.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/density_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_3.py
 48%|████▊     | 12/25 [03:17<03:43, 17.16s/it]cmap is used spring
cmap is used spring
cmap is used spring
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_68.py
 52%|█████▏    | 13/25 [03:36<03:31, 17.61s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_61.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_55.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_27.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/area_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/contour_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_24.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_23.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_63.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_70.py
 56%|█████▌    | 14/25 [03:53<03:11, 17.41s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_25.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_25.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_22.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_61.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/graph_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_4.py
 60%|██████    | 15/25 [04:10<02:52, 17.30s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_94.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_21.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_30.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_23.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_8.py
 64%|██████▍   | 16/25 [04:27<02:36, 17.39s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_78.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_22.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_21.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_23.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_60.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_3.py
 68%|██████▊   | 17/25 [04:42<02:12, 16.62s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_53.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_79.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_9.py
 72%|███████▏  | 18/25 [05:01<02:01, 17.30s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_30.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_25.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_25.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_65.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_66.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_29.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_69.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_24.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_77.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_55.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_51.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_23.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_34.py
 76%|███████▌  | 19/25 [05:15<01:38, 16.43s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_76.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_77.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_96.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_26.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_64.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/density_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_30.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_73.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_62.py
 80%|████████  | 20/25 [05:34<01:25, 17.13s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_50.py
 84%|████████▍ | 21/25 [05:49<01:05, 16.34s/it]cmap is used autumn
 88%|████████▊ | 22/25 [06:05<00:48, 16.22s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_36.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_23.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_28.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_52.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_24.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_49.py
 92%|█████████▏| 23/25 [06:22<00:33, 16.59s/it]cmap is used nipy_spectral
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_86.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_63.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_88.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_34.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_56.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_26.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_29.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_79.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_81.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_71.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_4.py
cmap is used jet
cmap is used jet
 96%|█████████▌| 24/25 [06:41<00:17, 17.19s/it]genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_28.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_57.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/graph_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_74.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_29.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_21.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_36.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_32.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_40.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_49.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_72.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_66.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_48.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_45.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_28.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_58.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_33.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/contour_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_37.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_50.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/density_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/contour_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_25.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_24.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_51.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_21.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/tree_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_22.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_27.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_30.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_31.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_27.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_31.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_35.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_64.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_76.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_82.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_40.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_29.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_28.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_54.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/graph_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_59.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/tree_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_90.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_93.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_26.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_84.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_39.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_21.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_59.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_62.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_24.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_23.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_42.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_54.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/graph_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_21.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/density_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_24.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_23.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_21.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_24.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_22.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_6.py
100%|██████████| 25/25 [06:55<00:00, 16.29s/it]100%|██████████| 25/25 [06:55<00:00, 16.62s/it]
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_87.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_22.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_35.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_80.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_24.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_72.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_17.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_8.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_9.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_71.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_5.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_95.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_27.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_22.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_14.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_11.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_43.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_75.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_18.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_52.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_46.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_47.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_20.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_99.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_58.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_13.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_6.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_29.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/contour_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_3.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/area_2.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_37.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_7.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_22.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_15.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_89.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_10.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_23.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/area_1.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_19.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_16.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_24.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_4.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_12.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_91.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_21.py
genearion_code_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_5.py
self.results_file ./results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results_code4evaluation.json
Time taken:  430.3455023765564
args.tasks ['gpt4evaluation']
args.model pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_60.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/area_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_39.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_86.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_36.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_56.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_33.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_24.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/area_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/density_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_25.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_24.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_69.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_52.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_92.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_95.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_38.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_22.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_52.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_31.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_24.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_43.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_21.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_78.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_26.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_100.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_70.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/tree_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_83.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_38.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_63.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/graph_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_23.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_42.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_54.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_22.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/tree_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_66.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_88.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_24.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_78.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_28.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_45.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_58.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_21.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/graph_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_97.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_59.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_25.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_72.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_72.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_61.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_21.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_79.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_32.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_46.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_90.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_62.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/density_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_31.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_21.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_46.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_56.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_29.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_57.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_21.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_24.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/graph_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_79.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_23.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_30.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_61.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_70.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_24.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_23.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_55.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_84.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/tree_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_27.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_27.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/contour_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_25.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_29.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_25.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_23.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/area_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_57.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_50.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/contour_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_73.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_48.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_23.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_28.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/graph_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_22.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_30.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_34.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_35.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_24.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_75.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_41.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_35.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_23.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_44.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_43.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_68.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_37.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_42.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_33.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_25.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_24.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_21.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_24.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_71.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_89.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_25.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_22.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_34.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_94.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_30.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_32.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_93.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_67.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_87.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_30.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_74.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_48.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_51.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_80.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_54.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_62.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_49.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_25.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_64.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_22.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_26.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_73.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_26.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_50.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_91.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/density_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_68.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_23.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/area_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_41.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_69.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_22.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/density_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_63.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_25.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_59.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_75.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_85.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_27.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_60.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_22.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_26.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_10.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_65.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_21.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_22.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_29.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_96.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_30.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_25.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/contour_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_58.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/tree_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_76.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/contour_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_99.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_15.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_18.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_77.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_66.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_27.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_82.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_74.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/density_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_71.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_27.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_28.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_28.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_23.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_47.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_65.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/tree_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_77.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_53.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_53.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_17.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_29.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_21.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_81.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_21.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_51.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_49.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_47.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_44.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_29.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_36.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_3.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_37.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/contour_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_19.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/3d_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_13.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_20.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/graph_5.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_12.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_2.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_45.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_14.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_28.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_76.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_80.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/pie_11.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_39.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_40.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_22.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_6.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_7.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_40.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_98.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_26.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_9.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/violin_8.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_1.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_64.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_55.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_16.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_4.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_23.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_67.pdf
Converting pdf to png:  results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/area_1.pdf
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:03<25:15,  3.04s/it]  0%|          | 2/500 [00:06<25:05,  3.02s/it]  1%|          | 3/500 [00:09<25:00,  3.02s/it]  1%|          | 4/500 [00:12<24:58,  3.02s/it]  1%|          | 5/500 [00:15<25:05,  3.04s/it]  1%|          | 6/500 [00:15<17:15,  2.10s/it]  1%|▏         | 7/500 [00:18<19:55,  2.43s/it]  2%|▏         | 8/500 [00:21<21:37,  2.64s/it]  2%|▏         | 9/500 [00:24<22:55,  2.80s/it]  2%|▏         | 10/500 [00:27<23:27,  2.87s/it]  2%|▏         | 11/500 [00:30<23:52,  2.93s/it]  2%|▏         | 12/500 [00:33<24:07,  2.97s/it]  3%|▎         | 13/500 [00:36<24:20,  3.00s/it]  3%|▎         | 14/500 [00:40<24:29,  3.02s/it]  3%|▎         | 15/500 [00:43<24:35,  3.04s/it]  3%|▎         | 16/500 [00:46<24:37,  3.05s/it]  3%|▎         | 17/500 [00:46<17:26,  2.17s/it]  4%|▎         | 18/500 [00:49<19:36,  2.44s/it]  4%|▍         | 19/500 [00:52<21:02,  2.63s/it]  4%|▍         | 20/500 [00:55<22:06,  2.76s/it]  4%|▍         | 21/500 [00:58<22:46,  2.85s/it]  4%|▍         | 22/500 [01:01<23:08,  2.90s/it]  5%|▍         | 23/500 [01:04<23:21,  2.94s/it]  5%|▍         | 24/500 [01:04<16:42,  2.11s/it]  5%|▌         | 25/500 [01:07<18:50,  2.38s/it]  5%|▌         | 26/500 [01:10<20:20,  2.57s/it]  5%|▌         | 27/500 [01:13<21:23,  2.71s/it]  6%|▌         | 28/500 [01:16<22:01,  2.80s/it]  6%|▌         | 29/500 [01:19<22:31,  2.87s/it]  6%|▌         | 30/500 [01:22<22:52,  2.92s/it]  6%|▌         | 31/500 [01:26<23:06,  2.96s/it]  6%|▋         | 32/500 [01:26<16:24,  2.10s/it]  7%|▋         | 33/500 [01:29<18:24,  2.37s/it]  7%|▋         | 34/500 [01:32<19:54,  2.56s/it]  7%|▋         | 35/500 [01:35<20:54,  2.70s/it]  7%|▋         | 36/500 [01:38<21:29,  2.78s/it]  7%|▋         | 37/500 [01:41<22:02,  2.86s/it]  8%|▊         | 38/500 [01:44<22:21,  2.90s/it]  8%|▊         | 39/500 [01:47<22:37,  2.95s/it]  8%|▊         | 40/500 [01:50<22:44,  2.97s/it]  8%|▊         | 41/500 [01:53<22:48,  2.98s/it]  8%|▊         | 42/500 [01:56<22:44,  2.98s/it]  9%|▊         | 43/500 [01:59<22:44,  2.99s/it]  9%|▉         | 44/500 [02:06<33:28,  4.40s/it]  9%|▉         | 45/500 [02:09<30:11,  3.98s/it]  9%|▉         | 46/500 [02:12<27:50,  3.68s/it]  9%|▉         | 47/500 [02:15<26:13,  3.47s/it] 10%|▉         | 48/500 [02:18<25:04,  3.33s/it] 10%|▉         | 49/500 [02:21<24:11,  3.22s/it] 10%|█         | 50/500 [02:24<23:49,  3.18s/it] 10%|█         | 51/500 [02:27<23:24,  3.13s/it] 10%|█         | 52/500 [02:30<23:02,  3.09s/it] 11%|█         | 53/500 [02:33<22:51,  3.07s/it] 11%|█         | 54/500 [02:37<22:45,  3.06s/it] 11%|█         | 55/500 [02:37<17:07,  2.31s/it] 11%|█         | 56/500 [02:40<18:48,  2.54s/it] 11%|█▏        | 57/500 [02:43<20:02,  2.71s/it] 12%|█▏        | 58/500 [02:46<20:50,  2.83s/it] 12%|█▏        | 59/500 [02:49<21:27,  2.92s/it] 12%|█▏        | 60/500 [02:53<21:47,  2.97s/it] 12%|█▏        | 61/500 [02:56<22:04,  3.02s/it] 12%|█▏        | 62/500 [02:59<22:12,  3.04s/it] 13%|█▎        | 63/500 [02:59<16:22,  2.25s/it] 13%|█▎        | 64/500 [03:02<18:08,  2.50s/it] 13%|█▎        | 65/500 [03:05<19:30,  2.69s/it] 13%|█▎        | 66/500 [03:08<20:14,  2.80s/it] 13%|█▎        | 67/500 [03:12<20:47,  2.88s/it] 14%|█▎        | 68/500 [03:15<21:11,  2.94s/it] 14%|█▍        | 69/500 [03:18<21:26,  2.98s/it] 14%|█▍        | 70/500 [03:21<21:39,  3.02s/it] 14%|█▍        | 71/500 [03:24<21:58,  3.07s/it] 14%|█▍        | 72/500 [03:27<22:04,  3.09s/it] 15%|█▍        | 73/500 [03:30<21:50,  3.07s/it] 15%|█▍        | 74/500 [03:33<21:44,  3.06s/it] 15%|█▌        | 75/500 [03:36<21:42,  3.07s/it] 15%|█▌        | 76/500 [03:39<21:36,  3.06s/it] 15%|█▌        | 77/500 [03:42<21:36,  3.07s/it] 16%|█▌        | 78/500 [03:45<21:33,  3.06s/it] 16%|█▌        | 79/500 [03:49<21:31,  3.07s/it] 16%|█▌        | 80/500 [03:52<21:29,  3.07s/it] 16%|█▌        | 81/500 [03:55<21:28,  3.08s/it] 16%|█▋        | 82/500 [03:58<21:22,  3.07s/it] 17%|█▋        | 83/500 [04:01<21:23,  3.08s/it] 17%|█▋        | 84/500 [04:04<21:21,  3.08s/it] 17%|█▋        | 85/500 [04:07<21:13,  3.07s/it] 17%|█▋        | 86/500 [04:10<21:06,  3.06s/it] 17%|█▋        | 87/500 [04:13<20:58,  3.05s/it] 18%|█▊        | 88/500 [04:16<20:56,  3.05s/it] 18%|█▊        | 89/500 [04:19<20:53,  3.05s/it] 18%|█▊        | 90/500 [04:19<15:04,  2.21s/it] 18%|█▊        | 91/500 [04:23<16:53,  2.48s/it] 18%|█▊        | 92/500 [04:26<18:07,  2.66s/it] 19%|█▊        | 93/500 [04:29<18:52,  2.78s/it] 19%|█▉        | 94/500 [04:32<19:24,  2.87s/it] 19%|█▉        | 95/500 [04:35<19:45,  2.93s/it] 19%|█▉        | 96/500 [04:38<20:04,  2.98s/it] 19%|█▉        | 97/500 [04:41<20:20,  3.03s/it] 20%|█▉        | 98/500 [04:44<20:24,  3.05s/it] 20%|█▉        | 99/500 [04:47<20:25,  3.06s/it] 20%|██        | 100/500 [04:48<16:26,  2.47s/it] 20%|██        | 101/500 [04:51<17:45,  2.67s/it] 20%|██        | 102/500 [04:55<18:32,  2.79s/it] 21%|██        | 103/500 [04:55<13:29,  2.04s/it] 21%|██        | 104/500 [04:58<15:25,  2.34s/it] 21%|██        | 105/500 [04:58<11:05,  1.68s/it] 21%|██        | 106/500 [05:01<13:49,  2.11s/it] 21%|██▏       | 107/500 [05:04<15:44,  2.40s/it] 22%|██▏       | 108/500 [05:07<17:03,  2.61s/it] 22%|██▏       | 109/500 [05:10<17:50,  2.74s/it] 22%|██▏       | 110/500 [05:13<18:25,  2.83s/it] 22%|██▏       | 111/500 [05:16<18:49,  2.90s/it] 22%|██▏       | 112/500 [05:20<19:07,  2.96s/it] 23%|██▎       | 113/500 [05:23<19:20,  3.00s/it] 23%|██▎       | 114/500 [05:26<19:26,  3.02s/it] 23%|██▎       | 115/500 [05:29<19:24,  3.03s/it] 23%|██▎       | 116/500 [05:32<19:25,  3.04s/it] 23%|██▎       | 117/500 [05:32<14:14,  2.23s/it] 24%|██▎       | 118/500 [05:35<15:47,  2.48s/it] 24%|██▍       | 119/500 [05:38<16:56,  2.67s/it] 24%|██▍       | 120/500 [05:41<17:46,  2.81s/it] 24%|██▍       | 121/500 [05:45<18:17,  2.90s/it] 24%|██▍       | 122/500 [05:48<18:40,  2.96s/it] 25%|██▍       | 123/500 [05:51<18:58,  3.02s/it] 25%|██▍       | 124/500 [05:54<19:02,  3.04s/it] 25%|██▌       | 125/500 [05:57<19:04,  3.05s/it] 25%|██▌       | 126/500 [06:00<19:04,  3.06s/it] 25%|██▌       | 127/500 [06:03<19:04,  3.07s/it] 26%|██▌       | 128/500 [06:06<19:01,  3.07s/it] 26%|██▌       | 129/500 [06:09<18:59,  3.07s/it] 26%|██▌       | 130/500 [06:12<18:58,  3.08s/it] 26%|██▌       | 131/500 [06:15<18:50,  3.06s/it] 26%|██▋       | 132/500 [06:18<18:47,  3.06s/it] 27%|██▋       | 133/500 [06:22<18:43,  3.06s/it] 27%|██▋       | 134/500 [06:25<18:49,  3.09s/it] 27%|██▋       | 135/500 [06:28<18:40,  3.07s/it] 27%|██▋       | 136/500 [06:31<18:38,  3.07s/it] 27%|██▋       | 137/500 [06:34<18:35,  3.07s/it] 28%|██▊       | 138/500 [06:37<18:31,  3.07s/it] 28%|██▊       | 139/500 [06:37<13:42,  2.28s/it] 28%|██▊       | 140/500 [06:40<15:08,  2.52s/it] 28%|██▊       | 141/500 [06:44<16:05,  2.69s/it] 28%|██▊       | 142/500 [06:47<16:42,  2.80s/it] 29%|██▊       | 143/500 [06:50<17:08,  2.88s/it] 29%|██▉       | 144/500 [06:53<17:25,  2.94s/it] 29%|██▉       | 145/500 [06:56<17:40,  2.99s/it] 29%|██▉       | 146/500 [06:59<17:50,  3.02s/it] 29%|██▉       | 147/500 [07:02<17:52,  3.04s/it] 30%|██▉       | 148/500 [07:05<17:53,  3.05s/it] 30%|██▉       | 149/500 [07:08<17:53,  3.06s/it] 30%|███       | 150/500 [07:08<12:57,  2.22s/it] 30%|███       | 151/500 [07:12<14:26,  2.48s/it] 30%|███       | 152/500 [07:15<15:27,  2.67s/it] 31%|███       | 153/500 [07:18<16:08,  2.79s/it] 31%|███       | 154/500 [07:21<16:36,  2.88s/it] 31%|███       | 155/500 [07:24<16:54,  2.94s/it] 31%|███       | 156/500 [07:27<17:02,  2.97s/it] 31%|███▏      | 157/500 [07:30<17:08,  3.00s/it] 32%|███▏      | 158/500 [07:33<17:10,  3.01s/it] 32%|███▏      | 159/500 [07:36<17:11,  3.03s/it] 32%|███▏      | 160/500 [07:39<17:15,  3.05s/it] 32%|███▏      | 161/500 [07:40<12:35,  2.23s/it] 32%|███▏      | 162/500 [07:43<13:56,  2.48s/it] 33%|███▎      | 163/500 [07:46<14:52,  2.65s/it] 33%|███▎      | 164/500 [07:46<10:55,  1.95s/it] 33%|███▎      | 165/500 [07:49<12:47,  2.29s/it] 33%|███▎      | 166/500 [07:52<14:07,  2.54s/it] 33%|███▎      | 167/500 [07:55<14:59,  2.70s/it] 34%|███▎      | 168/500 [07:58<15:28,  2.80s/it] 34%|███▍      | 169/500 [08:01<15:53,  2.88s/it] 34%|███▍      | 170/500 [08:02<11:49,  2.15s/it] 34%|███▍      | 171/500 [08:02<08:40,  1.58s/it] 34%|███▍      | 172/500 [08:05<10:59,  2.01s/it] 35%|███▍      | 173/500 [08:08<12:34,  2.31s/it] 35%|███▍      | 174/500 [08:11<13:39,  2.52s/it] 35%|███▌      | 175/500 [08:14<14:24,  2.66s/it] 35%|███▌      | 176/500 [08:17<14:53,  2.76s/it] 35%|███▌      | 177/500 [08:20<15:14,  2.83s/it] 36%|███▌      | 178/500 [08:20<11:03,  2.06s/it] 36%|███▌      | 179/500 [08:23<12:34,  2.35s/it] 36%|███▌      | 180/500 [08:26<13:42,  2.57s/it] 36%|███▌      | 181/500 [08:27<09:46,  1.84s/it] 36%|███▋      | 182/500 [08:27<07:18,  1.38s/it] 37%|███▋      | 183/500 [08:30<09:53,  1.87s/it] 37%|███▋      | 184/500 [08:33<11:41,  2.22s/it] 37%|███▋      | 185/500 [08:36<12:55,  2.46s/it] 37%|███▋      | 186/500 [08:39<13:46,  2.63s/it] 37%|███▋      | 187/500 [08:42<14:19,  2.74s/it] 38%|███▊      | 188/500 [08:45<14:39,  2.82s/it] 38%|███▊      | 189/500 [08:48<14:55,  2.88s/it] 38%|███▊      | 190/500 [08:51<15:03,  2.91s/it] 38%|███▊      | 191/500 [08:54<15:10,  2.95s/it] 38%|███▊      | 192/500 [08:57<15:13,  2.97s/it] 39%|███▊      | 193/500 [09:00<15:14,  2.98s/it] 39%|███▉      | 194/500 [09:03<15:12,  2.98s/it] 39%|███▉      | 195/500 [09:06<15:10,  2.98s/it] 39%|███▉      | 196/500 [09:09<15:07,  2.99s/it] 39%|███▉      | 197/500 [09:10<11:56,  2.36s/it] 40%|███▉      | 198/500 [09:10<08:43,  1.73s/it] 40%|███▉      | 199/500 [09:13<10:37,  2.12s/it] 40%|████      | 200/500 [09:16<11:53,  2.38s/it] 40%|████      | 201/500 [09:19<12:46,  2.56s/it] 40%|████      | 202/500 [09:22<13:23,  2.70s/it] 41%|████      | 203/500 [09:25<13:48,  2.79s/it] 41%|████      | 204/500 [09:26<10:16,  2.08s/it] 41%|████      | 205/500 [09:29<11:37,  2.36s/it] 41%|████      | 206/500 [09:32<12:34,  2.57s/it] 41%|████▏     | 207/500 [09:35<13:10,  2.70s/it] 42%|████▏     | 208/500 [09:38<13:35,  2.79s/it] 42%|████▏     | 209/500 [09:38<09:55,  2.05s/it] 42%|████▏     | 210/500 [09:38<07:25,  1.53s/it] 42%|████▏     | 211/500 [09:41<09:32,  1.98s/it] 42%|████▏     | 212/500 [09:44<10:58,  2.29s/it] 43%|████▎     | 213/500 [09:47<11:57,  2.50s/it] 43%|████▎     | 214/500 [09:47<08:35,  1.80s/it] 43%|████▎     | 215/500 [09:48<06:15,  1.32s/it] 43%|████▎     | 216/500 [09:51<08:39,  1.83s/it] 43%|████▎     | 217/500 [09:54<10:20,  2.19s/it] 44%|████▎     | 218/500 [09:54<07:28,  1.59s/it] 44%|████▍     | 219/500 [09:54<05:28,  1.17s/it] 44%|████▍     | 220/500 [09:57<08:00,  1.72s/it] 44%|████▍     | 221/500 [10:00<09:47,  2.11s/it] 44%|████▍     | 222/500 [10:03<11:02,  2.38s/it] 45%|████▍     | 223/500 [10:06<11:53,  2.57s/it] 45%|████▍     | 224/500 [10:09<12:27,  2.71s/it] 45%|████▌     | 225/500 [10:12<12:52,  2.81s/it] 45%|████▌     | 226/500 [10:15<13:07,  2.87s/it] 45%|████▌     | 227/500 [10:15<09:21,  2.06s/it] 46%|████▌     | 228/500 [10:18<10:39,  2.35s/it] 46%|████▌     | 229/500 [10:21<11:32,  2.56s/it] 46%|████▌     | 230/500 [10:25<12:15,  2.72s/it] 46%|████▌     | 231/500 [10:28<12:37,  2.82s/it] 46%|████▋     | 232/500 [10:31<12:51,  2.88s/it] 47%|████▋     | 233/500 [10:34<13:03,  2.93s/it] 47%|████▋     | 234/500 [10:37<13:07,  2.96s/it] 47%|████▋     | 235/500 [10:40<13:10,  2.98s/it] 47%|████▋     | 236/500 [10:43<13:12,  3.00s/it] 47%|████▋     | 237/500 [10:46<13:10,  3.01s/it] 48%|████▊     | 238/500 [10:49<13:09,  3.01s/it] 48%|████▊     | 239/500 [10:52<13:08,  3.02s/it] 48%|████▊     | 240/500 [10:55<13:07,  3.03s/it] 48%|████▊     | 241/500 [10:58<13:03,  3.02s/it] 48%|████▊     | 242/500 [11:01<13:00,  3.03s/it] 49%|████▊     | 243/500 [11:04<12:57,  3.03s/it] 49%|████▉     | 244/500 [11:07<12:53,  3.02s/it] 49%|████▉     | 245/500 [11:10<12:47,  3.01s/it] 49%|████▉     | 246/500 [11:10<09:08,  2.16s/it] 49%|████▉     | 247/500 [11:13<10:09,  2.41s/it] 50%|████▉     | 248/500 [11:16<10:49,  2.58s/it] 50%|████▉     | 249/500 [11:19<11:18,  2.70s/it] 50%|█████     | 250/500 [11:22<11:38,  2.80s/it] 50%|█████     | 251/500 [11:25<11:54,  2.87s/it] 50%|█████     | 252/500 [11:28<12:02,  2.91s/it] 51%|█████     | 253/500 [11:28<08:34,  2.08s/it] 51%|█████     | 254/500 [11:31<09:40,  2.36s/it] 51%|█████     | 255/500 [11:34<10:29,  2.57s/it] 51%|█████     | 256/500 [11:35<07:53,  1.94s/it] 51%|█████▏    | 257/500 [11:38<09:10,  2.27s/it] 52%|█████▏    | 258/500 [11:41<10:02,  2.49s/it] 52%|█████▏    | 259/500 [11:44<10:37,  2.64s/it] 52%|█████▏    | 260/500 [11:47<11:01,  2.76s/it] 52%|█████▏    | 261/500 [11:50<11:17,  2.84s/it] 52%|█████▏    | 262/500 [11:53<11:25,  2.88s/it] 53%|█████▎    | 263/500 [11:56<11:32,  2.92s/it] 53%|█████▎    | 264/500 [11:59<11:35,  2.95s/it] 53%|█████▎    | 265/500 [12:02<11:38,  2.97s/it] 53%|█████▎    | 266/500 [12:02<08:38,  2.22s/it] 53%|█████▎    | 267/500 [12:06<09:32,  2.46s/it] 54%|█████▎    | 268/500 [12:09<10:07,  2.62s/it] 54%|█████▍    | 269/500 [12:12<10:33,  2.74s/it] 54%|█████▍    | 270/500 [12:12<07:43,  2.02s/it] 54%|█████▍    | 271/500 [12:12<05:43,  1.50s/it] 54%|█████▍    | 272/500 [12:12<04:17,  1.13s/it] 55%|█████▍    | 273/500 [12:13<03:54,  1.03s/it] 55%|█████▍    | 274/500 [12:16<06:03,  1.61s/it] 55%|█████▌    | 275/500 [12:19<07:36,  2.03s/it] 55%|█████▌    | 276/500 [12:22<08:41,  2.33s/it] 55%|█████▌    | 277/500 [12:25<09:27,  2.55s/it] 56%|█████▌    | 278/500 [12:28<09:56,  2.69s/it] 56%|█████▌    | 279/500 [12:31<10:15,  2.79s/it] 56%|█████▌    | 280/500 [12:34<10:24,  2.84s/it] 56%|█████▌    | 281/500 [12:37<10:31,  2.88s/it] 56%|█████▋    | 282/500 [12:40<10:34,  2.91s/it] 57%|█████▋    | 283/500 [12:43<10:38,  2.94s/it] 57%|█████▋    | 284/500 [12:46<10:38,  2.96s/it] 57%|█████▋    | 285/500 [12:46<07:33,  2.11s/it] 57%|█████▋    | 286/500 [12:49<08:30,  2.39s/it] 57%|█████▋    | 287/500 [12:52<09:08,  2.57s/it] 58%|█████▊    | 288/500 [12:55<09:33,  2.70s/it] 58%|█████▊    | 289/500 [12:58<09:49,  2.80s/it] 58%|█████▊    | 290/500 [12:59<06:58,  1.99s/it] 58%|█████▊    | 291/500 [13:08<14:45,  4.24s/it] 58%|█████▊    | 292/500 [13:11<13:24,  3.87s/it] 59%|█████▊    | 293/500 [13:14<12:28,  3.62s/it] 59%|█████▉    | 294/500 [13:17<11:48,  3.44s/it] 59%|█████▉    | 295/500 [13:17<08:24,  2.46s/it] 59%|█████▉    | 296/500 [13:20<08:57,  2.63s/it] 59%|█████▉    | 297/500 [13:21<06:41,  1.98s/it] 60%|█████▉    | 298/500 [13:24<07:45,  2.30s/it] 60%|█████▉    | 299/500 [13:24<05:54,  1.76s/it] 60%|██████    | 300/500 [13:24<04:13,  1.27s/it] 60%|██████    | 301/500 [13:27<05:53,  1.78s/it] 60%|██████    | 302/500 [13:30<07:04,  2.15s/it] 61%|██████    | 303/500 [13:33<07:53,  2.41s/it] 61%|██████    | 304/500 [13:34<05:51,  1.79s/it] 61%|██████    | 305/500 [13:37<07:01,  2.16s/it] 61%|██████    | 306/500 [13:40<07:48,  2.42s/it] 61%|██████▏   | 307/500 [13:43<08:21,  2.60s/it] 62%|██████▏   | 308/500 [13:46<08:44,  2.73s/it] 62%|██████▏   | 309/500 [13:49<08:58,  2.82s/it] 62%|██████▏   | 310/500 [13:52<09:09,  2.89s/it] 62%|██████▏   | 311/500 [13:55<09:17,  2.95s/it] 62%|██████▏   | 312/500 [13:58<09:22,  2.99s/it] 63%|██████▎   | 313/500 [14:01<09:22,  3.01s/it] 63%|██████▎   | 314/500 [14:04<09:18,  3.00s/it] 63%|██████▎   | 315/500 [14:07<09:17,  3.01s/it] 63%|██████▎   | 316/500 [14:10<09:12,  3.00s/it] 64%|██████▎   | 318/500 [14:13<07:04,  2.33s/it] 64%|██████▍   | 319/500 [14:16<07:33,  2.51s/it] 64%|██████▍   | 320/500 [14:19<07:55,  2.64s/it] 64%|██████▍   | 321/500 [14:22<08:11,  2.75s/it] 64%|██████▍   | 322/500 [14:25<08:24,  2.84s/it] 65%|██████▍   | 323/500 [14:28<08:32,  2.89s/it] 65%|██████▍   | 324/500 [14:32<08:36,  2.94s/it] 65%|██████▌   | 325/500 [14:35<08:39,  2.97s/it] 65%|██████▌   | 326/500 [14:35<06:13,  2.15s/it] 65%|██████▌   | 327/500 [14:35<04:38,  1.61s/it] 66%|██████▌   | 328/500 [14:38<05:49,  2.03s/it] 66%|██████▌   | 329/500 [14:39<04:45,  1.67s/it] 66%|██████▌   | 330/500 [14:40<03:51,  1.36s/it] 66%|██████▌   | 331/500 [14:43<05:14,  1.86s/it] 66%|██████▋   | 332/500 [14:46<06:10,  2.21s/it] 67%|██████▋   | 333/500 [14:49<06:51,  2.46s/it] 67%|██████▋   | 334/500 [14:52<07:17,  2.64s/it] 67%|██████▋   | 335/500 [14:55<07:36,  2.77s/it] 67%|██████▋   | 336/500 [14:58<07:46,  2.84s/it] 67%|██████▋   | 337/500 [15:01<07:51,  2.89s/it] 68%|██████▊   | 338/500 [15:04<07:54,  2.93s/it] 68%|██████▊   | 339/500 [15:07<07:57,  2.97s/it] 68%|██████▊   | 340/500 [15:10<07:55,  2.97s/it] 68%|██████▊   | 341/500 [15:10<05:53,  2.23s/it] 68%|██████▊   | 342/500 [15:13<06:30,  2.47s/it] 69%|██████▊   | 343/500 [15:16<06:52,  2.63s/it] 69%|██████▉   | 344/500 [15:18<05:44,  2.21s/it] 69%|██████▉   | 345/500 [15:18<04:11,  1.63s/it] 69%|██████▉   | 346/500 [15:21<05:13,  2.04s/it] 69%|██████▉   | 347/500 [15:24<05:56,  2.33s/it] 70%|██████▉   | 348/500 [15:27<06:26,  2.54s/it] 70%|██████▉   | 349/500 [15:28<05:09,  2.05s/it] 70%|███████   | 350/500 [15:28<03:50,  1.54s/it] 70%|███████   | 351/500 [15:28<02:54,  1.17s/it] 70%|███████   | 352/500 [15:31<04:13,  1.71s/it] 71%|███████   | 353/500 [15:32<03:02,  1.24s/it] 71%|███████   | 354/500 [15:35<04:17,  1.76s/it] 71%|███████   | 355/500 [15:38<05:11,  2.14s/it] 71%|███████   | 356/500 [15:41<05:45,  2.40s/it] 71%|███████▏  | 357/500 [15:44<06:07,  2.57s/it] 72%|███████▏  | 358/500 [15:47<06:23,  2.70s/it] 72%|███████▏  | 359/500 [15:50<06:34,  2.80s/it] 72%|███████▏  | 360/500 [15:53<06:40,  2.86s/it] 72%|███████▏  | 361/500 [15:56<06:43,  2.90s/it] 72%|███████▏  | 362/500 [15:59<06:45,  2.94s/it] 73%|███████▎  | 363/500 [16:02<06:46,  2.96s/it] 73%|███████▎  | 364/500 [16:05<06:44,  2.97s/it] 73%|███████▎  | 365/500 [16:08<06:43,  2.99s/it] 73%|███████▎  | 366/500 [16:11<06:38,  2.97s/it] 73%|███████▎  | 367/500 [16:14<06:37,  2.99s/it] 74%|███████▎  | 368/500 [16:17<06:31,  2.97s/it] 74%|███████▍  | 369/500 [16:20<06:28,  2.97s/it] 74%|███████▍  | 370/500 [16:22<06:25,  2.96s/it] 74%|███████▍  | 371/500 [16:23<04:42,  2.19s/it] 74%|███████▍  | 372/500 [16:26<05:10,  2.42s/it] 75%|███████▍  | 373/500 [16:29<05:29,  2.59s/it] 75%|███████▍  | 374/500 [16:32<05:41,  2.71s/it] 75%|███████▌  | 375/500 [16:35<05:47,  2.78s/it] 75%|███████▌  | 376/500 [16:38<05:52,  2.84s/it] 75%|███████▌  | 377/500 [16:41<05:55,  2.89s/it] 76%|███████▌  | 378/500 [16:41<04:12,  2.07s/it] 76%|███████▌  | 379/500 [16:44<04:44,  2.35s/it] 76%|███████▌  | 380/500 [16:47<05:05,  2.54s/it] 76%|███████▌  | 381/500 [16:50<05:18,  2.68s/it] 76%|███████▋  | 382/500 [16:53<05:26,  2.77s/it] 77%|███████▋  | 383/500 [16:56<05:32,  2.84s/it] 77%|███████▋  | 384/500 [16:59<05:34,  2.89s/it] 77%|███████▋  | 385/500 [17:02<05:36,  2.92s/it] 77%|███████▋  | 387/500 [17:05<04:16,  2.27s/it] 78%|███████▊  | 388/500 [17:06<03:28,  1.86s/it] 78%|███████▊  | 389/500 [17:08<03:58,  2.15s/it] 78%|███████▊  | 390/500 [17:11<04:21,  2.38s/it] 78%|███████▊  | 391/500 [17:14<04:38,  2.55s/it] 78%|███████▊  | 392/500 [17:17<04:48,  2.67s/it] 79%|███████▊  | 393/500 [17:20<04:55,  2.77s/it] 79%|███████▉  | 394/500 [17:23<05:00,  2.83s/it] 79%|███████▉  | 395/500 [17:26<05:02,  2.88s/it] 79%|███████▉  | 396/500 [17:29<05:03,  2.91s/it] 79%|███████▉  | 397/500 [17:32<05:02,  2.94s/it] 80%|███████▉  | 398/500 [17:35<05:01,  2.96s/it] 80%|███████▉  | 399/500 [17:38<04:59,  2.96s/it] 80%|████████  | 400/500 [17:41<04:57,  2.97s/it] 80%|████████  | 401/500 [17:44<04:55,  2.98s/it] 80%|████████  | 402/500 [17:47<04:52,  2.98s/it] 81%|████████  | 403/500 [17:50<04:50,  2.99s/it] 81%|████████  | 404/500 [17:53<04:46,  2.99s/it] 81%|████████  | 405/500 [17:56<04:43,  2.99s/it] 81%|████████  | 406/500 [17:59<04:40,  2.98s/it] 81%|████████▏ | 407/500 [18:02<04:37,  2.98s/it] 82%|████████▏ | 408/500 [18:05<04:34,  2.98s/it] 82%|████████▏ | 409/500 [18:08<04:31,  2.99s/it] 82%|████████▏ | 410/500 [18:11<04:28,  2.99s/it] 82%|████████▏ | 411/500 [18:14<04:25,  2.99s/it] 82%|████████▏ | 412/500 [18:17<04:22,  2.98s/it] 83%|████████▎ | 413/500 [18:20<04:20,  2.99s/it] 83%|████████▎ | 414/500 [18:21<03:09,  2.20s/it] 83%|████████▎ | 415/500 [18:24<03:30,  2.47s/it] 83%|████████▎ | 416/500 [18:27<03:41,  2.64s/it] 83%|████████▎ | 417/500 [18:30<03:47,  2.75s/it] 84%|████████▎ | 418/500 [18:33<03:50,  2.81s/it] 84%|████████▍ | 419/500 [18:36<03:51,  2.86s/it] 84%|████████▍ | 420/500 [18:36<02:48,  2.10s/it] 84%|████████▍ | 421/500 [18:39<03:06,  2.36s/it] 84%|████████▍ | 422/500 [18:42<03:18,  2.54s/it] 85%|████████▍ | 423/500 [18:42<02:21,  1.84s/it] 85%|████████▍ | 424/500 [18:45<02:45,  2.17s/it] 85%|████████▌ | 425/500 [18:48<03:01,  2.42s/it] 85%|████████▌ | 426/500 [18:51<03:12,  2.59s/it] 85%|████████▌ | 427/500 [18:54<03:24,  2.80s/it] 86%|████████▌ | 428/500 [18:57<03:26,  2.86s/it] 86%|████████▌ | 429/500 [19:00<03:26,  2.91s/it] 86%|████████▌ | 430/500 [19:03<03:25,  2.94s/it] 86%|████████▌ | 431/500 [19:06<03:24,  2.97s/it] 86%|████████▋ | 432/500 [19:09<03:21,  2.96s/it] 87%|████████▋ | 433/500 [19:12<03:19,  2.97s/it] 87%|████████▋ | 434/500 [19:15<03:16,  2.97s/it] 87%|████████▋ | 435/500 [19:18<03:13,  2.98s/it] 87%|████████▋ | 436/500 [19:19<02:16,  2.14s/it] 87%|████████▋ | 437/500 [19:22<02:31,  2.40s/it] 88%|████████▊ | 438/500 [19:25<02:40,  2.58s/it] 88%|████████▊ | 439/500 [19:28<02:45,  2.71s/it] 88%|████████▊ | 440/500 [19:31<02:46,  2.78s/it] 88%|████████▊ | 441/500 [19:33<02:47,  2.84s/it] 88%|████████▊ | 442/500 [19:36<02:47,  2.89s/it] 89%|████████▊ | 443/500 [19:39<02:46,  2.91s/it] 89%|████████▉ | 444/500 [19:40<01:58,  2.11s/it] 89%|████████▉ | 445/500 [19:43<02:11,  2.38s/it] 89%|████████▉ | 446/500 [19:46<02:18,  2.56s/it] 89%|████████▉ | 447/500 [19:49<02:22,  2.69s/it] 90%|████████▉ | 448/500 [19:52<02:24,  2.79s/it] 90%|████████▉ | 449/500 [19:55<02:25,  2.86s/it] 90%|█████████ | 450/500 [19:58<02:24,  2.88s/it] 90%|█████████ | 451/500 [20:01<02:22,  2.91s/it] 90%|█████████ | 452/500 [20:04<02:20,  2.93s/it] 91%|█████████ | 453/500 [20:07<02:18,  2.95s/it] 91%|█████████ | 454/500 [20:07<01:41,  2.21s/it] 91%|█████████ | 455/500 [20:08<01:20,  1.78s/it] 91%|█████████ | 456/500 [20:11<01:34,  2.14s/it] 91%|█████████▏| 457/500 [20:14<01:42,  2.39s/it] 92%|█████████▏| 458/500 [20:17<01:47,  2.57s/it] 92%|█████████▏| 459/500 [20:20<01:50,  2.69s/it] 92%|█████████▏| 460/500 [20:23<01:50,  2.77s/it] 92%|█████████▏| 461/500 [20:26<01:51,  2.86s/it] 92%|█████████▏| 462/500 [20:29<01:50,  2.90s/it] 93%|█████████▎| 463/500 [20:32<01:48,  2.94s/it] 93%|█████████▎| 464/500 [20:35<01:46,  2.96s/it] 93%|█████████▎| 465/500 [20:38<01:43,  2.97s/it] 93%|█████████▎| 466/500 [20:41<01:41,  2.98s/it] 93%|█████████▎| 467/500 [20:44<01:38,  2.99s/it] 94%|█████████▎| 468/500 [20:47<01:35,  2.99s/it] 94%|█████████▍| 469/500 [20:50<01:32,  2.99s/it] 94%|█████████▍| 470/500 [20:53<01:29,  3.00s/it] 94%|█████████▍| 471/500 [20:56<01:27,  3.01s/it] 94%|█████████▍| 472/500 [20:59<01:24,  3.01s/it] 95%|█████████▍| 473/500 [21:02<01:21,  3.01s/it] 95%|█████████▍| 474/500 [21:05<01:18,  3.00s/it] 95%|█████████▌| 475/500 [21:08<01:14,  2.99s/it] 95%|█████████▌| 476/500 [21:08<00:51,  2.13s/it] 95%|█████████▌| 477/500 [21:11<00:54,  2.38s/it] 96%|█████████▌| 478/500 [21:14<00:56,  2.57s/it] 96%|█████████▌| 479/500 [21:17<00:56,  2.69s/it] 96%|█████████▌| 480/500 [21:20<00:56,  2.81s/it] 96%|█████████▌| 481/500 [21:23<00:54,  2.89s/it] 96%|█████████▋| 482/500 [21:26<00:53,  2.96s/it] 97%|█████████▋| 483/500 [21:29<00:51,  3.04s/it] 97%|█████████▋| 484/500 [21:33<00:49,  3.07s/it] 97%|█████████▋| 485/500 [21:36<00:46,  3.10s/it] 97%|█████████▋| 486/500 [21:39<00:43,  3.09s/it] 97%|█████████▋| 487/500 [21:42<00:40,  3.11s/it] 98%|█████████▊| 488/500 [21:45<00:37,  3.11s/it] 98%|█████████▊| 489/500 [21:48<00:34,  3.12s/it] 98%|█████████▊| 490/500 [21:51<00:31,  3.12s/it] 98%|█████████▊| 491/500 [21:54<00:28,  3.12s/it] 98%|█████████▊| 492/500 [21:58<00:25,  3.15s/it] 99%|█████████▊| 493/500 [21:58<00:16,  2.37s/it] 99%|█████████▉| 494/500 [22:01<00:15,  2.59s/it] 99%|█████████▉| 495/500 [22:04<00:13,  2.72s/it] 99%|█████████▉| 496/500 [22:07<00:11,  2.85s/it] 99%|█████████▉| 497/500 [22:11<00:08,  2.94s/it]100%|█████████▉| 498/500 [22:14<00:05,  2.98s/it]100%|█████████▉| 499/500 [22:17<00:03,  3.01s/it]100%|██████████| 500/500 [22:20<00:00,  3.04s/it]100%|██████████| 500/500 [22:20<00:00,  2.68s/it]
  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:15<00:45, 15.27s/it] 50%|█████     | 2/4 [00:23<00:21, 10.87s/it] 75%|███████▌  | 3/4 [00:30<00:09,  9.13s/it]originial_png_file: dataset/ori_500/line_56.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_56.png
originial_png_file: dataset/ori_500/heatmap_25.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_25.png
originial_png_file: dataset/ori_500/line_69.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_69.png
originial_png_file: dataset/ori_500/quiver_3.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/quiver_3.png
originial_png_file: dataset/ori_500/errorbar_13.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_13.png
originial_png_file: dataset/ori_500/line_63.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_63.png
originial_png_file: dataset/ori_500/line_38.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_38.png
originial_png_file: dataset/ori_500/HR_7.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_7.png
originial_png_file: dataset/ori_500/line_49.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_49.png
originial_png_file: dataset/ori_500/scatter_4.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_4.png
originial_png_file: dataset/ori_500/line_70.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_70.png
originial_png_file: dataset/ori_500/bar_34.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_34.png
originial_png_file: dataset/ori_500/box_20.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_20.png
originial_png_file: dataset/ori_500/bar_9.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_9.png
originial_png_file: dataset/ori_500/heatmap_11.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_11.png
originial_png_file: dataset/ori_500/box_5.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_5.png
originial_png_file: dataset/ori_500/line_65.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_65.png
originial_png_file: dataset/ori_500/errorpoint_3.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorpoint_3.png
originial_png_file: dataset/ori_500/multidiff_3.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_3.png
originial_png_file: dataset/ori_500/hist_17.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_17.png
originial_png_file: dataset/ori_500/bar_14.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_14.png
originial_png_file: dataset/ori_500/PIP_10.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/PIP_10.png
originial_png_file: dataset/ori_500/line_25.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_25.png
originial_png_file: dataset/ori_500/multidiff_7.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_7.png
originial_png_file: dataset/ori_500/hist_14.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_14.png
originial_png_file: dataset/ori_500/radar_17.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_17.png
originial_png_file: dataset/ori_500/scatter_1.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_1.png
originial_png_file: dataset/ori_500/box_2.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_2.png
originial_png_file: dataset/ori_500/heatmap_12.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_12.png
originial_png_file: dataset/ori_500/line_15.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_15.png
originial_png_file: dataset/ori_500/line_27.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_27.png
originial_png_file: dataset/ori_500/line_67.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_67.png
originial_png_file: dataset/ori_500/radar_4.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/radar_4.png
originial_png_file: dataset/ori_500/box_19.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_19.png
originial_png_file: dataset/ori_500/line_22.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_22.png
originial_png_file: dataset/ori_500/line_50.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_50.png
originial_png_file: dataset/ori_500/line_53.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_53.png
originial_png_file: dataset/ori_500/errorbar_22.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_22.png
originial_png_file: dataset/ori_500/errorbar_30.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_30.png
originial_png_file: dataset/ori_500/line_68.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_68.png
originial_png_file: dataset/ori_500/line_47.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_47.png
100%|██████████| 4/4 [00:50<00:00, 13.64s/it]100%|██████████| 4/4 [00:50<00:00, 12.66s/it]
originial_png_file: dataset/ori_500/bar_39.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_39.png
originial_png_file: dataset/ori_500/line_57.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_57.png
originial_png_file: dataset/ori_500/line_80.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_80.png
originial_png_file: dataset/ori_500/CB_22.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/CB_22.png
originial_png_file: dataset/ori_500/errorbar_18.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_18.png
originial_png_file: dataset/ori_500/bar_22.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_22.png
originial_png_file: dataset/ori_500/errorbar_15.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_15.png
originial_png_file: dataset/ori_500/line_14.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_14.png
originial_png_file: dataset/ori_500/hist_20.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_20.png
originial_png_file: dataset/ori_500/HR_8.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/HR_8.png
originial_png_file: dataset/ori_500/line_45.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_45.png
originial_png_file: dataset/ori_500/line_35.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_35.png
originial_png_file: dataset/ori_500/hist_11.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/hist_11.png
originial_png_file: dataset/ori_500/multidiff_14.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/multidiff_14.png
originial_png_file: dataset/ori_500/scatter_7.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_7.png
originial_png_file: dataset/ori_500/bar_50.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_50.png
originial_png_file: dataset/ori_500/line_54.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_54.png
originial_png_file: dataset/ori_500/bar_12.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_12.png
originial_png_file: dataset/ori_500/line_78.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_78.png
originial_png_file: dataset/ori_500/line_34.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_34.png
originial_png_file: dataset/ori_500/box_4.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_4.png
originial_png_file: dataset/ori_500/heatmap_5.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/heatmap_5.png
originial_png_file: dataset/ori_500/line_8.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_8.png
originial_png_file: dataset/ori_500/errorbar_20.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/errorbar_20.png
originial_png_file: dataset/ori_500/line_62.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_62.png
originial_png_file: dataset/ori_500/box_17.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/box_17.png
originial_png_file: dataset/ori_500/line_4.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/line_4.png
Request timed out.
originial_png_file: dataset/ori_500/bar_48.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/bar_48.png
originial_png_file: dataset/ori_500/scatter_2.png generated_png_file: results/direct/chart2code_pretrain_mm_only-7b_3072_bsz128_1e3_mix_data_ocr_code_pretrain_578k_1000_DirectAgent_results/direct/scatter_2.png
Time taken:  2149.7284319400787
正在处理模型: stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000
INFO 01-17 20:15:31 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.
INFO 01-17 20:15:31 llm_engine.py:249] Initializing an LLM engine (v0.6.4) with config: model='/mnt/lingjiejiang/multimodal_code/sft_checkpoints/stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000', speculative_config=None, tokenizer='/mnt/lingjiejiang/multimodal_code/sft_checkpoints/stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/mnt/lingjiejiang/multimodal_code/sft_checkpoints/stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 01-17 20:15:31 selector.py:135] Using Flash Attention backend.
INFO 01-17 20:15:32 model_runner.py:1072] Starting to load model /mnt/lingjiejiang/multimodal_code/sft_checkpoints/stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000...
Loading safetensors checkpoint shards:   0% Completed | 0/10 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  10% Completed | 1/10 [00:02<00:25,  2.81s/it]
Loading safetensors checkpoint shards:  20% Completed | 2/10 [00:06<00:28,  3.61s/it]
Loading safetensors checkpoint shards:  30% Completed | 3/10 [00:09<00:23,  3.30s/it]
Loading safetensors checkpoint shards:  40% Completed | 4/10 [00:13<00:19,  3.25s/it]
Loading safetensors checkpoint shards:  50% Completed | 5/10 [00:16<00:15,  3.16s/it]
Loading safetensors checkpoint shards:  60% Completed | 6/10 [00:19<00:12,  3.09s/it]
Loading safetensors checkpoint shards:  70% Completed | 7/10 [00:22<00:09,  3.07s/it]
Loading safetensors checkpoint shards:  80% Completed | 8/10 [00:25<00:06,  3.06s/it]
Loading safetensors checkpoint shards:  90% Completed | 9/10 [00:26<00:02,  2.63s/it]
Loading safetensors checkpoint shards: 100% Completed | 10/10 [00:28<00:00,  2.37s/it]
Loading safetensors checkpoint shards: 100% Completed | 10/10 [00:28<00:00,  2.86s/it]

INFO 01-17 20:16:01 model_runner.py:1077] Loading model weights took 15.5083 GB
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
INFO 01-17 20:16:06 worker.py:232] Memory profiling results: total_gpu_memory=79.25GiB initial_memory_usage=16.15GiB peak_torch_memory=20.53GiB memory_usage_post_profile=16.55Gib non_torch_memory=1.04GiB kv_cache_size=49.77GiB gpu_memory_utilization=0.90
INFO 01-17 20:16:06 gpu_executor.py:113] # GPU blocks: 58239, # CPU blocks: 4681
INFO 01-17 20:16:06 gpu_executor.py:117] Maximum concurrency for 32768 tokens per request: 28.44x
INFO 01-17 20:16:10 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-17 20:16:10 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 01-17 20:16:23 model_runner.py:1518] Graph capturing finished in 12 secs, took 0.37 GiB
Processing 500 files
INFO 01-17 20:16:26 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:16:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:34,  6.92s/it, est. speed input: 147.98 toks/s, output: 21.53 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:28,  2.94s/it, est. speed input: 251.33 toks/s, output: 43.40 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:49,  1.71s/it, est. speed input: 344.85 toks/s, output: 65.48 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:21,  1.27it/s, est. speed input: 569.91 toks/s, output: 112.25 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:09,  2.65it/s, est. speed input: 869.34 toks/s, output: 184.31 toks/s]Processed prompts:  41%|████      | 13/32 [00:07<00:03,  5.34it/s, est. speed input: 1355.56 toks/s, output: 302.84 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:07<00:02,  6.23it/s, est. speed input: 1550.69 toks/s, output: 350.07 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:08<00:02,  7.09it/s, est. speed input: 1742.18 toks/s, output: 397.41 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:02,  5.63it/s, est. speed input: 1810.66 toks/s, output: 431.69 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:09<00:02,  5.38it/s, est. speed input: 1951.72 toks/s, output: 473.78 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:09<00:01,  6.34it/s, est. speed input: 2049.86 toks/s, output: 528.47 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:09<00:01,  6.25it/s, est. speed input: 2101.52 toks/s, output: 551.92 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:09<00:01,  4.36it/s, est. speed input: 2114.12 toks/s, output: 558.25 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:10<00:01,  4.32it/s, est. speed input: 2147.07 toks/s, output: 581.14 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:12<00:03,  1.43it/s, est. speed input: 1844.08 toks/s, output: 520.27 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:13<00:03,  1.26it/s, est. speed input: 1751.82 toks/s, output: 523.31 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:56<00:35, 11.96s/it, est. speed input: 441.83 toks/s, output: 193.40 toks/s] Processed prompts:  94%|█████████▍| 30/32 [00:59<00:19,  9.61s/it, est. speed input: 432.82 toks/s, output: 250.83 toks/s]Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  1.87s/it, est. speed input: 463.78 toks/s, output: 387.85 toks/s]
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:17:27 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:35,  6.94s/it, est. speed input: 102.72 toks/s, output: 18.44 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:53,  1.84s/it, est. speed input: 313.81 toks/s, output: 55.94 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:38,  1.38s/it, est. speed input: 473.01 toks/s, output: 73.97 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:18,  1.38it/s, est. speed input: 661.90 toks/s, output: 116.93 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:12,  1.91it/s, est. speed input: 829.44 toks/s, output: 156.14 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:07,  2.80it/s, est. speed input: 1055.39 toks/s, output: 203.13 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:08<00:03,  5.34it/s, est. speed input: 1509.44 toks/s, output: 302.81 toks/s]Processed prompts:  50%|█████     | 16/32 [00:08<00:02,  6.34it/s, est. speed input: 1659.82 toks/s, output: 349.57 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:08<00:02,  6.51it/s, est. speed input: 1804.81 toks/s, output: 393.98 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:09<00:01,  6.40it/s, est. speed input: 1967.46 toks/s, output: 436.23 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:01,  7.82it/s, est. speed input: 2121.22 toks/s, output: 489.70 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:10<00:01,  4.15it/s, est. speed input: 2127.84 toks/s, output: 505.98 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:10<00:01,  4.42it/s, est. speed input: 2172.51 toks/s, output: 532.84 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:11<00:01,  3.20it/s, est. speed input: 2133.56 toks/s, output: 537.71 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:14<00:02,  1.39it/s, est. speed input: 1834.43 toks/s, output: 500.80 toks/s]Processed prompts:  91%|█████████ | 29/32 [01:00<00:30, 10.03s/it, est. speed input: 440.38 toks/s, output: 184.92 toks/s] Processed prompts: 100%|██████████| 32/32 [01:00<00:00,  1.88s/it, est. speed input: 486.93 toks/s, output: 389.15 toks/s]
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:18:28 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:40,  7.11s/it, est. speed input: 144.67 toks/s, output: 16.89 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:31,  3.06s/it, est. speed input: 242.39 toks/s, output: 34.51 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:51,  1.78s/it, est. speed input: 344.69 toks/s, output: 52.84 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:33,  1.20s/it, est. speed input: 480.03 toks/s, output: 71.79 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:16,  1.60it/s, est. speed input: 718.74 toks/s, output: 112.37 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:09,  2.62it/s, est. speed input: 969.03 toks/s, output: 155.38 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:06,  3.46it/s, est. speed input: 1123.67 toks/s, output: 196.66 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:08<00:05,  3.89it/s, est. speed input: 1251.63 toks/s, output: 236.43 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:04,  4.47it/s, est. speed input: 1474.61 toks/s, output: 280.31 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:04,  3.82it/s, est. speed input: 1497.00 toks/s, output: 296.63 toks/s]Processed prompts:  50%|█████     | 16/32 [00:09<00:04,  3.68it/s, est. speed input: 1529.15 toks/s, output: 317.16 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:10<00:02,  5.15it/s, est. speed input: 1719.80 toks/s, output: 372.97 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:10<00:02,  5.72it/s, est. speed input: 1775.66 toks/s, output: 399.74 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:10<00:01,  6.33it/s, est. speed input: 1852.24 toks/s, output: 426.65 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:10<00:01,  6.54it/s, est. speed input: 2004.16 toks/s, output: 477.39 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:10<00:01,  6.91it/s, est. speed input: 2044.44 toks/s, output: 504.60 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:11<00:01,  4.99it/s, est. speed input: 2068.97 toks/s, output: 544.44 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:12<00:01,  3.54it/s, est. speed input: 2023.00 toks/s, output: 575.27 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:14<00:02,  1.52it/s, est. speed input: 1789.45 toks/s, output: 531.82 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:15<00:02,  1.37it/s, est. speed input: 1752.89 toks/s, output: 542.58 toks/s]Processed prompts:  94%|█████████▍| 30/32 [01:00<00:23, 11.54s/it, est. speed input: 464.69 toks/s, output: 204.73 toks/s] Processed prompts: 100%|██████████| 32/32 [01:00<00:00,  1.89s/it, est. speed input: 507.07 toks/s, output: 340.28 toks/s]
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:19:29 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:36,  6.97s/it, est. speed input: 49.94 toks/s, output: 19.23 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:38,  3.29s/it, est. speed input: 97.40 toks/s, output: 40.24 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:35,  1.26s/it, est. speed input: 341.62 toks/s, output: 86.01 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:24,  1.10it/s, est. speed input: 419.29 toks/s, output: 108.68 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:17,  1.52it/s, est. speed input: 482.05 toks/s, output: 131.53 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:08<00:12,  1.96it/s, est. speed input: 539.26 toks/s, output: 153.78 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:05,  4.07it/s, est. speed input: 827.28 toks/s, output: 226.84 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:08<00:04,  4.89it/s, est. speed input: 1018.12 toks/s, output: 272.05 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:05,  3.07it/s, est. speed input: 1079.30 toks/s, output: 295.43 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:10<00:06,  2.65it/s, est. speed input: 1070.21 toks/s, output: 311.19 toks/s]Processed prompts:  50%|█████     | 16/32 [00:11<00:08,  1.98it/s, est. speed input: 1100.31 toks/s, output: 320.01 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:11<00:06,  2.16it/s, est. speed input: 1148.21 toks/s, output: 347.22 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:11<00:04,  2.79it/s, est. speed input: 1288.50 toks/s, output: 408.27 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:12<00:02,  4.00it/s, est. speed input: 1457.61 toks/s, output: 479.35 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:12<00:02,  4.44it/s, est. speed input: 1535.39 toks/s, output: 512.23 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:12<00:01,  5.58it/s, est. speed input: 1699.27 toks/s, output: 580.24 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:13<00:01,  3.82it/s, est. speed input: 1731.21 toks/s, output: 621.01 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:13<00:01,  3.94it/s, est. speed input: 1774.27 toks/s, output: 651.99 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:14<00:01,  3.08it/s, est. speed input: 1771.03 toks/s, output: 667.85 toks/s]Processed prompts:  94%|█████████▍| 30/32 [01:00<00:18,  9.12s/it, est. speed input: 439.36 toks/s, output: 234.25 toks/s] Processed prompts: 100%|██████████| 32/32 [01:00<00:00,  1.88s/it, est. speed input: 479.10 toks/s, output: 370.36 toks/s]
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:20:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<04:07,  7.98s/it, est. speed input: 147.30 toks/s, output: 17.80 toks/s]Processed prompts:   6%|▋         | 2/32 [00:08<01:40,  3.36s/it, est. speed input: 188.05 toks/s, output: 35.93 toks/s]Processed prompts:   9%|▉         | 3/32 [00:08<00:55,  1.90s/it, est. speed input: 349.12 toks/s, output: 54.40 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:17,  1.47it/s, est. speed input: 805.44 toks/s, output: 111.34 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:10,  2.24it/s, est. speed input: 1064.72 toks/s, output: 150.46 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:06,  3.15it/s, est. speed input: 1264.23 toks/s, output: 190.02 toks/s]Processed prompts:  41%|████      | 13/32 [00:08<00:03,  4.77it/s, est. speed input: 1522.81 toks/s, output: 250.47 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:03,  4.93it/s, est. speed input: 1662.67 toks/s, output: 288.21 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:09<00:02,  5.08it/s, est. speed input: 1845.53 toks/s, output: 326.47 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:09<00:02,  4.95it/s, est. speed input: 1932.37 toks/s, output: 345.62 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:10<00:02,  4.90it/s, est. speed input: 2002.28 toks/s, output: 386.05 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:10<00:02,  4.58it/s, est. speed input: 2020.13 toks/s, output: 405.17 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:10<00:01,  5.26it/s, est. speed input: 2166.09 toks/s, output: 454.17 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:11<00:01,  5.63it/s, est. speed input: 2208.73 toks/s, output: 479.61 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:11<00:01,  5.23it/s, est. speed input: 2266.33 toks/s, output: 501.07 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:11<00:01,  5.50it/s, est. speed input: 2357.33 toks/s, output: 526.52 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:11<00:01,  4.03it/s, est. speed input: 2351.91 toks/s, output: 540.61 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:12<00:00,  4.16it/s, est. speed input: 2389.23 toks/s, output: 565.18 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:13<00:01,  2.31it/s, est. speed input: 2281.45 toks/s, output: 561.87 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:16<00:02,  1.26s/it, est. speed input: 1866.60 toks/s, output: 492.57 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:19<00:01,  1.69s/it, est. speed input: 1650.68 toks/s, output: 471.77 toks/s]Processed prompts: 100%|██████████| 32/32 [00:59<00:00, 13.00s/it, est. speed input: 552.30 toks/s, output: 220.06 toks/s] Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  1.86s/it, est. speed input: 552.30 toks/s, output: 220.06 toks/s]
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:21:30 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:57,  7.67s/it, est. speed input: 153.21 toks/s, output: 14.86 toks/s]Processed prompts:   6%|▋         | 2/32 [00:08<01:45,  3.53s/it, est. speed input: 226.30 toks/s, output: 31.83 toks/s]Processed prompts:   9%|▉         | 3/32 [00:08<00:58,  2.00s/it, est. speed input: 379.23 toks/s, output: 50.08 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:08<00:24,  1.09it/s, est. speed input: 662.76 toks/s, output: 87.90 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:18,  1.43it/s, est. speed input: 746.34 toks/s, output: 106.80 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:08,  2.87it/s, est. speed input: 1098.78 toks/s, output: 166.37 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:06,  3.33it/s, est. speed input: 1234.57 toks/s, output: 186.09 toks/s]Processed prompts:  41%|████      | 13/32 [00:09<00:03,  5.60it/s, est. speed input: 1491.31 toks/s, output: 249.45 toks/s]Processed prompts:  50%|█████     | 16/32 [00:09<00:02,  7.03it/s, est. speed input: 1738.65 toks/s, output: 310.51 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:10<00:02,  5.61it/s, est. speed input: 1880.91 toks/s, output: 344.18 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:11<00:03,  3.52it/s, est. speed input: 1840.25 toks/s, output: 364.50 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:11<00:03,  3.46it/s, est. speed input: 1901.96 toks/s, output: 385.57 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:11<00:02,  3.83it/s, est. speed input: 1964.43 toks/s, output: 412.07 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:11<00:02,  3.78it/s, est. speed input: 1989.35 toks/s, output: 434.78 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:12<00:02,  3.57it/s, est. speed input: 2047.25 toks/s, output: 456.32 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:13<00:03,  2.30it/s, est. speed input: 1978.76 toks/s, output: 461.21 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:14<00:03,  1.78it/s, est. speed input: 1947.78 toks/s, output: 469.31 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:17<00:06,  1.30s/it, est. speed input: 1653.36 toks/s, output: 425.86 toks/s]Processed prompts:  88%|████████▊ | 28/32 [01:04<00:57, 14.30s/it, est. speed input: 459.35 toks/s, output: 176.93 toks/s] Processed prompts: 100%|██████████| 32/32 [01:04<00:00,  2.02s/it, est. speed input: 525.62 toks/s, output: 430.11 toks/s]
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:22:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:23,  6.58s/it, est. speed input: 100.93 toks/s, output: 17.94 toks/s]Processed prompts:   6%|▋         | 2/32 [00:06<01:23,  2.78s/it, est. speed input: 209.13 toks/s, output: 36.27 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:47,  1.65s/it, est. speed input: 300.14 toks/s, output: 55.09 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:29,  1.04s/it, est. speed input: 375.28 toks/s, output: 75.25 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:13,  1.87it/s, est. speed input: 581.73 toks/s, output: 116.34 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:07<00:10,  2.38it/s, est. speed input: 673.74 toks/s, output: 136.94 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:07<00:05,  3.89it/s, est. speed input: 949.44 toks/s, output: 180.84 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:07<00:04,  4.69it/s, est. speed input: 1186.66 toks/s, output: 221.33 toks/s]Processed prompts:  41%|████      | 13/32 [00:08<00:03,  5.41it/s, est. speed input: 1349.20 toks/s, output: 265.14 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:08<00:02,  7.09it/s, est. speed input: 1534.20 toks/s, output: 313.95 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:08<00:01,  8.17it/s, est. speed input: 1724.72 toks/s, output: 360.70 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:08<00:01,  8.08it/s, est. speed input: 1851.32 toks/s, output: 405.87 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:09<00:01,  6.22it/s, est. speed input: 1918.18 toks/s, output: 443.70 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:09<00:01,  5.66it/s, est. speed input: 2004.68 toks/s, output: 463.27 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:09<00:01,  6.22it/s, est. speed input: 2097.32 toks/s, output: 490.08 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:09<00:01,  6.26it/s, est. speed input: 2141.32 toks/s, output: 514.46 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:09<00:00,  9.25it/s, est. speed input: 2439.45 toks/s, output: 602.70 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:12<00:01,  1.88it/s, est. speed input: 2021.71 toks/s, output: 538.06 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:59<00:18,  9.12s/it, est. speed input: 445.90 toks/s, output: 183.39 toks/s] Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  1.85s/it, est. speed input: 476.46 toks/s, output: 321.57 toks/s]
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:23:35 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:09,  8.06s/it, est. speed input: 103.93 toks/s, output: 17.36 toks/s]Processed prompts:   6%|▋         | 2/32 [00:08<01:46,  3.56s/it, est. speed input: 173.14 toks/s, output: 35.76 toks/s]Processed prompts:   9%|▉         | 3/32 [00:08<00:59,  2.04s/it, est. speed input: 296.45 toks/s, output: 55.06 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:08<00:37,  1.34s/it, est. speed input: 438.41 toks/s, output: 74.78 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:09<00:26,  1.03it/s, est. speed input: 513.31 toks/s, output: 94.76 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:09<00:13,  1.81it/s, est. speed input: 761.54 toks/s, output: 137.52 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:07,  2.90it/s, est. speed input: 973.06 toks/s, output: 183.82 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:04,  4.65it/s, est. speed input: 1253.89 toks/s, output: 252.90 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:10<00:04,  4.46it/s, est. speed input: 1390.08 toks/s, output: 292.18 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:10<00:03,  4.66it/s, est. speed input: 1458.78 toks/s, output: 314.77 toks/s]Processed prompts:  50%|█████     | 16/32 [00:10<00:03,  4.15it/s, est. speed input: 1518.38 toks/s, output: 333.39 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:11<00:03,  3.91it/s, est. speed input: 1540.67 toks/s, output: 353.84 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:11<00:02,  5.50it/s, est. speed input: 1681.89 toks/s, output: 408.89 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:11<00:01,  7.25it/s, est. speed input: 1887.48 toks/s, output: 464.85 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:12<00:02,  4.21it/s, est. speed input: 1910.34 toks/s, output: 493.68 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:21<00:06,  1.29s/it, est. speed input: 1279.55 toks/s, output: 384.76 toks/s]Processed prompts:  88%|████████▊ | 28/32 [01:04<00:30,  7.52s/it, est. speed input: 451.23 toks/s, output: 192.98 toks/s] Processed prompts: 100%|██████████| 32/32 [01:04<00:00,  2.02s/it, est. speed input: 522.64 toks/s, output: 445.91 toks/s]
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:24:41 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:42,  7.17s/it, est. speed input: 191.49 toks/s, output: 13.53 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:39,  3.33s/it, est. speed input: 339.62 toks/s, output: 29.57 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:26,  1.02it/s, est. speed input: 756.03 toks/s, output: 81.10 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:20,  1.30it/s, est. speed input: 840.43 toks/s, output: 98.31 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:08<00:15,  1.65it/s, est. speed input: 991.12 toks/s, output: 115.98 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:08<00:08,  2.68it/s, est. speed input: 1134.68 toks/s, output: 153.58 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:08<00:05,  3.83it/s, est. speed input: 1301.94 toks/s, output: 192.46 toks/s]Processed prompts:  41%|████      | 13/32 [00:09<00:05,  3.40it/s, est. speed input: 1460.22 toks/s, output: 221.76 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:05,  3.55it/s, est. speed input: 1512.53 toks/s, output: 241.45 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:09<00:02,  5.63it/s, est. speed input: 1796.96 toks/s, output: 313.10 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:10<00:02,  5.03it/s, est. speed input: 1917.66 toks/s, output: 350.70 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:10<00:02,  4.35it/s, est. speed input: 1940.06 toks/s, output: 367.56 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:10<00:02,  4.01it/s, est. speed input: 1924.14 toks/s, output: 386.89 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:11<00:02,  3.34it/s, est. speed input: 1892.67 toks/s, output: 402.76 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:11<00:02,  3.82it/s, est. speed input: 1968.28 toks/s, output: 430.04 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:13<00:05,  1.40it/s, est. speed input: 1750.55 toks/s, output: 403.70 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:15<00:06,  1.03it/s, est. speed input: 1629.19 toks/s, output: 401.32 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:18<00:09,  1.51s/it, est. speed input: 1443.61 toks/s, output: 383.07 toks/s]Processed prompts:  84%|████████▍ | 27/32 [01:04<01:11, 14.38s/it, est. speed input: 410.26 toks/s, output: 169.80 toks/s] Processed prompts: 100%|██████████| 32/32 [01:04<00:00,  2.03s/it, est. speed input: 490.38 toks/s, output: 485.54 toks/s]
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:25:46 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:50,  7.43s/it, est. speed input: 50.60 toks/s, output: 18.84 toks/s]Processed prompts:   6%|▋         | 2/32 [00:07<01:36,  3.21s/it, est. speed input: 105.97 toks/s, output: 38.36 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:07<00:34,  1.23s/it, est. speed input: 380.11 toks/s, output: 79.02 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:17,  1.46it/s, est. speed input: 493.69 toks/s, output: 119.77 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:11,  2.11it/s, est. speed input: 685.91 toks/s, output: 160.47 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:09,  2.34it/s, est. speed input: 822.50 toks/s, output: 195.50 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:09<00:06,  3.16it/s, est. speed input: 955.34 toks/s, output: 243.09 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:04,  4.24it/s, est. speed input: 1192.69 toks/s, output: 293.58 toks/s]Processed prompts:  50%|█████     | 16/32 [00:09<00:03,  4.92it/s, est. speed input: 1320.08 toks/s, output: 340.51 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:10<00:03,  4.00it/s, est. speed input: 1324.88 toks/s, output: 355.05 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:11<00:06,  2.03it/s, est. speed input: 1227.59 toks/s, output: 345.87 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:12<00:08,  1.62it/s, est. speed input: 1203.24 toks/s, output: 354.12 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:13<00:07,  1.54it/s, est. speed input: 1202.44 toks/s, output: 373.15 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:13<00:07,  1.56it/s, est. speed input: 1183.78 toks/s, output: 396.54 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:14<00:07,  1.38it/s, est. speed input: 1200.34 toks/s, output: 412.83 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:16<00:08,  1.02it/s, est. speed input: 1164.06 toks/s, output: 415.65 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:23<00:20,  2.61s/it, est. speed input: 885.91 toks/s, output: 346.58 toks/s] Processed prompts:  78%|███████▊  | 25/32 [00:44<00:56,  8.03s/it, est. speed input: 486.89 toks/s, output: 240.09 toks/s]Processed prompts:  81%|████████▏ | 26/32 [01:05<01:11, 11.95s/it, est. speed input: 342.51 toks/s, output: 224.17 toks/s]Processed prompts: 100%|██████████| 32/32 [01:05<00:00,  2.06s/it, est. speed input: 451.42 toks/s, output: 597.32 toks/s]
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:26:53 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:05<03:01,  5.85s/it, est. speed input: 89.61 toks/s, output: 20.01 toks/s]Processed prompts:   6%|▋         | 2/32 [00:06<01:20,  2.67s/it, est. speed input: 170.51 toks/s, output: 41.32 toks/s]Processed prompts:   9%|▉         | 3/32 [00:06<00:47,  1.62s/it, est. speed input: 365.59 toks/s, output: 63.73 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:30,  1.09s/it, est. speed input: 398.53 toks/s, output: 87.31 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:20,  1.30it/s, est. speed input: 433.11 toks/s, output: 111.85 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:07<00:15,  1.72it/s, est. speed input: 606.97 toks/s, output: 136.50 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:09,  2.63it/s, est. speed input: 750.74 toks/s, output: 187.17 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:07,  2.87it/s, est. speed input: 875.21 toks/s, output: 233.12 toks/s]Processed prompts:  41%|████      | 13/32 [00:08<00:04,  4.41it/s, est. speed input: 1043.56 toks/s, output: 320.93 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:09<00:04,  3.61it/s, est. speed input: 1093.05 toks/s, output: 337.74 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:04,  4.12it/s, est. speed input: 1126.06 toks/s, output: 368.61 toks/s]Processed prompts:  50%|█████     | 16/32 [00:09<00:03,  4.56it/s, est. speed input: 1217.06 toks/s, output: 398.44 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:10<00:04,  3.42it/s, est. speed input: 1338.63 toks/s, output: 437.24 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:10<00:03,  3.98it/s, est. speed input: 1400.00 toks/s, output: 470.89 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:10<00:02,  4.93it/s, est. speed input: 1487.12 toks/s, output: 536.22 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:11<00:03,  3.12it/s, est. speed input: 1437.27 toks/s, output: 541.46 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:11<00:01,  4.55it/s, est. speed input: 1574.46 toks/s, output: 617.69 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:12<00:02,  3.12it/s, est. speed input: 1529.61 toks/s, output: 625.04 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:12<00:02,  2.21it/s, est. speed input: 1501.01 toks/s, output: 625.64 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:13<00:02,  2.43it/s, est. speed input: 1539.67 toks/s, output: 655.56 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:14<00:02,  1.79it/s, est. speed input: 1473.09 toks/s, output: 656.47 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:15<00:01,  1.87it/s, est. speed input: 1503.58 toks/s, output: 703.93 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:15<00:00,  2.13it/s, est. speed input: 1549.54 toks/s, output: 740.55 toks/s]Processed prompts: 100%|██████████| 32/32 [00:19<00:00,  1.37s/it, est. speed input: 1277.60 toks/s, output: 641.26 toks/s]Processed prompts: 100%|██████████| 32/32 [00:19<00:00,  1.64it/s, est. speed input: 1277.60 toks/s, output: 641.26 toks/s]
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:13 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<04:04,  7.87s/it, est. speed input: 125.98 toks/s, output: 17.14 toks/s]Processed prompts:   6%|▋         | 2/32 [00:08<01:40,  3.35s/it, est. speed input: 191.44 toks/s, output: 34.78 toks/s]Processed prompts:   9%|▉         | 3/32 [00:08<00:54,  1.89s/it, est. speed input: 333.48 toks/s, output: 52.88 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:08<00:37,  1.33s/it, est. speed input: 412.15 toks/s, output: 70.88 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:08<00:24,  1.12it/s, est. speed input: 466.95 toks/s, output: 91.28 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:08<00:16,  1.59it/s, est. speed input: 571.88 toks/s, output: 111.91 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:09<00:09,  2.43it/s, est. speed input: 791.05 toks/s, output: 151.88 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:09<00:08,  2.56it/s, est. speed input: 888.62 toks/s, output: 171.30 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:09<00:08,  2.62it/s, est. speed input: 976.37 toks/s, output: 191.07 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:10<00:06,  3.16it/s, est. speed input: 1097.79 toks/s, output: 214.78 toks/s]Processed prompts:  41%|████      | 13/32 [00:10<00:06,  3.12it/s, est. speed input: 1196.25 toks/s, output: 255.89 toks/s]Processed prompts:  50%|█████     | 16/32 [00:11<00:03,  4.88it/s, est. speed input: 1434.18 toks/s, output: 336.42 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:11<00:04,  3.26it/s, est. speed input: 1462.12 toks/s, output: 346.84 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:11<00:02,  4.58it/s, est. speed input: 1649.24 toks/s, output: 407.36 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:12<00:02,  4.21it/s, est. speed input: 1703.05 toks/s, output: 429.82 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:12<00:02,  4.95it/s, est. speed input: 1808.43 toks/s, output: 486.51 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:12<00:00,  7.79it/s, est. speed input: 2070.18 toks/s, output: 584.13 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:12<00:00,  6.56it/s, est. speed input: 2134.48 toks/s, output: 635.38 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:13<00:00,  4.20it/s, est. speed input: 2101.07 toks/s, output: 666.28 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:15<00:00,  2.03it/s, est. speed input: 1940.52 toks/s, output: 635.61 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:18<00:01,  1.01s/it, est. speed input: 1695.42 toks/s, output: 579.12 toks/s]Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  2.62s/it, est. speed input: 1223.34 toks/s, output: 457.84 toks/s]Processed prompts: 100%|██████████| 32/32 [00:26<00:00,  1.19it/s, est. speed input: 1223.34 toks/s, output: 457.84 toks/s]
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:27:40 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:08<04:15,  8.23s/it, est. speed input: 101.91 toks/s, output: 15.79 toks/s]Processed prompts:   6%|▋         | 2/32 [00:08<01:47,  3.60s/it, est. speed input: 215.08 toks/s, output: 32.62 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:09<00:43,  1.56s/it, est. speed input: 406.49 toks/s, output: 67.16 toks/s]Processed prompts:  19%|█▉        | 6/32 [00:09<00:23,  1.12it/s, est. speed input: 658.36 toks/s, output: 106.51 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:09<00:14,  1.68it/s, est. speed input: 852.51 toks/s, output: 147.11 toks/s]Processed prompts:  28%|██▊       | 9/32 [00:10<00:12,  1.88it/s, est. speed input: 908.52 toks/s, output: 166.59 toks/s]Processed prompts:  34%|███▍      | 11/32 [00:10<00:07,  2.78it/s, est. speed input: 1119.81 toks/s, output: 212.43 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:10<00:06,  3.09it/s, est. speed input: 1196.55 toks/s, output: 233.88 toks/s]Processed prompts:  41%|████      | 13/32 [00:10<00:06,  3.03it/s, est. speed input: 1250.48 toks/s, output: 252.95 toks/s]Processed prompts:  44%|████▍     | 14/32 [00:11<00:05,  3.14it/s, est. speed input: 1285.52 toks/s, output: 274.00 toks/s]Processed prompts:  50%|█████     | 16/32 [00:11<00:04,  3.74it/s, est. speed input: 1404.65 toks/s, output: 320.12 toks/s]Processed prompts:  56%|█████▋    | 18/32 [00:12<00:03,  4.00it/s, est. speed input: 1517.40 toks/s, output: 366.28 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:12<00:03,  3.88it/s, est. speed input: 1579.36 toks/s, output: 388.64 toks/s]Processed prompts:  62%|██████▎   | 20/32 [00:12<00:03,  3.88it/s, est. speed input: 1627.24 toks/s, output: 412.35 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:12<00:02,  4.08it/s, est. speed input: 1706.24 toks/s, output: 437.81 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:13<00:02,  4.05it/s, est. speed input: 1750.54 toks/s, output: 462.25 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:13<00:03,  2.98it/s, est. speed input: 1777.11 toks/s, output: 477.16 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:14<00:03,  2.39it/s, est. speed input: 1773.47 toks/s, output: 491.87 toks/s]Processed prompts:  78%|███████▊  | 25/32 [00:14<00:03,  2.33it/s, est. speed input: 1790.25 toks/s, output: 513.72 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:16<00:04,  1.28it/s, est. speed input: 1692.76 toks/s, output: 502.46 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:25<00:15,  3.10s/it, est. speed input: 1151.61 toks/s, output: 379.03 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:27<00:11,  2.90s/it, est. speed input: 1100.37 toks/s, output: 398.61 toks/s]Processed prompts:  91%|█████████ | 29/32 [01:02<00:37, 12.57s/it, est. speed input: 495.98 toks/s, output: 238.91 toks/s] Processed prompts: 100%|██████████| 32/32 [01:02<00:00,  1.97s/it, est. speed input: 549.35 toks/s, output: 434.00 toks/s]
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:28:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:06<03:26,  6.67s/it, est. speed input: 81.55 toks/s, output: 22.19 toks/s]Processed prompts:   6%|▋         | 2/32 [00:06<01:24,  2.81s/it, est. speed input: 157.50 toks/s, output: 44.58 toks/s]Processed prompts:  12%|█▎        | 4/32 [00:06<00:30,  1.11s/it, est. speed input: 404.30 toks/s, output: 89.48 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:07<00:09,  2.41it/s, est. speed input: 884.68 toks/s, output: 183.60 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:07<00:07,  3.05it/s, est. speed input: 1085.87 toks/s, output: 226.50 toks/s]Processed prompts:  38%|███▊      | 12/32 [00:07<00:04,  4.11it/s, est. speed input: 1260.49 toks/s, output: 274.73 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:07<00:03,  5.39it/s, est. speed input: 1482.57 toks/s, output: 343.23 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:07<00:01,  8.45it/s, est. speed input: 1885.21 toks/s, output: 449.44 toks/s]Processed prompts:  69%|██████▉   | 22/32 [00:08<00:01,  6.92it/s, est. speed input: 2028.94 toks/s, output: 505.67 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:09<00:01,  5.20it/s, est. speed input: 2024.84 toks/s, output: 530.05 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:13<00:04,  1.41it/s, est. speed input: 1452.78 toks/s, output: 425.11 toks/s]Processed prompts:  84%|████████▍ | 27/32 [00:15<00:04,  1.23it/s, est. speed input: 1357.89 toks/s, output: 435.21 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:18<00:04,  1.21s/it, est. speed input: 1197.23 toks/s, output: 414.26 toks/s]Processed prompts:  91%|█████████ | 29/32 [01:00<00:28,  9.43s/it, est. speed input: 385.85 toks/s, output: 193.72 toks/s] Processed prompts: 100%|██████████| 32/32 [01:00<00:00,  1.88s/it, est. speed input: 437.39 toks/s, output: 398.30 toks/s]
INFO 01-17 20:29:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:29:45 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|▎         | 1/32 [00:07<03:38,  7.06s/it, est. speed input: 133.15 toks/s, output: 18.84 toks/s]Processed prompts:   9%|▉         | 3/32 [00:07<00:59,  2.07s/it, est. speed input: 355.16 toks/s, output: 56.77 toks/s]Processed prompts:  16%|█▌        | 5/32 [00:07<00:27,  1.03s/it, est. speed input: 546.48 toks/s, output: 100.76 toks/s]Processed prompts:  22%|██▏       | 7/32 [00:08<00:16,  1.55it/s, est. speed input: 743.80 toks/s, output: 143.58 toks/s]Processed prompts:  25%|██▌       | 8/32 [00:08<00:12,  1.92it/s, est. speed input: 885.91 toks/s, output: 165.68 toks/s]Processed prompts:  31%|███▏      | 10/32 [00:08<00:08,  2.53it/s, est. speed input: 1020.11 toks/s, output: 207.22 toks/s]Processed prompts:  41%|████      | 13/32 [00:08<00:04,  4.13it/s, est. speed input: 1372.01 toks/s, output: 280.89 toks/s]Processed prompts:  47%|████▋     | 15/32 [00:09<00:04,  3.85it/s, est. speed input: 1448.85 toks/s, output: 318.39 toks/s]Processed prompts:  53%|█████▎    | 17/32 [00:09<00:04,  3.70it/s, est. speed input: 1531.03 toks/s, output: 358.19 toks/s]Processed prompts:  59%|█████▉    | 19/32 [00:10<00:02,  4.73it/s, est. speed input: 1676.94 toks/s, output: 415.84 toks/s]Processed prompts:  66%|██████▌   | 21/32 [00:10<00:01,  5.88it/s, est. speed input: 1859.24 toks/s, output: 473.53 toks/s]Processed prompts:  72%|███████▏  | 23/32 [00:10<00:01,  5.22it/s, est. speed input: 1912.88 toks/s, output: 517.67 toks/s]Processed prompts:  75%|███████▌  | 24/32 [00:11<00:01,  4.24it/s, est. speed input: 1961.03 toks/s, output: 532.50 toks/s]Processed prompts:  81%|████████▏ | 26/32 [00:11<00:01,  4.80it/s, est. speed input: 2072.48 toks/s, output: 589.00 toks/s]Processed prompts:  88%|████████▊ | 28/32 [00:12<00:01,  3.97it/s, est. speed input: 2118.45 toks/s, output: 628.46 toks/s]Processed prompts:  91%|█████████ | 29/32 [00:13<00:01,  2.37it/s, est. speed input: 1974.92 toks/s, output: 615.51 toks/s]Processed prompts:  94%|█████████▍| 30/32 [00:14<00:01,  1.93it/s, est. speed input: 1949.95 toks/s, output: 621.65 toks/s]Processed prompts:  97%|█████████▋| 31/32 [00:59<00:10, 10.90s/it, est. speed input: 487.44 toks/s, output: 217.49 toks/s] Processed prompts: 100%|██████████| 32/32 [00:59<00:00,  1.86s/it, est. speed input: 501.75 toks/s, output: 286.46 toks/s]
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
INFO 01-17 20:30:44 preprocess.py:215] Your model uses the legacy input pipeline instead of the new multi-modal processor. Please note that the legacy pipeline will be removed in a future release. For more details, see: https://github.com/vllm-project/vllm/issues/10114
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:05<01:39,  5.23s/it, est. speed input: 262.57 toks/s, output: 23.35 toks/s]Processed prompts:  10%|█         | 2/20 [00:05<00:39,  2.22s/it, est. speed input: 397.56 toks/s, output: 47.05 toks/s]Processed prompts:  15%|█▌        | 3/20 [00:05<00:22,  1.31s/it, est. speed input: 610.91 toks/s, output: 70.95 toks/s]Processed prompts:  30%|███       | 6/20 [00:05<00:06,  2.10it/s, est. speed input: 1050.26 toks/s, output: 147.64 toks/s]Processed prompts:  40%|████      | 8/20 [00:06<00:04,  2.79it/s, est. speed input: 1292.61 toks/s, output: 196.70 toks/s]Processed prompts:  45%|████▌     | 9/20 [00:06<00:03,  3.13it/s, est. speed input: 1373.50 toks/s, output: 221.43 toks/s]Processed prompts:  55%|█████▌    | 11/20 [00:06<00:02,  4.10it/s, est. speed input: 1590.15 toks/s, output: 274.33 toks/s]Processed prompts:  65%|██████▌   | 13/20 [00:06<00:01,  4.71it/s, est. speed input: 1830.27 toks/s, output: 326.38 toks/s]Processed prompts:  75%|███████▌  | 15/20 [00:06<00:00,  6.09it/s, est. speed input: 2098.30 toks/s, output: 387.61 toks/s]Processed prompts:  80%|████████  | 16/20 [00:07<00:00,  4.46it/s, est. speed input: 2148.98 toks/s, output: 399.61 toks/s]Processed prompts:  85%|████████▌ | 17/20 [00:07<00:00,  4.78it/s, est. speed input: 2203.96 toks/s, output: 429.12 toks/s]Processed prompts:  90%|█████████ | 18/20 [00:08<00:00,  2.23it/s, est. speed input: 1946.26 toks/s, output: 412.84 toks/s]Processed prompts:  95%|█████████▌| 19/20 [00:10<00:00,  1.50it/s, est. speed input: 1827.26 toks/s, output: 406.61 toks/s]Processed prompts: 100%|██████████| 20/20 [00:12<00:00,  1.10s/it, est. speed input: 1549.07 toks/s, output: 384.83 toks/s]Processed prompts: 100%|██████████| 20/20 [00:12<00:00,  1.61it/s, est. speed input: 1549.07 toks/s, output: 384.83 toks/s]
[rank0]:[W117 20:30:57.148910851 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
input_file results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results.json
output_dir results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker
  0%|          | 0/25 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/CB_16.py", line 21, in <module>
    ax.set_xticklabels(['SEAC', 'SAC(20Hz)'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (3), usually from a call to set_ticks, does not match the number of labels (2).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/3d_7.py", line 24, in <module>
    ax.set_zlabel('Z-axis')
AttributeError: 'Axes' object has no attribute 'set_zlabel'
  4%|▍         | 1/25 [00:01<00:42,  1.77s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/HR_17.py:13: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/CB_2.py", line 21, in <module>
    ax.text(i, success_rates[i] + 1, trends[i], ha='center', va='bottom', color='red')
IndexError: list index out of range
 12%|█▏        | 3/25 [00:03<00:22,  1.04s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/PIP_7.py", line 13, in <module>
    ax.plot(x, y1, 'b-', label='WI')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (201,) and (21,)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/bar_21.py", line 20, in <module>
    ax.set_xticklabels(['Strong Disagree', 'Disagree', 'Neutral', 'Agree', 'Strong Agree'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (11), usually from a call to set_ticks, does not match the number of labels (5).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/HR_24.py", line 26, in <module>
    im = ax.tripcolor(tri, Z.ravel(), cmap=cmap)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/tri/_tripcolor.py", line 62, in tripcolor
    tri, args, kwargs = Triangulation.get_from_args_and_kwargs(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/tri/_triangulation.py", line 167, in get_from_args_and_kwargs
    triangulation = Triangulation(x, y, triangles, mask)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/tri/_triangulation.py", line 45, in __init__
    self.x = np.asarray(x, dtype=np.float64)
TypeError: float() argument must be a string or a number, not 'Delaunay'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/HR_7.py", line 25, in <module>
    ax2.add_patch(plt.Rectangle((i*20, 0), 20, 10, color=color, alpha=0.5))
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 718, in __init__
    super().__init__(**kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 81, in __init__
    self.set_color(color)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 371, in set_color
    self.set_facecolor(c)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 356, in set_facecolor
    self._set_facecolor(color)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 344, in _set_facecolor
    self._facecolor = colors.to_rgba(color, alpha)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/colors.py", line 302, in to_rgba
    rgba = _to_rgba_no_colorcycle(c, alpha)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/colors.py", line 384, in _to_rgba_no_colorcycle
    raise ValueError(f"Invalid RGBA argument: {orig_c!r}")
ValueError: Invalid RGBA argument: 'L'
 16%|█▌        | 4/25 [00:04<00:25,  1.22s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/CB_22.py", line 56, in <module>
    ax.legend().get_texts()[0].set_color('#00FFFF')
IndexError: list index out of range
 24%|██▍       | 6/25 [00:06<00:17,  1.06it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/area_4.py", line 18, in <module>
    ax.fill_between(x, y_content, ymin=0, color='#4286f4', alpha=0.3)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 5512, in fill_between
    return self._fill_between_x_or_y(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 5493, in _fill_between_x_or_y
    collection = mcoll.PolyCollection(polys, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/collections.py", line 1198, in __init__
    super().__init__(**kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/collections.py", line 203, in __init__
    self._internal_update(kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/artist.py", line 1219, in _internal_update
    return self._update_props(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/artist.py", line 1193, in _update_props
    raise AttributeError(
AttributeError: PolyCollection.set() got an unexpected keyword argument 'ymin'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/bar_52.py", line 27, in <module>
    ax.text(bar.get_x() + bar.get_width()/2, yval+synthetic_data[bar.get_x()], round(yval, 2), va='bottom')
TypeError: list indices must be integers or slices, not numpy.float64
 28%|██▊       | 7/25 [00:07<00:19,  1.06s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/bar_42.py", line 43, in <module>
    ax.bar(brands, acc_values, color='green')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (26,) and arg 1 with shape (33,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/bar_70.py", line 12, in <module>
    ax.bar(labels, scores, color=colors)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (20,) and arg 1 with shape (21,).
/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/collections.py:1109: UserWarning: Collection without array used. Make sure to specify the values to be colormapped via the `c` argument.
  warnings.warn("Collection without array used. Make sure to "
 32%|███▏      | 8/25 [00:09<00:21,  1.24s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/bar_65.py", line 12, in <module>
    ax.plot([0, 1, 2, 3, 4], [i*2, i*2+1, i*2+2, i*2+3, i*2+4], color=colors[i])
IndexError: list index out of range
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/bar_62.py", line 20, in <module>
    ax.text(bar.get_x() + bar.get_width()/2, yval+synthetic_data[bar.get_x()], round(yval, 2), va='bottom')
TypeError: list indices must be integers or slices, not numpy.float64
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/bar_75.py", line 11, in <module>
    ax.pie(truthful, labels=["Truthful Recall", "Misleading Recall"], colors=["black", "pink"], autopct='%1.1f%%')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 3240, in pie
    raise ValueError("'label' must be of length 'x'")
ValueError: 'label' must be of length 'x'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/bar_83.py", line 20, in <module>
    ax.bar(emotions, metrics_2, color=colors)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (10,) and arg 1 with shape (12,).
 36%|███▌      | 9/25 [00:10<00:20,  1.29s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/density_5.py:26: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/box_20.py", line 23, in <module>
    ax.bar(['target', 'control'], [np.random.rand(2), np.random.rand(2)], color='blue')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2524, in bar
    r = mpatches.Rectangle(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 718, in __init__
    super().__init__(**kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 91, in __init__
    self.set_linewidth(linewidth)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/patches.py", line 391, in set_linewidth
    self._linewidth = float(w)
TypeError: only length-1 arrays can be converted to Python scalars
 40%|████      | 10/25 [00:12<00:20,  1.35s/it]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/heatmap_17.py", line 17, in <module>
    ax.plot(prices, 'o-', color=cmap(prices))
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 539, in _plot_args
    return [l[0] for l in result]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 539, in <listcomp>
    return [l[0] for l in result]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 532, in <genexpr>
    result = (make_artist(axes, x[:, j % ncx], y[:, j % ncy], kw,
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 346, in _makeline
    seg = mlines.Line2D(x, y, **kw)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/lines.py", line 376, in __init__
    self.set_color(color)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/lines.py", line 1061, in set_color
    mcolors._check_color_like(color=color)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/colors.py", line 246, in _check_color_like
    raise ValueError(f"{v!r} is not a valid value for {k}")
ValueError: array([[0.94343153, 0.80227625, 0.7291716 , 1.        ],
       [0.89588459, 0.43307456, 0.33868063, 1.        ],
       [0.23437708, 0.30554173, 0.75967953, 1.        ],
       [0.88839049, 0.41770292, 0.32789791, 1.        ],
       [0.95485341, 0.59162235, 0.47133746, 1.        ],
       [0.53256824, 0.6698006 , 0.99039327, 1.        ],
       [0.53800422, 0.67490159, 0.99172189, 1.        ],
       [0.37859825, 0.50385622, 0.91369161, 1.        ],
       [0.33837651, 0.45281861, 0.87931708, 1.        ],
       [0.6619679 , 0.77549147, 0.99393653, 1.        ],
       [0.96889416, 0.67947956, 0.56281229, 1.        ],
       [0.29471843, 0.39354193, 0.83438417, 1.        ],
       [0.95637093, 0.77514433, 0.68641595, 1.        ],
       [0.48924641, 0.62753606, 0.97689551, 1.        ],
       [0.93832636, 0.80891655, 0.74116152, 1.        ],
       [0.35841498, 0.47842617, 0.89679465, 1.        ],
       [0.47846225, 0.61656364, 0.9727209 , 1.        ],
       [0.9605812 , 0.76250102, 0.66796355, 1.        ],
       [0.85237814, 0.34649195, 0.28034647, 1.        ],
       [0.83936494, 0.32185622, 0.26492398, 1.        ],
       [0.586921  , 0.71812131, 0.99887411, 1.        ],
       [0.87962226, 0.85817494, 0.84584387, 1.        ],
       [0.70567316, 0.01555616, 0.15023281, 1.        ],
       [0.33837651, 0.45281861, 0.87931708, 1.        ],
       [0.31394635, 0.42005166, 0.85499254, 1.        ],
       [0.86742764, 0.8643766 , 0.86260246, 1.        ],
       [0.51082432, 0.64939661, 0.98507878, 1.        ],
       [0.88368714, 0.85610772, 0.84025767, 1.        ],
       [0.69845409, 0.79944988, 0.98457746, 1.        ],
       [0.79606387, 0.84869321, 0.93347147, 1.        ],
       [0.9682034 , 0.7208441 , 0.61229299, 1.        ],
       [0.91203258, 0.46967958, 0.3665649 , 1.        ],
       [0.52713226, 0.6646996 , 0.98906465, 1.        ],
       [0.72404137, 0.81491039, 0.97565097, 1.        ],
       [0.76336278, 0.83509222, 0.95565768, 1.        ],
       [0.73389779, 0.82001788, 0.97072437, 1.        ],
       [0.89588177, 0.84990606, 0.82349908, 1.        ],
       [0.29944126, 0.40024818, 0.83984198, 1.        ],
       [0.57061644, 0.70410916, 0.99719483, 1.        ],
       [0.9455403 , 0.79860574, 0.72310542, 1.        ],
       [0.53256824, 0.6698006 , 0.99039327, 1.        ],
       [0.93677961, 0.5327495 , 0.41809334, 1.        ],
       [0.76803436, 0.83703522, 0.95248822, 1.        ],
       [0.60316207, 0.73152748, 0.99956528, 1.        ],
       [0.96164474, 0.75802918, 0.66178238, 1.        ],
       [0.93925377, 0.53958149, 0.4239002 , 1.        ],
       [0.9455403 , 0.79860574, 0.72310542, 1.        ],
       [0.94915051, 0.79078527, 0.71087559, 1.        ],
       [0.96889416, 0.67947956, 0.56281229, 1.        ],
       [0.8204011 , 0.28676491, 0.24515952, 1.        ]]) is not a valid value for color
 44%|████▍     | 11/25 [00:13<00:19,  1.39s/it] 48%|████▊     | 12/25 [00:15<00:18,  1.41s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/errorbar_26.py", line 26, in <module>
    ax.bar(categories, support, color='lightblue')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (7,) and arg 1 with shape (2,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/hist_1.py", line 74, in <module>
    ax.contour([100, 90, 80, 70], [60, 50, 40, 30], [20, 10, 0, 0], colors=['#4B4B4B'])
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 6520, in contour
    contours = mcontour.QuadContourSet(self, *args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/contour.py", line 858, in __init__
    kwargs = self._process_args(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/contour.py", line 1523, in _process_args
    x, y, z = self._contour_args(args, kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/contour.py", line 1563, in _contour_args
    x, y, z = self._check_xyz(x, y, z_orig, kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/contour.py", line 1589, in _check_xyz
    raise TypeError(f"Input z must be 2D, not {z.ndim}D")
TypeError: Input z must be 2D, not 1D
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/errorbar_4.py", line 27, in <module>
    ax.axhline(y=median(tokens), color='black', linestyle='-')
NameError: name 'median' is not defined
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/heatmap_22.py", line 42, in <module>
    heatmap.set_edgecolor('face')
AttributeError: 'AxesImage' object has no attribute 'set_edgecolor'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/heatmap_6.py", line 13, in <module>
    ax.barh(brands, memory_bandwidths, color='blue')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2701, in barh
    patches = self.bar(x=left, height=height, width=width, bottom=y,
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 2461, in bar
    x, height, width, y, linewidth, hatch = np.broadcast_arrays(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 540, in broadcast_arrays
    shape = _broadcast_shape(*args)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/numpy/lib/stride_tricks.py", line 422, in _broadcast_shape
    b = np.broadcast(*args[:32])
ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 2 with shape (6,) and arg 3 with shape (4,).
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/heatmap_10.py", line 12, in <module>
    wedges, texts, autotexts = ax.pie(data, labels=labels, autopct='%1.1f%%', startangle=90)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 3240, in pie
    raise ValueError("'label' must be of length 'x'")
ValueError: 'label' must be of length 'x'
 68%|██████▊   | 17/25 [00:16<00:05,  1.49it/s]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/hist_13.py:29: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_xticklabels(['Camels', 'Kangaroos'], color='#0080ff')
/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/hist_13.py:30: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_yticklabels(['1000', '1000', '1000', '1000'], color='#ffa500')
 72%|███████▏  | 18/25 [00:18<00:05,  1.27it/s] 76%|███████▌  | 19/25 [00:19<00:05,  1.11it/s]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/line_51.py:25: RuntimeWarning: divide by zero encountered in log
  growth.plot(np.linspace(0, 10, 100), np.log(np.linspace(0, 10, 100)), 'r-')
 80%|████████  | 20/25 [00:20<00:05,  1.01s/it] 88%|████████▊ | 22/25 [00:22<00:02,  1.12it/s]Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/multidiff_24.py", line 26, in <module>
    angles = np.linspace(0, 2 * np.pi, len(techniques), endpoint=False).tolist()
NameError: name 'np' is not defined
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/line_9.py", line 49, in <module>
    ax.legend().get_texts()[0].set_color('blue')
IndexError: list index out of range
 96%|█████████▌| 24/25 [00:24<00:00,  1.14it/s]100%|██████████| 25/25 [00:25<00:00,  1.02it/s]100%|██████████| 25/25 [00:25<00:00,  1.02s/it]
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/scatter_21.py", line 18, in <module>
    ax.scatter(range(len(libri_data)), libri_data, color=libri_colors)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4673, in scatter
    self._parse_scatter_color_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4502, in _parse_scatter_color_args
    raise invalid_shape_exception(len(colors), xsize)
ValueError: 'c' argument has 2 elements, which is inconsistent with 'x' and 'y' with size 8.
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/radar_7.py", line 17, in <module>
    ax.set_zlabel('z')
AttributeError: 'Axes' object has no attribute 'set_zlabel'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/multidiff_8.py", line 15, in <module>
    ax.plot(x, y1, 'b-', label='Random')
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 1724, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 303, in __call__
    yield from self._plot_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 499, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (26,) and (28,)
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/radar_14.py", line 23, in <module>
    scatter = ax.scatter(range(num_students), scores, c=colors, s=100)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4673, in scatter
    self._parse_scatter_color_args(
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4502, in _parse_scatter_color_args
    raise invalid_shape_exception(len(colors), xsize)
ValueError: 'c' argument has 4 elements, which is inconsistent with 'x' and 'y' with size 10.
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/scatter_20.py", line 17, in <module>
    cbar.set_clim(0, 100)
AttributeError: 'Colorbar' object has no attribute 'set_clim'
Traceback (most recent call last):
  File "/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct_checker/scatter_18.py", line 33, in <module>
    ax.set_yticklabels(y_labels)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axes/_base.py", line 73, in wrapper
    return get_method(self)(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/_api/deprecation.py", line 297, in wrapper
    return func(*args, **kwargs)
  File "/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/axis.py", line 2025, in set_ticklabels
    raise ValueError(
ValueError: The number of FixedLocator locations (6), usually from a call to set_ticks, does not match the number of labels (1).
Total Python Files 413
Total PDF Files 381
input_file results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results.json
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:01<01:09,  1.42s/it]  4%|▍         | 2/50 [00:02<01:00,  1.27s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  6%|▌         | 3/50 [00:03<00:57,  1.22s/it]  8%|▊         | 4/50 [00:05<01:01,  1.33s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_17.py:14: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
 10%|█         | 5/50 [00:06<01:02,  1.38s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
 12%|█▏        | 6/50 [00:07<00:57,  1.31s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_17.py:14: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
 14%|█▍        | 7/50 [00:09<00:54,  1.28s/it] 16%|█▌        | 8/50 [00:10<00:56,  1.35s/it] 18%|█▊        | 9/50 [00:11<00:53,  1.31s/it] 20%|██        | 10/50 [00:13<00:53,  1.34s/it] 22%|██▏       | 11/50 [00:14<00:54,  1.39s/it] 24%|██▍       | 12/50 [00:16<00:54,  1.44s/it] 26%|██▌       | 13/50 [00:17<00:53,  1.45s/it] 28%|██▊       | 14/50 [00:19<00:54,  1.52s/it] 30%|███       | 15/50 [00:20<00:51,  1.47s/it] 32%|███▏      | 16/50 [00:22<00:48,  1.41s/it] 34%|███▍      | 17/50 [00:23<00:45,  1.37s/it] 36%|███▌      | 18/50 [00:24<00:44,  1.41s/it]/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/collections.py:1109: UserWarning: Collection without array used. Make sure to specify the values to be colormapped via the `c` argument.
  warnings.warn("Collection without array used. Make sure to "
 38%|███▊      | 19/50 [00:26<00:45,  1.45s/it] 40%|████      | 20/50 [00:28<00:45,  1.50s/it]/home/v-lingjiang/miniconda3/envs/chartmimic/lib/python3.9/site-packages/matplotlib/collections.py:1109: UserWarning: Collection without array used. Make sure to specify the values to be colormapped via the `c` argument.
  warnings.warn("Collection without array used. Make sure to "
 42%|████▏     | 21/50 [00:29<00:43,  1.50s/it] 44%|████▍     | 22/50 [00:30<00:41,  1.49s/it] 46%|████▌     | 23/50 [00:32<00:41,  1.52s/it] 48%|████▊     | 24/50 [00:33<00:38,  1.49s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_5.py:27: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
 50%|█████     | 25/50 [00:35<00:35,  1.41s/it] 52%|█████▏    | 26/50 [00:36<00:34,  1.43s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_5.py:27: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
 54%|█████▍    | 27/50 [00:37<00:31,  1.35s/it] 56%|█████▌    | 28/50 [00:39<00:29,  1.34s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
 58%|█████▊    | 29/50 [00:40<00:28,  1.34s/it] 60%|██████    | 30/50 [00:41<00:25,  1.28s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
 62%|██████▏   | 31/50 [00:43<00:24,  1.30s/it] 64%|██████▍   | 32/50 [00:44<00:23,  1.30s/it] 66%|██████▌   | 33/50 [00:45<00:22,  1.34s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_13.py:30: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_xticklabels(['Camels', 'Kangaroos'], color='#0080ff')
/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_13.py:31: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_yticklabels(['1000', '1000', '1000', '1000'], color='#ffa500')
 68%|██████▊   | 34/50 [00:47<00:21,  1.33s/it] 70%|███████   | 35/50 [00:48<00:19,  1.33s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_13.py:30: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_xticklabels(['Camels', 'Kangaroos'], color='#0080ff')
/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_13.py:31: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.
  ax.set_yticklabels(['1000', '1000', '1000', '1000'], color='#ffa500')
 72%|███████▏  | 36/50 [00:50<00:23,  1.69s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_51.py:26: RuntimeWarning: divide by zero encountered in log
  growth.plot(np.linspace(0, 10, 100), np.log(np.linspace(0, 10, 100)), 'r-')
 74%|███████▍  | 37/50 [00:52<00:21,  1.62s/it]/home/v-lingjiang/project/ChartMimic/results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_51.py:26: RuntimeWarning: divide by zero encountered in log
  growth.plot(np.linspace(0, 10, 100), np.log(np.linspace(0, 10, 100)), 'r-')
 76%|███████▌  | 38/50 [00:54<00:19,  1.63s/it] 78%|███████▊  | 39/50 [00:55<00:17,  1.58s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
 80%|████████  | 40/50 [00:57<00:16,  1.64s/it] 82%|████████▏ | 41/50 [00:58<00:13,  1.48s/it]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
 84%|████████▍ | 42/50 [00:59<00:12,  1.53s/it] 86%|████████▌ | 43/50 [01:01<00:10,  1.47s/it] 88%|████████▊ | 44/50 [01:02<00:08,  1.48s/it] 90%|█████████ | 45/50 [01:03<00:06,  1.35s/it] 92%|█████████▏| 46/50 [01:05<00:05,  1.34s/it] 94%|█████████▍| 47/50 [01:06<00:04,  1.43s/it] 96%|█████████▌| 48/50 [01:08<00:02,  1.39s/it] 98%|█████████▊| 49/50 [01:09<00:01,  1.38s/it]100%|██████████| 50/50 [01:10<00:00,  1.40s/it]100%|██████████| 50/50 [01:10<00:00,  1.42s/it]
args.tasks ['code4evaluation']
args.model stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000
result file: ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results_code4evaluation.json
original_dataset_dir:  ./dataset/ori_500
generated_dataset_dir:  ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results
len dataset: 500
  0%|          | 0/25 [00:00<?, ?it/s]No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
cmap is used viridis
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_32.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_25.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_25.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_44.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_67.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_1.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
  4%|▍         | 1/25 [00:18<07:22, 18.45s/it]cmap is used coolwarm
cmap is used viridis
cmap is used plasma
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_36.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_32.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_47.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_15.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_14.py
cmap is used viridis
cmap is used viridis
cmap is used viridis
cmap is used viridis
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_26.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_16.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_5.py
  8%|▊         | 2/25 [00:34<06:34, 17.16s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_97.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_67.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_26.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_41.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_10.py
 12%|█▏        | 3/25 [00:53<06:37, 18.06s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_73.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_18.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_40.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_18.py
cmap is used viridis
 16%|█▌        | 4/25 [01:07<05:46, 16.49s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_82.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_41.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_16.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_20.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_65.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_92.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_19.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_49.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_44.py
 20%|██        | 5/25 [01:25<05:40, 17.04s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_16.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/contour_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_56.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_83.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_25.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_15.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_98.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_20.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_68.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_12.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_28.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_12.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_80.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_33.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_78.py
cmap is used coolwarm
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_38.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_60.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/contour_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_10.py
cmap is used viridis
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_12.py
cmap is used <matplotlib.colors.LinearSegmentedColormap object at 0x7fc7fa237b50>
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_70.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_15.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_3.py
 24%|██▍       | 6/25 [01:42<05:23, 17.00s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_40.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_6.py
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_texts.py:54: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_15.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_43.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_12.py
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_chart_types.py:375: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_24.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_69.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/contour_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_25.py
 28%|██▊       | 7/25 [01:59<05:03, 16.89s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_46.py
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_colors.py:766: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_71.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_21.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_16.py
/home/v-lingjiang/project/ChartMimic/./dataset/ori_500/CB_6_log_layouts.py:31: RuntimeWarning: covariance is not symmetric positive-semidefinite.
  species: np.random.multivariate_normal(dist["mean"], dist["cov"], 100)
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_25.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_39.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_72.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_66.py
 32%|███▏      | 8/25 [02:16<04:47, 16.92s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_22.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_48.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_12.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_76.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_85.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_16.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_19.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_18.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_15.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_69.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_3.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
 36%|███▌      | 9/25 [02:37<04:49, 18.09s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_48.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_61.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_77.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_8.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_57.py
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_51_log_texts.py:57: RuntimeWarning: divide by zero encountered in log
  growth.plot(np.linspace(0, 10, 100), np.log(np.linspace(0, 10, 100)), 'r-')
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_100.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_19.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_74.py
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_51_log_chart_types.py:378: RuntimeWarning: divide by zero encountered in log
  growth.plot(np.linspace(0, 10, 100), np.log(np.linspace(0, 10, 100)), 'r-')
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_21.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_19.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_51_log_colors.py:769: RuntimeWarning: divide by zero encountered in log
  growth.plot(np.linspace(0, 10, 100), np.log(np.linspace(0, 10, 100)), 'r-')
 40%|████      | 10/25 [03:03<05:10, 20.68s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_19.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_42.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_75.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_55.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_24.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_51.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_30.py
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_51_log_layouts.py:34: RuntimeWarning: divide by zero encountered in log
  growth.plot(np.linspace(0, 10, 100), np.log(np.linspace(0, 10, 100)), 'r-')
cmap is used viridis
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_19.py
cmap is used viridis
cmap is used viridis
cmap is used viridis
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_24.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
cmap is used magma
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_22.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_30.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_23.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_53.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_10.py
cmap is used <matplotlib.colors.LinearSegmentedColormap object at 0x7a36d7b02190>
 44%|████▍     | 11/25 [03:28<05:06, 21.92s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_7.py
cmap is used viridis
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_23.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_21.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_25.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_23.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_23.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_12.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_29.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_15.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_28.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_25.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_38.py
 48%|████▊     | 12/25 [03:51<04:47, 22.15s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_27.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_3.py
cmap is used viridis
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_68.py
cmap is used spring
cmap is used spring
cmap is used spring
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_25.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_45.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_86.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_63.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_77.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_55.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_30.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_96.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_95.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_27.py
 52%|█████▏    | 13/25 [04:12<04:21, 21.80s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_63.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_27.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_13.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
 56%|█████▌    | 14/25 [04:30<03:47, 20.68s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_12.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_26.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_42.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_94.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_20.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_21.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_54.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_70.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_22.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_61.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_7.py
No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_23.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_20.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_14.py
 60%|██████    | 15/25 [04:47<03:17, 19.78s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_18.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_64.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_25.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_19.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_78.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_15.py
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_5_log_texts.py:58: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_18.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_60.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_4.py
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_5_log_chart_types.py:379: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_51.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_36.py
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_5_log_colors.py:770: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_9.py
 64%|██████▍   | 16/25 [05:08<03:00, 20.01s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_22.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_20.py
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_5_log_layouts.py:35: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_22.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_59.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_79.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_88.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_34.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_56.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_12.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_22.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_24.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_23.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_45.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_20.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_28.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_58.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_16.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_19.py
 68%|██████▊   | 17/25 [05:26<02:36, 19.53s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_16.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_18.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_22.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_65.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_66.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_29.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_39.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_33.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_54.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_19.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_99.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_43.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_53.py
 72%|███████▏  | 18/25 [05:46<02:17, 19.65s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_90.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_26.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_12.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_73.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_35.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_18.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_52.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_28.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_58.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_30.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_4.py
 76%|███████▌  | 19/25 [06:05<01:56, 19.38s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_64.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_29.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_15.py
cmap is used viridis
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_23.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_34.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_27.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_30.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_31.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_28.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_57.py
 80%|████████  | 20/25 [06:23<01:35, 19.03s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_50.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_62.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_15.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_22.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_21.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_59.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_52.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_6.py
 84%|████████▍ | 21/25 [06:40<01:13, 18.33s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_76.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_37.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_93.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_62.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_24.py
cmap is used autumn
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_23.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_21.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_9.py
 88%|████████▊ | 22/25 [06:58<00:55, 18.41s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_79.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_81.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_26.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_24.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_20.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_16.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_46.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_27.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_31.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_49.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_21.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_20.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_15.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_89.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_15.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_15.py
cmap is used viridis
 92%|█████████▏| 23/25 [07:17<00:37, 18.59s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_15.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_71.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_47.py
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_17_log_texts.py:45: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_19.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_16.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_24.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_12.py
cmap is used coolwarm
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_17_log_chart_types.py:366: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_24.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_23.py
cmap is used nipy_spectral
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_20.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_18.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_9.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_18.py
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_17_log_colors.py:757: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
 96%|█████████▌| 24/25 [07:36<00:18, 18.49s/it]genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_16.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_1.py
/home/v-lingjiang/project/ChartMimic/./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_17_log_layouts.py:22: RuntimeWarning: divide by zero encountered in log
  y5 = np.log(x)
cmap is used jet
cmap is used jet
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_72.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_84.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_24.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_91.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_13.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/contour_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_18.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_37.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_50.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_12.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_29.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_35.py
100%|██████████| 25/25 [07:52<00:00, 17.71s/it]100%|██████████| 25/25 [07:52<00:00, 18.88s/it]
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_87.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_80.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_4.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_12.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_10.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_22.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_11.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_17.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_21.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_16.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_6.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_75.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_18.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_7.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/contour_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_1.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_19.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_20.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_12.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_20.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_3.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_2.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_8.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_5.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_74.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_14.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_29.py
genearion_code_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_21.py
self.results_file ./results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results_code4evaluation.json
Time taken:  510.4491982460022
args.tasks ['gpt4evaluation']
args.model stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_60.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_39.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_86.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_36.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_56.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_33.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_24.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_25.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_24.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_69.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_52.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_92.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_95.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_38.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_22.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_52.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_31.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_24.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_43.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_21.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_78.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_26.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_100.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_70.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_83.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_38.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_63.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_23.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_42.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_54.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_22.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_66.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_88.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_24.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_78.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_28.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_45.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_58.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_21.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_97.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_59.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_25.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_72.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_72.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_61.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_21.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_79.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_32.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_46.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_90.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_62.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_31.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_21.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_46.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_56.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_29.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_57.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_21.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_24.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_79.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_23.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_30.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_61.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_70.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_24.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_23.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_55.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_84.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_27.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_27.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/contour_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_25.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_29.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_25.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_23.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_57.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_50.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/contour_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_73.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_48.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_23.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_28.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_22.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_30.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_34.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_35.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_24.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_75.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_41.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_35.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_23.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_44.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_43.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_68.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_37.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_42.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_33.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_25.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_24.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_21.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_24.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_71.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_89.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_25.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_22.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_34.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_94.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_30.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_32.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_93.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_67.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_87.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_30.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_74.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_48.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_51.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_80.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_54.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_62.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_49.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_25.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_64.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_22.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_26.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_73.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_26.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_50.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_91.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_68.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_23.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_41.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_69.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_22.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_63.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_25.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_59.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_75.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_85.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_27.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_60.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_22.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_26.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_10.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_65.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_21.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_22.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_29.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_96.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_30.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_25.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/contour_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_58.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_76.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/contour_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_99.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_15.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_18.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_77.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_66.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_27.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_82.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_74.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_71.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_27.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_28.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_28.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_23.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_47.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_65.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_77.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_53.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_53.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_17.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_29.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_21.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_81.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_21.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_51.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_49.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_47.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_44.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_29.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_36.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_3.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_37.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/contour_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_19.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_13.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_20.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_5.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_12.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_2.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_45.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_14.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_28.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_76.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_80.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_11.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_39.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_40.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_22.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_6.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_7.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_40.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_98.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_26.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_9.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_8.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_1.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_64.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_55.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_16.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_4.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_23.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_67.pdf
Converting pdf to png:  results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_1.pdf
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:00<04:35,  1.81it/s]  0%|          | 2/500 [00:01<04:17,  1.93it/s]  1%|          | 3/500 [00:01<04:28,  1.85it/s]  1%|          | 4/500 [00:04<12:24,  1.50s/it]  1%|          | 5/500 [00:04<08:54,  1.08s/it]  1%|          | 6/500 [00:05<06:35,  1.25it/s]  1%|▏         | 7/500 [00:05<05:50,  1.41it/s]  2%|▏         | 8/500 [00:05<04:32,  1.80it/s]  2%|▏         | 10/500 [00:06<02:52,  2.84it/s]  2%|▏         | 11/500 [00:06<03:46,  2.16it/s]  2%|▏         | 12/500 [00:07<03:36,  2.25it/s]  3%|▎         | 13/500 [00:10<09:15,  1.14s/it]  3%|▎         | 14/500 [00:13<13:23,  1.65s/it]  3%|▎         | 15/500 [00:13<10:08,  1.26s/it]  3%|▎         | 16/500 [00:13<08:02,  1.00it/s]  3%|▎         | 17/500 [00:14<05:55,  1.36it/s]  4%|▎         | 18/500 [00:14<04:37,  1.74it/s]  4%|▍         | 19/500 [00:14<04:29,  1.78it/s]  4%|▍         | 20/500 [00:15<04:35,  1.74it/s]  4%|▍         | 21/500 [00:15<03:43,  2.15it/s]  4%|▍         | 22/500 [00:15<03:21,  2.37it/s]  5%|▍         | 23/500 [00:18<09:25,  1.19s/it]  5%|▍         | 24/500 [00:19<07:04,  1.12it/s]  5%|▌         | 25/500 [00:22<12:01,  1.52s/it]  5%|▌         | 26/500 [00:22<08:52,  1.12s/it]  5%|▌         | 27/500 [00:23<08:23,  1.07s/it]  6%|▌         | 28/500 [00:26<13:13,  1.68s/it]  6%|▌         | 29/500 [00:26<10:00,  1.27s/it]  6%|▌         | 30/500 [00:27<08:10,  1.04s/it]  6%|▌         | 31/500 [00:27<06:23,  1.22it/s]  7%|▋         | 33/500 [00:28<05:00,  1.55it/s]  7%|▋         | 34/500 [00:28<04:41,  1.66it/s]  7%|▋         | 35/500 [00:31<09:30,  1.23s/it]  7%|▋         | 36/500 [00:31<07:14,  1.07it/s]  7%|▋         | 37/500 [00:32<05:51,  1.32it/s]  8%|▊         | 38/500 [00:35<10:47,  1.40s/it]  8%|▊         | 39/500 [00:38<14:16,  1.86s/it]  8%|▊         | 40/500 [00:38<11:08,  1.45s/it]  8%|▊         | 42/500 [00:39<07:24,  1.03it/s]  9%|▊         | 43/500 [00:39<06:31,  1.17it/s]  9%|▉         | 44/500 [00:40<06:14,  1.22it/s]  9%|▉         | 45/500 [00:40<04:55,  1.54it/s]  9%|▉         | 46/500 [00:41<04:36,  1.64it/s]  9%|▉         | 47/500 [00:44<09:44,  1.29s/it] 10%|▉         | 48/500 [00:44<07:52,  1.04s/it] 10%|▉         | 49/500 [00:45<06:25,  1.17it/s] 10%|█         | 50/500 [00:45<05:11,  1.44it/s] 10%|█         | 51/500 [00:45<04:20,  1.72it/s] 10%|█         | 52/500 [00:48<09:40,  1.30s/it] 11%|█         | 53/500 [00:48<07:06,  1.05it/s] 11%|█         | 54/500 [00:49<05:43,  1.30it/s] 11%|█         | 55/500 [00:49<04:59,  1.49it/s] 11%|█         | 56/500 [00:50<04:02,  1.83it/s] 11%|█▏        | 57/500 [00:50<03:39,  2.02it/s] 12%|█▏        | 58/500 [00:51<04:06,  1.79it/s] 12%|█▏        | 59/500 [00:51<04:32,  1.62it/s] 12%|█▏        | 60/500 [00:54<09:44,  1.33s/it] 12%|█▏        | 61/500 [00:55<07:39,  1.05s/it] 12%|█▏        | 62/500 [00:56<07:18,  1.00s/it] 13%|█▎        | 63/500 [00:56<05:49,  1.25it/s] 13%|█▎        | 64/500 [00:56<05:03,  1.44it/s] 13%|█▎        | 65/500 [00:57<04:23,  1.65it/s] 13%|█▎        | 66/500 [00:57<04:22,  1.65it/s] 13%|█▎        | 67/500 [00:58<03:33,  2.03it/s] 14%|█▎        | 68/500 [00:58<04:03,  1.77it/s] 14%|█▍        | 69/500 [00:59<04:15,  1.68it/s] 14%|█▍        | 70/500 [01:02<09:22,  1.31s/it] 14%|█▍        | 71/500 [01:03<08:02,  1.12s/it] 14%|█▍        | 72/500 [01:03<06:13,  1.15it/s] 15%|█▍        | 73/500 [01:03<05:11,  1.37it/s] 15%|█▍        | 74/500 [01:04<04:50,  1.47it/s] 15%|█▌        | 75/500 [01:07<09:40,  1.37s/it] 15%|█▌        | 76/500 [01:10<13:00,  1.84s/it] 15%|█▌        | 77/500 [01:10<09:42,  1.38s/it] 16%|█▌        | 78/500 [01:11<07:58,  1.13s/it] 16%|█▌        | 79/500 [01:11<06:11,  1.13it/s] 16%|█▌        | 80/500 [01:11<05:04,  1.38it/s] 16%|█▌        | 81/500 [01:13<06:07,  1.14it/s] 16%|█▋        | 82/500 [01:16<10:30,  1.51s/it] 17%|█▋        | 83/500 [01:16<08:12,  1.18s/it] 17%|█▋        | 84/500 [01:16<06:23,  1.09it/s] 17%|█▋        | 85/500 [01:19<10:37,  1.54s/it] 17%|█▋        | 86/500 [01:22<13:35,  1.97s/it] 17%|█▋        | 87/500 [01:23<10:42,  1.55s/it] 18%|█▊        | 88/500 [01:26<13:45,  2.00s/it] 18%|█▊        | 89/500 [01:26<10:37,  1.55s/it] 18%|█▊        | 90/500 [01:27<08:19,  1.22s/it] 18%|█▊        | 91/500 [01:28<07:54,  1.16s/it] 18%|█▊        | 92/500 [01:31<11:36,  1.71s/it] 19%|█▊        | 93/500 [01:31<09:00,  1.33s/it] 19%|█▉        | 94/500 [01:32<07:30,  1.11s/it] 19%|█▉        | 95/500 [01:32<06:08,  1.10it/s] 19%|█▉        | 96/500 [01:33<04:54,  1.37it/s] 19%|█▉        | 97/500 [01:33<03:51,  1.74it/s] 20%|█▉        | 98/500 [01:36<08:40,  1.30s/it] 20%|█▉        | 99/500 [01:36<07:17,  1.09s/it] 20%|██        | 100/500 [01:37<06:37,  1.01it/s] 20%|██        | 101/500 [01:38<05:18,  1.25it/s] 20%|██        | 102/500 [01:38<04:23,  1.51it/s] 21%|██        | 103/500 [01:39<04:51,  1.36it/s] 21%|██        | 104/500 [01:39<04:06,  1.61it/s] 21%|██        | 105/500 [01:42<08:44,  1.33s/it] 21%|██        | 106/500 [01:43<06:49,  1.04s/it] 21%|██▏       | 107/500 [01:46<10:37,  1.62s/it] 22%|██▏       | 108/500 [01:46<08:10,  1.25s/it] 22%|██▏       | 109/500 [01:46<06:14,  1.05it/s] 22%|██▏       | 110/500 [01:47<05:41,  1.14it/s] 22%|██▏       | 111/500 [01:47<05:08,  1.26it/s] 22%|██▏       | 112/500 [01:50<09:19,  1.44s/it] 23%|██▎       | 113/500 [01:51<07:21,  1.14s/it] 23%|██▎       | 114/500 [01:52<06:36,  1.03s/it] 23%|██▎       | 115/500 [01:52<05:42,  1.12it/s] 23%|██▎       | 116/500 [01:53<04:35,  1.40it/s] 23%|██▎       | 117/500 [01:53<03:50,  1.66it/s] 24%|██▎       | 118/500 [01:56<08:27,  1.33s/it] 24%|██▍       | 119/500 [01:56<06:30,  1.03s/it] 24%|██▍       | 120/500 [01:56<05:03,  1.25it/s] 24%|██▍       | 121/500 [01:57<03:52,  1.63it/s] 24%|██▍       | 122/500 [01:57<03:29,  1.81it/s] 25%|██▍       | 123/500 [01:58<04:13,  1.49it/s] 25%|██▍       | 124/500 [01:59<04:07,  1.52it/s] 25%|██▌       | 125/500 [02:00<05:32,  1.13it/s] 25%|██▌       | 126/500 [02:01<04:45,  1.31it/s] 25%|██▌       | 127/500 [02:04<08:56,  1.44s/it] 26%|██▌       | 128/500 [02:04<07:16,  1.17s/it] 26%|██▌       | 129/500 [02:04<05:47,  1.07it/s] 26%|██▌       | 130/500 [02:05<05:18,  1.16it/s] 26%|██▌       | 131/500 [02:05<03:53,  1.58it/s] 26%|██▋       | 132/500 [02:06<03:15,  1.88it/s] 27%|██▋       | 133/500 [02:06<02:48,  2.18it/s] 27%|██▋       | 135/500 [02:06<02:03,  2.95it/s] 27%|██▋       | 136/500 [02:06<01:49,  3.31it/s] 27%|██▋       | 137/500 [02:07<02:05,  2.90it/s] 28%|██▊       | 138/500 [02:07<02:13,  2.70it/s] 28%|██▊       | 139/500 [02:08<02:37,  2.30it/s] 28%|██▊       | 140/500 [02:09<03:18,  1.82it/s] 28%|██▊       | 141/500 [02:09<02:53,  2.07it/s] 28%|██▊       | 142/500 [02:09<02:41,  2.22it/s] 29%|██▊       | 143/500 [02:10<02:20,  2.54it/s] 29%|██▉       | 144/500 [02:10<02:15,  2.62it/s] 29%|██▉       | 145/500 [02:10<02:06,  2.80it/s] 29%|██▉       | 146/500 [02:11<01:48,  3.25it/s] 29%|██▉       | 147/500 [02:11<02:01,  2.92it/s] 30%|██▉       | 148/500 [02:12<02:31,  2.33it/s] 30%|██▉       | 149/500 [02:12<01:57,  3.00it/s] 30%|███       | 151/500 [02:12<01:46,  3.27it/s] 30%|███       | 152/500 [02:13<01:54,  3.05it/s] 31%|███       | 153/500 [02:13<02:00,  2.88it/s] 31%|███       | 154/500 [02:16<06:11,  1.07s/it] 31%|███       | 155/500 [02:16<05:05,  1.13it/s] 31%|███       | 156/500 [02:17<03:59,  1.43it/s] 31%|███▏      | 157/500 [02:20<07:55,  1.39s/it] 32%|███▏      | 158/500 [02:23<10:43,  1.88s/it] 32%|███▏      | 159/500 [02:23<08:14,  1.45s/it] 32%|███▏      | 160/500 [02:23<06:05,  1.08s/it] 32%|███▏      | 161/500 [02:24<04:51,  1.16it/s] 32%|███▏      | 162/500 [02:25<05:48,  1.03s/it] 33%|███▎      | 163/500 [02:25<04:24,  1.28it/s] 33%|███▎      | 164/500 [02:26<03:26,  1.63it/s] 33%|███▎      | 165/500 [02:26<03:37,  1.54it/s] 33%|███▎      | 166/500 [02:27<02:46,  2.01it/s] 33%|███▎      | 167/500 [02:27<02:08,  2.60it/s] 34%|███▍      | 169/500 [02:28<02:27,  2.24it/s] 34%|███▍      | 171/500 [02:28<02:09,  2.55it/s] 34%|███▍      | 172/500 [02:28<01:47,  3.05it/s] 35%|███▍      | 173/500 [02:29<01:40,  3.26it/s] 35%|███▍      | 174/500 [02:29<02:04,  2.62it/s] 35%|███▌      | 175/500 [02:29<01:44,  3.12it/s] 35%|███▌      | 176/500 [02:30<02:04,  2.61it/s] 35%|███▌      | 177/500 [02:33<06:04,  1.13s/it] 36%|███▌      | 178/500 [02:33<04:30,  1.19it/s] 36%|███▌      | 179/500 [02:34<04:47,  1.12it/s] 36%|███▌      | 180/500 [02:37<08:03,  1.51s/it] 36%|███▌      | 181/500 [02:37<05:58,  1.12s/it] 36%|███▋      | 182/500 [02:38<04:40,  1.13it/s] 37%|███▋      | 183/500 [02:38<03:56,  1.34it/s] 37%|███▋      | 184/500 [02:39<03:30,  1.50it/s] 37%|███▋      | 185/500 [02:42<07:10,  1.37s/it] 37%|███▋      | 186/500 [02:43<06:29,  1.24s/it] 37%|███▋      | 187/500 [02:43<04:49,  1.08it/s] 38%|███▊      | 188/500 [02:44<05:19,  1.02s/it] 38%|███▊      | 189/500 [02:45<04:40,  1.11it/s] 38%|███▊      | 191/500 [02:45<03:02,  1.70it/s] 38%|███▊      | 192/500 [02:48<06:07,  1.19s/it] 39%|███▊      | 193/500 [02:51<08:32,  1.67s/it] 39%|███▉      | 194/500 [02:51<06:37,  1.30s/it] 39%|███▉      | 195/500 [02:52<05:23,  1.06s/it] 39%|███▉      | 196/500 [02:52<04:34,  1.11it/s] 39%|███▉      | 197/500 [02:53<04:34,  1.10it/s] 40%|███▉      | 198/500 [02:53<03:29,  1.44it/s] 40%|███▉      | 199/500 [02:56<06:54,  1.38s/it] 40%|████      | 200/500 [02:57<05:23,  1.08s/it] 40%|████      | 201/500 [02:57<04:22,  1.14it/s] 40%|████      | 202/500 [02:58<03:41,  1.35it/s] 41%|████      | 203/500 [02:58<02:44,  1.80it/s] 41%|████      | 204/500 [02:58<02:41,  1.83it/s] 41%|████      | 205/500 [02:59<02:26,  2.02it/s] 41%|████      | 206/500 [03:00<02:59,  1.64it/s] 41%|████▏     | 207/500 [03:00<03:17,  1.48it/s] 42%|████▏     | 208/500 [03:01<02:44,  1.78it/s] 42%|████▏     | 209/500 [03:01<02:10,  2.24it/s] 42%|████▏     | 210/500 [03:01<02:05,  2.32it/s] 42%|████▏     | 211/500 [03:03<03:24,  1.41it/s] 42%|████▏     | 212/500 [03:03<02:48,  1.71it/s] 43%|████▎     | 213/500 [03:06<06:20,  1.33s/it] 43%|████▎     | 215/500 [03:07<04:11,  1.13it/s] 43%|████▎     | 216/500 [03:08<04:35,  1.03it/s] 43%|████▎     | 217/500 [03:11<07:04,  1.50s/it] 44%|████▎     | 218/500 [03:11<05:40,  1.21s/it] 44%|████▍     | 219/500 [03:11<04:18,  1.09it/s] 44%|████▍     | 220/500 [03:12<03:44,  1.25it/s] 44%|████▍     | 221/500 [03:13<03:20,  1.39it/s] 45%|████▍     | 224/500 [03:13<02:14,  2.05it/s] 45%|████▌     | 225/500 [03:14<02:18,  1.98it/s] 45%|████▌     | 226/500 [03:14<02:14,  2.04it/s] 45%|████▌     | 227/500 [03:17<05:04,  1.11s/it] 46%|████▌     | 228/500 [03:18<04:08,  1.09it/s] 46%|████▌     | 229/500 [03:18<03:33,  1.27it/s] 46%|████▌     | 230/500 [03:18<02:41,  1.67it/s] 46%|████▌     | 231/500 [03:19<02:21,  1.91it/s] 46%|████▋     | 232/500 [03:19<02:18,  1.94it/s] 47%|████▋     | 233/500 [03:20<02:21,  1.88it/s] 47%|████▋     | 234/500 [03:21<03:25,  1.29it/s] 47%|████▋     | 235/500 [03:22<02:57,  1.49it/s] 47%|████▋     | 236/500 [03:25<06:05,  1.38s/it] 47%|████▋     | 237/500 [03:25<04:58,  1.13s/it] 48%|████▊     | 238/500 [03:26<04:07,  1.06it/s] 48%|████▊     | 239/500 [03:26<03:06,  1.40it/s] 48%|████▊     | 240/500 [03:29<06:02,  1.40s/it] 48%|████▊     | 241/500 [03:29<04:36,  1.07s/it] 48%|████▊     | 242/500 [03:31<06:08,  1.43s/it] 49%|████▊     | 243/500 [03:32<04:27,  1.04s/it] 49%|████▉     | 244/500 [03:32<03:18,  1.29it/s] 49%|████▉     | 245/500 [03:32<02:44,  1.55it/s] 49%|████▉     | 246/500 [03:35<05:40,  1.34s/it] 50%|████▉     | 248/500 [03:35<03:25,  1.22it/s] 50%|█████     | 250/500 [03:35<02:08,  1.94it/s] 50%|█████     | 251/500 [03:36<02:23,  1.74it/s] 51%|█████     | 253/500 [03:37<01:51,  2.22it/s] 51%|█████     | 254/500 [03:37<01:56,  2.12it/s] 51%|█████     | 255/500 [03:37<01:35,  2.56it/s] 51%|█████     | 256/500 [03:38<01:32,  2.65it/s] 51%|█████▏    | 257/500 [03:38<01:14,  3.26it/s] 52%|█████▏    | 258/500 [03:38<01:07,  3.56it/s] 52%|█████▏    | 259/500 [03:39<01:34,  2.55it/s] 52%|█████▏    | 260/500 [03:42<04:32,  1.14s/it] 52%|█████▏    | 261/500 [03:42<03:46,  1.06it/s] 52%|█████▏    | 262/500 [03:43<03:28,  1.14it/s] 53%|█████▎    | 263/500 [03:43<02:47,  1.41it/s] 53%|█████▎    | 264/500 [03:44<02:32,  1.55it/s] 53%|█████▎    | 265/500 [03:44<02:01,  1.94it/s] 53%|█████▎    | 266/500 [03:47<04:52,  1.25s/it] 53%|█████▎    | 267/500 [03:50<06:51,  1.77s/it] 54%|█████▎    | 268/500 [03:53<08:13,  2.13s/it] 54%|█████▍    | 269/500 [03:53<05:59,  1.56s/it] 54%|█████▍    | 270/500 [03:54<05:20,  1.39s/it] 54%|█████▍    | 271/500 [03:54<04:06,  1.08s/it] 54%|█████▍    | 272/500 [03:57<06:14,  1.64s/it] 55%|█████▍    | 273/500 [03:58<05:06,  1.35s/it] 55%|█████▍    | 274/500 [03:59<04:03,  1.08s/it] 55%|█████▌    | 275/500 [04:02<06:11,  1.65s/it] 55%|█████▌    | 276/500 [04:02<04:26,  1.19s/it] 55%|█████▌    | 277/500 [04:02<03:22,  1.10it/s] 56%|█████▌    | 278/500 [04:03<03:38,  1.02it/s] 56%|█████▌    | 279/500 [04:06<05:49,  1.58s/it] 56%|█████▌    | 281/500 [04:07<04:04,  1.12s/it] 56%|█████▋    | 282/500 [04:10<05:43,  1.58s/it] 57%|█████▋    | 283/500 [04:10<04:21,  1.21s/it] 57%|█████▋    | 284/500 [04:11<03:24,  1.06it/s] 57%|█████▋    | 285/500 [04:11<02:39,  1.35it/s] 57%|█████▋    | 286/500 [04:14<04:55,  1.38s/it] 57%|█████▋    | 287/500 [04:17<06:31,  1.84s/it] 58%|█████▊    | 288/500 [04:17<05:04,  1.44s/it] 58%|█████▊    | 289/500 [04:18<04:10,  1.19s/it] 58%|█████▊    | 290/500 [04:18<03:01,  1.15it/s] 58%|█████▊    | 291/500 [04:19<03:00,  1.16it/s] 59%|█████▊    | 293/500 [04:20<02:14,  1.54it/s] 59%|█████▉    | 294/500 [04:20<02:06,  1.63it/s] 59%|█████▉    | 295/500 [04:20<01:41,  2.03it/s] 59%|█████▉    | 296/500 [04:21<01:35,  2.15it/s] 59%|█████▉    | 297/500 [04:21<01:33,  2.18it/s] 60%|█████▉    | 298/500 [04:21<01:19,  2.55it/s] 60%|█████▉    | 299/500 [04:22<01:24,  2.37it/s] 60%|██████    | 300/500 [04:22<01:15,  2.66it/s] 60%|██████    | 301/500 [04:22<01:13,  2.71it/s] 60%|██████    | 302/500 [04:25<03:47,  1.15s/it] 61%|██████    | 303/500 [04:26<03:10,  1.04it/s] 61%|██████    | 304/500 [04:26<02:30,  1.30it/s] 61%|██████    | 305/500 [04:27<02:38,  1.23it/s] 61%|██████    | 306/500 [04:28<02:40,  1.21it/s] 61%|██████▏   | 307/500 [04:29<02:30,  1.28it/s] 62%|██████▏   | 308/500 [04:32<04:59,  1.56s/it] 62%|██████▏   | 309/500 [04:32<03:47,  1.19s/it] 62%|██████▏   | 310/500 [04:33<02:48,  1.13it/s] 62%|██████▏   | 311/500 [04:33<02:08,  1.48it/s] 62%|██████▏   | 312/500 [04:33<01:48,  1.73it/s] 63%|██████▎   | 313/500 [04:33<01:35,  1.96it/s] 63%|██████▎   | 314/500 [04:34<01:47,  1.73it/s] 63%|██████▎   | 315/500 [04:35<02:05,  1.48it/s] 63%|██████▎   | 316/500 [04:35<01:32,  1.98it/s] 63%|██████▎   | 317/500 [04:35<01:13,  2.48it/s] 64%|██████▎   | 318/500 [04:36<01:06,  2.72it/s] 64%|██████▍   | 319/500 [04:36<00:53,  3.36it/s] 64%|██████▍   | 320/500 [04:36<00:54,  3.28it/s] 64%|██████▍   | 321/500 [04:39<03:18,  1.11s/it] 64%|██████▍   | 322/500 [04:39<02:38,  1.12it/s] 65%|██████▍   | 323/500 [04:40<02:00,  1.47it/s] 65%|██████▍   | 324/500 [04:40<01:59,  1.47it/s] 65%|██████▌   | 325/500 [04:41<01:46,  1.65it/s] 65%|██████▌   | 326/500 [04:41<01:36,  1.80it/s] 65%|██████▌   | 327/500 [04:42<01:24,  2.06it/s] 66%|██████▌   | 329/500 [04:45<02:44,  1.04it/s] 66%|██████▌   | 330/500 [04:45<02:30,  1.13it/s] 66%|██████▌   | 331/500 [04:45<02:00,  1.40it/s] 66%|██████▋   | 332/500 [04:46<01:35,  1.76it/s] 67%|██████▋   | 333/500 [04:49<03:27,  1.24s/it] 67%|██████▋   | 334/500 [04:49<03:04,  1.11s/it] 67%|██████▋   | 335/500 [04:52<04:32,  1.65s/it] 67%|██████▋   | 336/500 [04:53<03:42,  1.36s/it] 67%|██████▋   | 337/500 [04:53<02:58,  1.09s/it] 68%|██████▊   | 338/500 [04:56<04:28,  1.66s/it] 68%|██████▊   | 339/500 [04:57<03:24,  1.27s/it] 68%|██████▊   | 340/500 [04:57<02:30,  1.06it/s] 68%|██████▊   | 341/500 [04:57<02:02,  1.30it/s] 68%|██████▊   | 342/500 [04:58<01:42,  1.55it/s] 69%|██████▊   | 343/500 [05:01<03:31,  1.35s/it] 69%|██████▉   | 344/500 [05:04<04:46,  1.84s/it] 69%|██████▉   | 345/500 [05:04<03:32,  1.37s/it] 69%|██████▉   | 346/500 [05:07<04:46,  1.86s/it] 69%|██████▉   | 347/500 [05:10<05:36,  2.20s/it] 70%|██████▉   | 348/500 [05:10<04:13,  1.66s/it] 70%|██████▉   | 349/500 [05:11<03:36,  1.44s/it] 70%|███████   | 350/500 [05:12<02:44,  1.09s/it] 70%|███████   | 351/500 [05:12<02:06,  1.18it/s] 70%|███████   | 352/500 [05:12<01:32,  1.60it/s] 71%|███████   | 353/500 [05:12<01:18,  1.88it/s] 71%|███████   | 354/500 [05:13<01:23,  1.75it/s] 71%|███████   | 355/500 [05:16<03:09,  1.31s/it] 71%|███████   | 356/500 [05:16<02:32,  1.06s/it] 71%|███████▏  | 357/500 [05:17<02:12,  1.08it/s] 72%|███████▏  | 358/500 [05:17<01:41,  1.39it/s] 72%|███████▏  | 359/500 [05:18<01:21,  1.72it/s] 72%|███████▏  | 360/500 [05:18<01:15,  1.84it/s] 72%|███████▏  | 361/500 [05:18<01:08,  2.02it/s] 72%|███████▏  | 362/500 [05:19<01:02,  2.22it/s] 73%|███████▎  | 363/500 [05:22<02:48,  1.23s/it] 73%|███████▎  | 364/500 [05:22<02:15,  1.01it/s] 73%|███████▎  | 365/500 [05:24<02:30,  1.12s/it] 73%|███████▎  | 367/500 [05:24<01:32,  1.43it/s] 74%|███████▎  | 368/500 [05:24<01:13,  1.81it/s] 74%|███████▍  | 369/500 [05:25<01:08,  1.92it/s] 74%|███████▍  | 370/500 [05:25<01:05,  1.99it/s] 74%|███████▍  | 371/500 [05:25<01:00,  2.14it/s] 74%|███████▍  | 372/500 [05:26<00:57,  2.22it/s] 75%|███████▍  | 373/500 [05:27<01:13,  1.72it/s] 75%|███████▍  | 374/500 [05:27<01:11,  1.76it/s] 75%|███████▌  | 375/500 [05:28<01:05,  1.92it/s] 75%|███████▌  | 376/500 [05:31<02:35,  1.25s/it] 75%|███████▌  | 377/500 [05:31<01:55,  1.07it/s] 76%|███████▌  | 378/500 [05:31<01:43,  1.18it/s] 76%|███████▌  | 379/500 [05:32<01:44,  1.16it/s] 76%|███████▌  | 380/500 [05:33<01:29,  1.35it/s] 76%|███████▌  | 381/500 [05:33<01:17,  1.54it/s] 76%|███████▋  | 382/500 [05:36<02:40,  1.36s/it] 77%|███████▋  | 383/500 [05:37<02:11,  1.12s/it] 77%|███████▋  | 384/500 [05:38<02:04,  1.07s/it] 77%|███████▋  | 385/500 [05:38<01:41,  1.13it/s] 77%|███████▋  | 387/500 [05:39<01:03,  1.77it/s] 78%|███████▊  | 388/500 [05:39<00:59,  1.90it/s] 78%|███████▊  | 389/500 [05:39<00:53,  2.09it/s] 78%|███████▊  | 390/500 [05:40<00:50,  2.19it/s] 78%|███████▊  | 391/500 [05:43<02:08,  1.18s/it] 78%|███████▊  | 392/500 [05:43<01:46,  1.02it/s] 79%|███████▊  | 393/500 [05:43<01:19,  1.35it/s] 79%|███████▉  | 394/500 [05:44<00:59,  1.79it/s] 79%|███████▉  | 395/500 [05:44<00:59,  1.78it/s] 79%|███████▉  | 396/500 [05:44<00:47,  2.20it/s] 79%|███████▉  | 397/500 [05:45<00:52,  1.95it/s] 80%|███████▉  | 398/500 [05:48<02:08,  1.26s/it] 80%|███████▉  | 399/500 [05:48<01:40,  1.01it/s] 80%|████████  | 400/500 [05:49<01:16,  1.31it/s] 80%|████████  | 401/500 [05:49<01:07,  1.46it/s] 80%|████████  | 402/500 [05:49<00:55,  1.76it/s] 81%|████████  | 403/500 [05:50<00:59,  1.62it/s] 81%|████████  | 404/500 [05:53<02:07,  1.33s/it] 81%|████████  | 405/500 [05:54<01:39,  1.04s/it] 81%|████████  | 406/500 [05:54<01:15,  1.25it/s] 81%|████████▏ | 407/500 [05:54<00:58,  1.60it/s] 82%|████████▏ | 408/500 [05:54<00:47,  1.93it/s] 82%|████████▏ | 409/500 [05:57<01:55,  1.27s/it] 82%|████████▏ | 410/500 [05:58<01:27,  1.03it/s] 82%|████████▏ | 411/500 [05:58<01:08,  1.30it/s] 82%|████████▏ | 412/500 [05:58<01:03,  1.38it/s] 83%|████████▎ | 413/500 [05:59<00:56,  1.54it/s] 83%|████████▎ | 414/500 [05:59<00:48,  1.76it/s] 83%|████████▎ | 415/500 [06:00<00:48,  1.76it/s] 83%|████████▎ | 416/500 [06:03<01:48,  1.29s/it] 83%|████████▎ | 417/500 [06:03<01:25,  1.03s/it] 84%|████████▎ | 418/500 [06:04<01:05,  1.26it/s] 84%|████████▍ | 419/500 [06:04<00:48,  1.68it/s] 84%|████████▍ | 420/500 [06:04<00:43,  1.84it/s] 84%|████████▍ | 421/500 [06:05<00:40,  1.96it/s] 84%|████████▍ | 422/500 [06:07<01:37,  1.24s/it] 85%|████████▍ | 423/500 [06:10<02:14,  1.75s/it] 85%|████████▍ | 424/500 [06:11<01:46,  1.40s/it] 85%|████████▌ | 425/500 [06:11<01:19,  1.06s/it] 85%|████████▌ | 426/500 [06:12<01:14,  1.01s/it] 85%|████████▌ | 427/500 [06:15<01:56,  1.60s/it] 86%|████████▌ | 428/500 [06:16<01:32,  1.29s/it] 86%|████████▌ | 429/500 [06:16<01:13,  1.04s/it] 86%|████████▌ | 431/500 [06:19<01:26,  1.26s/it] 86%|████████▋ | 432/500 [06:22<01:54,  1.69s/it] 87%|████████▋ | 433/500 [06:25<02:15,  2.03s/it] 87%|████████▋ | 434/500 [06:26<01:50,  1.67s/it] 87%|████████▋ | 435/500 [06:28<01:58,  1.83s/it] 87%|████████▋ | 436/500 [06:28<01:27,  1.36s/it] 87%|████████▋ | 437/500 [06:29<01:11,  1.13s/it] 88%|████████▊ | 439/500 [06:29<00:40,  1.52it/s] 88%|████████▊ | 440/500 [06:29<00:33,  1.80it/s] 88%|████████▊ | 441/500 [06:30<00:29,  2.02it/s] 88%|████████▊ | 442/500 [06:33<01:07,  1.16s/it] 89%|████████▊ | 443/500 [06:33<00:49,  1.14it/s] 89%|████████▉ | 444/500 [06:34<00:49,  1.13it/s] 89%|████████▉ | 446/500 [06:34<00:35,  1.53it/s] 89%|████████▉ | 447/500 [06:37<01:04,  1.22s/it] 90%|████████▉ | 448/500 [06:37<00:49,  1.06it/s] 90%|████████▉ | 449/500 [06:38<00:40,  1.27it/s] 90%|█████████ | 450/500 [06:38<00:31,  1.57it/s] 90%|█████████ | 451/500 [06:38<00:26,  1.84it/s] 90%|█████████ | 452/500 [06:39<00:23,  2.04it/s] 91%|█████████ | 453/500 [06:39<00:21,  2.20it/s] 91%|█████████ | 454/500 [06:40<00:23,  1.99it/s] 91%|█████████ | 455/500 [06:43<00:55,  1.24s/it] 91%|█████████ | 456/500 [06:43<00:45,  1.04s/it] 91%|█████████▏| 457/500 [06:44<00:35,  1.20it/s] 92%|█████████▏| 458/500 [06:44<00:29,  1.42it/s] 92%|█████████▏| 459/500 [06:45<00:28,  1.46it/s] 92%|█████████▏| 460/500 [06:45<00:23,  1.72it/s] 92%|█████████▏| 461/500 [06:45<00:18,  2.16it/s] 92%|█████████▏| 462/500 [06:47<00:34,  1.10it/s] 93%|█████████▎| 463/500 [06:48<00:28,  1.30it/s] 93%|█████████▎| 464/500 [06:51<00:51,  1.44s/it] 93%|█████████▎| 465/500 [06:51<00:37,  1.08s/it] 93%|█████████▎| 466/500 [06:51<00:27,  1.24it/s] 94%|█████████▎| 468/500 [06:52<00:23,  1.38it/s] 94%|█████████▍| 469/500 [06:55<00:39,  1.29s/it] 94%|█████████▍| 470/500 [06:56<00:32,  1.08s/it] 94%|█████████▍| 471/500 [06:56<00:24,  1.19it/s] 94%|█████████▍| 472/500 [06:56<00:18,  1.49it/s] 95%|█████████▍| 473/500 [06:59<00:35,  1.33s/it] 95%|█████████▍| 474/500 [06:59<00:26,  1.01s/it] 95%|█████████▌| 475/500 [07:00<00:24,  1.02it/s] 95%|█████████▌| 476/500 [07:03<00:37,  1.57s/it] 95%|█████████▌| 477/500 [07:06<00:45,  1.99s/it] 96%|█████████▌| 478/500 [07:07<00:33,  1.52s/it] 96%|█████████▌| 479/500 [07:07<00:25,  1.23s/it] 96%|█████████▌| 480/500 [07:08<00:23,  1.19s/it] 96%|█████████▌| 481/500 [07:10<00:23,  1.26s/it] 96%|█████████▋| 482/500 [07:10<00:18,  1.01s/it] 97%|█████████▋| 483/500 [07:10<00:13,  1.25it/s] 97%|█████████▋| 484/500 [07:11<00:13,  1.22it/s] 97%|█████████▋| 485/500 [07:12<00:09,  1.52it/s] 97%|█████████▋| 486/500 [07:12<00:08,  1.68it/s] 97%|█████████▋| 487/500 [07:12<00:06,  1.93it/s] 98%|█████████▊| 488/500 [07:13<00:05,  2.07it/s] 98%|█████████▊| 489/500 [07:16<00:13,  1.24s/it] 98%|█████████▊| 490/500 [07:16<00:09,  1.07it/s] 98%|█████████▊| 491/500 [07:19<00:13,  1.55s/it] 98%|█████████▊| 492/500 [07:20<00:09,  1.24s/it] 99%|█████████▊| 493/500 [07:20<00:07,  1.01s/it] 99%|█████████▉| 494/500 [07:20<00:05,  1.19it/s] 99%|█████████▉| 495/500 [07:21<00:03,  1.53it/s] 99%|█████████▉| 496/500 [07:24<00:05,  1.39s/it] 99%|█████████▉| 497/500 [07:24<00:03,  1.07s/it]100%|█████████▉| 498/500 [07:25<00:01,  1.14it/s]100%|█████████▉| 499/500 [07:25<00:00,  1.12it/s]100%|██████████| 500/500 [07:29<00:00,  1.54s/it]100%|██████████| 500/500 [07:29<00:00,  1.11it/s]
  0%|          | 0/21 [00:00<?, ?it/s]  5%|▍         | 1/21 [00:32<10:59, 32.97s/it] 10%|▉         | 2/21 [01:17<12:32, 39.61s/it] 14%|█▍        | 3/21 [01:27<07:53, 26.30s/it] 19%|█▉        | 4/21 [01:55<07:38, 26.95s/it] 24%|██▍       | 5/21 [02:18<06:49, 25.61s/it] 29%|██▊       | 6/21 [02:55<07:20, 29.39s/it] 33%|███▎      | 7/21 [03:09<05:40, 24.35s/it] 38%|███▊      | 8/21 [03:21<04:25, 20.42s/it] 43%|████▎     | 9/21 [03:30<03:21, 16.83s/it] 48%|████▊     | 10/21 [04:23<05:06, 27.85s/it] 52%|█████▏    | 11/21 [04:50<04:36, 27.61s/it] 57%|█████▋    | 12/21 [05:05<03:35, 23.96s/it]originial_png_file: dataset/ori_500/bar_69.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_69.png
originial_png_file: dataset/ori_500/scatter_21.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_21.png
originial_png_file: dataset/ori_500/bar_63.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_63.png
originial_png_file: dataset/ori_500/HR_17.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_17.png
originial_png_file: dataset/ori_500/HR_20.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_20.png
originial_png_file: dataset/ori_500/density_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_1.png
originial_png_file: dataset/ori_500/CB_30.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_30.png
originial_png_file: dataset/ori_500/errorbar_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_5.png
originial_png_file: dataset/ori_500/HR_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_10.png
originial_png_file: dataset/ori_500/hist_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_13.png
originial_png_file: dataset/ori_500/3d_15.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_15.png
originial_png_file: dataset/ori_500/PIP_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_8.png
originial_png_file: dataset/ori_500/errorbar_26.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_26.png
originial_png_file: dataset/ori_500/bar_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_3.png
originial_png_file: dataset/ori_500/HR_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_6.png
originial_png_file: dataset/ori_500/line_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_10.png
originial_png_file: dataset/ori_500/quiver_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_1.png
originial_png_file: dataset/ori_500/line_28.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_28.png
originial_png_file: dataset/ori_500/errorbar_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_2.png
originial_png_file: dataset/ori_500/line_39.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_39.png
originial_png_file: dataset/ori_500/bar_36.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_36.png
originial_png_file: dataset/ori_500/scatter_22.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_22.png
originial_png_file: dataset/ori_500/CB_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_1.png
originial_png_file: dataset/ori_500/line_42.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_42.png
originial_png_file: dataset/ori_500/bar_97.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_97.png
originial_png_file: dataset/ori_500/bar_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_7.png
originial_png_file: dataset/ori_500/bar_57.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_57.png
originial_png_file: dataset/ori_500/bar_55.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_55.png
originial_png_file: dataset/ori_500/bar_73.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_73.png
originial_png_file: dataset/ori_500/errorbar_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_3.png
originial_png_file: dataset/ori_500/bar_42.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_42.png
originial_png_file: dataset/ori_500/hist_20.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_20.png
originial_png_file: dataset/ori_500/violin_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_3.png
originial_png_file: dataset/ori_500/bar_91.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_91.png
originial_png_file: dataset/ori_500/density_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_4.png
originial_png_file: dataset/ori_500/HR_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_9.png
originial_png_file: dataset/ori_500/bar_30.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_30.png
originial_png_file: dataset/ori_500/violin_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_7.png
originial_png_file: dataset/ori_500/line_53.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_53.png
originial_png_file: dataset/ori_500/pie_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_13.png
originial_png_file: dataset/ori_500/scatter_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_1.png
originial_png_file: dataset/ori_500/PIP_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_7.png
originial_png_file: dataset/ori_500/scatter_19.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_19.png
originial_png_file: dataset/ori_500/bar_70.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_70.png
originial_png_file: dataset/ori_500/pie_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_9.png
originial_png_file: dataset/ori_500/bar_59.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_59.png
originial_png_file: dataset/ori_500/bar_16.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_16.png
originial_png_file: dataset/ori_500/bar_24.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_24.png
originial_png_file: dataset/ori_500/tree_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_3.png
originial_png_file: dataset/ori_500/errorbar_20.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_20.png
originial_png_file: dataset/ori_500/errorbar_16.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_16.png
originial_png_file: dataset/ori_500/CB_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_13.png
originial_png_file: dataset/ori_500/bar_11.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_11.png
originial_png_file: dataset/ori_500/line_49.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_49.png
originial_png_file: dataset/ori_500/box_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_10.png
originial_png_file: dataset/ori_500/line_25.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_25.png
originial_png_file: dataset/ori_500/errorpoint_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_7.png
originial_png_file: dataset/ori_500/box_25.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_25.png
originial_png_file: dataset/ori_500/bar_82.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_82.png
originial_png_file: dataset/ori_500/heatmap_20.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_20.png
originial_png_file: dataset/ori_500/pie_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_8.png
originial_png_file: dataset/ori_500/line_55.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_55.png
originial_png_file: dataset/ori_500/bar_33.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_33.png
originial_png_file: dataset/ori_500/bar_31.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_31.png
originial_png_file: dataset/ori_500/box_19.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_19.png
originial_png_file: dataset/ori_500/errorbar_22.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_22.png
originial_png_file: dataset/ori_500/bar_72.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_72.png
originial_png_file: dataset/ori_500/heatmap_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_3.png
originial_png_file: dataset/ori_500/scatter_16.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_16.png
originial_png_file: dataset/ori_500/line_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_4.png
originial_png_file: dataset/ori_500/bar_28.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_28.png
originial_png_file: dataset/ori_500/errorpoint_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_4.png
originial_png_file: dataset/ori_500/line_33.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_33.png
originial_png_file: dataset/ori_500/radar_19.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_19.png
originial_png_file: dataset/ori_500/multidiff_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_2.png
originial_png_file: dataset/ori_500/CB_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_6.png
originial_png_file: dataset/ori_500/line_59.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_59.png
originial_png_file: dataset/ori_500/heatmap_26.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_26.png
originial_png_file: dataset/ori_500/hist_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_9.png
originial_png_file: dataset/ori_500/bar_74.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_74.png
originial_png_file: dataset/ori_500/line_21.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_21.png
originial_png_file: dataset/ori_500/errorpoint_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_2.png
originial_png_file: dataset/ori_500/multidiff_23.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_23.png
originial_png_file: dataset/ori_500/density_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/density_5.png
originial_png_file: dataset/ori_500/scatter_24.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_24.png
originial_png_file: dataset/ori_500/bar_83.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_83.png
originial_png_file: dataset/ori_500/bar_66.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_66.png
originial_png_file: dataset/ori_500/box_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_2.png
originial_png_file: dataset/ori_500/errorpoint_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_3.png
originial_png_file: dataset/ori_500/bar_79.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_79.png
originial_png_file: dataset/ori_500/CB_27.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_27.png
originial_png_file: dataset/ori_500/multidiff_15.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_15.png
originial_png_file: dataset/ori_500/scatter_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_12.png
originial_png_file: dataset/ori_500/multidiff_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_8.png
originial_png_file: dataset/ori_500/3d_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_6.png
originial_png_file: dataset/ori_500/pie_15.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_15.png
originial_png_file: dataset/ori_500/line_68.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_68.png
originial_png_file: dataset/ori_500/multidiff_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_1.png
originial_png_file: dataset/ori_500/radar_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_6.png
originial_png_file: dataset/ori_500/heatmap_18.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_18.png
originial_png_file: dataset/ori_500/bar_27.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_27.png
originial_png_file: dataset/ori_500/HR_21.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_21.png
originial_png_file: dataset/ori_500/multidiff_16.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_16.png
originial_png_file: dataset/ori_500/bar_52.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_52.png
originial_png_file: dataset/ori_500/box_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_8.png
originial_png_file: dataset/ori_500/pie_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_10.png
originial_png_file: dataset/ori_500/HR_16.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_16.png
originial_png_file: dataset/ori_500/violin_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_6.png
originial_png_file: dataset/ori_500/line_31.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_31.png
originial_png_file: dataset/ori_500/line_61.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_61.png
originial_png_file: dataset/ori_500/bar_19.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_19.png
originial_png_file: dataset/ori_500/line_22.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_22.png
originial_png_file: dataset/ori_500/bar_68.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_68.png
originial_png_file: dataset/ori_500/box_15.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_15.png
Request timed out.
originial_png_file: dataset/ori_500/line_74.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_74.png
originial_png_file: dataset/ori_500/HR_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_5.png
originial_png_file: dataset/ori_500/CB_23.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_23.png
originial_png_file: dataset/ori_500/heatmap_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_1.png
originial_png_file: dataset/ori_500/bar_65.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_65.png
originial_png_file: dataset/ori_500/CB_11.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_11.png
originial_png_file: dataset/ori_500/bar_47.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_47.png
originial_png_file: dataset/ori_500/bar_44.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_44.png
originial_png_file: dataset/ori_500/PIP_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_4.png
 62%|██████▏   | 13/21 [15:34<27:37, 207.17s/it] 67%|██████▋   | 14/21 [15:53<17:32, 150.32s/it] 71%|███████▏  | 15/21 [16:01<10:45, 107.52s/it]originial_png_file: dataset/ori_500/bar_39.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_39.png
originial_png_file: dataset/ori_500/radar_14.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_14.png
originial_png_file: dataset/ori_500/scatter_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_13.png
originial_png_file: dataset/ori_500/line_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_1.png
originial_png_file: dataset/ori_500/CB_17.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_17.png
originial_png_file: dataset/ori_500/heatmap_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_4.png
originial_png_file: dataset/ori_500/bar_29.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_29.png
originial_png_file: dataset/ori_500/scatter_23.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_23.png
originial_png_file: dataset/ori_500/box_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_3.png
originial_png_file: dataset/ori_500/hist_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_3.png
originial_png_file: dataset/ori_500/radar_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_12.png
originial_png_file: dataset/ori_500/PIP_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_10.png
originial_png_file: dataset/ori_500/radar_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_2.png
originial_png_file: dataset/ori_500/line_50.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_50.png
originial_png_file: dataset/ori_500/line_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_6.png
originial_png_file: dataset/ori_500/box_22.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_22.png
originial_png_file: dataset/ori_500/bar_15.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_15.png
originial_png_file: dataset/ori_500/bar_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_12.png
originial_png_file: dataset/ori_500/box_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_9.png
Request timed out.
originial_png_file: dataset/ori_500/CB_19.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_19.png
originial_png_file: dataset/ori_500/CB_26.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_26.png
originial_png_file: dataset/ori_500/line_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_8.png
originial_png_file: dataset/ori_500/line_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_9.png
originial_png_file: dataset/ori_500/pie_14.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_14.png
originial_png_file: dataset/ori_500/multidiff_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_12.png
originial_png_file: dataset/ori_500/heatmap_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_10.png
originial_png_file: dataset/ori_500/bar_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_5.png
originial_png_file: dataset/ori_500/3d_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_12.png
originial_png_file: dataset/ori_500/errorbar_25.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_25.png
originial_png_file: dataset/ori_500/3d_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_9.png
originial_png_file: dataset/ori_500/CB_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_5.png
originial_png_file: dataset/ori_500/heatmap_21.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_21.png
originial_png_file: dataset/ori_500/hist_18.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_18.png
originial_png_file: dataset/ori_500/errorbar_14.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_14.png
originial_png_file: dataset/ori_500/scatter_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_6.png
originial_png_file: dataset/ori_500/bar_85.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_85.png
Request timed out.
originial_png_file: dataset/ori_500/multidiff_20.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_20.png
originial_png_file: dataset/ori_500/errorbar_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_8.png
originial_png_file: dataset/ori_500/line_65.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_65.png
originial_png_file: dataset/ori_500/line_36.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_36.png
originial_png_file: dataset/ori_500/multidiff_22.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_22.png
originial_png_file: dataset/ori_500/bar_86.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_86.png
originial_png_file: dataset/ori_500/line_38.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_38.png
originial_png_file: dataset/ori_500/CB_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_4.png
originial_png_file: dataset/ori_500/3d_14.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_14.png
originial_png_file: dataset/ori_500/line_18.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_18.png
originial_png_file: dataset/ori_500/line_32.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_32.png
Request timed out.
originial_png_file: dataset/ori_500/heatmap_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_2.png
originial_png_file: dataset/ori_500/scatter_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_5.png
originial_png_file: dataset/ori_500/box_18.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_18.png
originial_png_file: dataset/ori_500/hist_16.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_16.png
originial_png_file: dataset/ori_500/radar_11.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_11.png
originial_png_file: dataset/ori_500/bar_22.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_22.png
originial_png_file: dataset/ori_500/line_54.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_54.png
originial_png_file: dataset/ori_500/line_16.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_16.png
originial_png_file: dataset/ori_500/line_69.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_69.png
originial_png_file: dataset/ori_500/violin_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_1.png
originial_png_file: dataset/ori_500/bar_96.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_96.png
originial_png_file: dataset/ori_500/heatmap_27.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_27.png
originial_png_file: dataset/ori_500/scatter_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_3.png
originial_png_file: dataset/ori_500/3d_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_1.png
originial_png_file: dataset/ori_500/violin_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_8.png
originial_png_file: dataset/ori_500/multidiff_19.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_19.png
originial_png_file: dataset/ori_500/bar_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_1.png
Request timed out.
originial_png_file: dataset/ori_500/line_26.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_26.png
originial_png_file: dataset/ori_500/pie_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_2.png
originial_png_file: dataset/ori_500/line_58.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_58.png
originial_png_file: dataset/ori_500/bar_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_10.png
originial_png_file: dataset/ori_500/bar_46.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_46.png
originial_png_file: dataset/ori_500/line_24.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_24.png
originial_png_file: dataset/ori_500/line_57.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_57.png
originial_png_file: dataset/ori_500/multidiff_24.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_24.png
originial_png_file: dataset/ori_500/errorbar_17.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_17.png
originial_png_file: dataset/ori_500/bar_71.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_71.png
originial_png_file: dataset/ori_500/errorbar_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_7.png
originial_png_file: dataset/ori_500/violin_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_9.png
originial_png_file: dataset/ori_500/violin_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_10.png
originial_png_file: dataset/ori_500/radar_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_13.png
originial_png_file: dataset/ori_500/CB_22.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_22.png
originial_png_file: dataset/ori_500/line_77.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_77.png
originial_png_file: dataset/ori_500/tree_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_4.png
originial_png_file: dataset/ori_500/3d_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_2.png
originial_png_file: dataset/ori_500/errorpoint_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_1.png
originial_png_file: dataset/ori_500/violin_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_2.png
originial_png_file: dataset/ori_500/line_52.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_52.png
originial_png_file: dataset/ori_500/bar_100.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_100.png
originial_png_file: dataset/ori_500/scatter_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_10.png
originial_png_file: dataset/ori_500/errorpoint_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_8.png
originial_png_file: dataset/ori_500/quiver_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_4.png
originial_png_file: dataset/ori_500/multidiff_21.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_21.png
originial_png_file: dataset/ori_500/line_14.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_14.png
originial_png_file: dataset/ori_500/line_48.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_48.png
originial_png_file: dataset/ori_500/bar_41.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_41.png
originial_png_file: dataset/ori_500/radar_18.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_18.png
originial_png_file: dataset/ori_500/bar_94.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_94.png
originial_png_file: dataset/ori_500/line_62.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_62.png
originial_png_file: dataset/ori_500/HR_11.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_11.png
Request timed out.
Request timed out.
originial_png_file: dataset/ori_500/line_63.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_63.png
originial_png_file: dataset/ori_500/HR_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_8.png
originial_png_file: dataset/ori_500/line_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_5.png
originial_png_file: dataset/ori_500/HR_19.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_19.png
originial_png_file: dataset/ori_500/errorbar_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_1.png
originial_png_file: dataset/ori_500/line_20.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_20.png
originial_png_file: dataset/ori_500/bar_64.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_64.png
 76%|███████▌  | 16/21 [26:29<22:00, 264.05s/it] 81%|████████  | 17/21 [26:37<12:28, 187.21s/it]originial_png_file: dataset/ori_500/multidiff_25.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_25.png
originial_png_file: dataset/ori_500/bar_43.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_43.png
originial_png_file: dataset/ori_500/bar_38.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_38.png
originial_png_file: dataset/ori_500/HR_24.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_24.png
originial_png_file: dataset/ori_500/bar_61.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_61.png
originial_png_file: dataset/ori_500/bar_62.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_62.png
originial_png_file: dataset/ori_500/bar_14.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_14.png
originial_png_file: dataset/ori_500/radar_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_8.png
originial_png_file: dataset/ori_500/heatmap_11.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_11.png
originial_png_file: dataset/ori_500/line_43.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_43.png
originial_png_file: dataset/ori_500/heatmap_25.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_25.png
originial_png_file: dataset/ori_500/hist_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_10.png
originial_png_file: dataset/ori_500/line_64.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_64.png
originial_png_file: dataset/ori_500/line_19.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_19.png
originial_png_file: dataset/ori_500/line_75.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_75.png
originial_png_file: dataset/ori_500/pie_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_7.png
originial_png_file: dataset/ori_500/tree_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_5.png
Request timed out.
originial_png_file: dataset/ori_500/line_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_13.png
Request timed out.
originial_png_file: dataset/ori_500/bar_49.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_49.png
originial_png_file: dataset/ori_500/bar_80.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_80.png
originial_png_file: dataset/ori_500/scatter_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_7.png
originial_png_file: dataset/ori_500/PIP_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_1.png
originial_png_file: dataset/ori_500/errorpoint_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_6.png
originial_png_file: dataset/ori_500/bar_88.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_88.png
originial_png_file: dataset/ori_500/multidiff_17.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_17.png
originial_png_file: dataset/ori_500/bar_90.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_90.png
originial_png_file: dataset/ori_500/HR_23.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_23.png
originial_png_file: dataset/ori_500/HR_25.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_25.png
originial_png_file: dataset/ori_500/HR_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_7.png
originial_png_file: dataset/ori_500/line_44.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_44.png
originial_png_file: dataset/ori_500/line_11.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_11.png
originial_png_file: dataset/ori_500/bar_93.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_93.png
originial_png_file: dataset/ori_500/box_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_12.png
originial_png_file: dataset/ori_500/box_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_4.png
originial_png_file: dataset/ori_500/scatter_20.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_20.png
originial_png_file: dataset/ori_500/radar_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_4.png
originial_png_file: dataset/ori_500/bar_58.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_58.png
originial_png_file: dataset/ori_500/pie_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_6.png
originial_png_file: dataset/ori_500/line_51.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_51.png
originial_png_file: dataset/ori_500/bar_76.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_76.png
Request timed out.
Request timed out.
originial_png_file: dataset/ori_500/box_24.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_24.png
originial_png_file: dataset/ori_500/HR_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_12.png
originial_png_file: dataset/ori_500/box_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_13.png
originial_png_file: dataset/ori_500/heatmap_17.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_17.png
originial_png_file: dataset/ori_500/pie_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_5.png
originial_png_file: dataset/ori_500/HR_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_4.png
originial_png_file: dataset/ori_500/violin_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_5.png
originial_png_file: dataset/ori_500/3d_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_13.png
originial_png_file: dataset/ori_500/radar_20.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_20.png
Request timed out.
originial_png_file: dataset/ori_500/HR_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_13.png
originial_png_file: dataset/ori_500/pie_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_4.png
originial_png_file: dataset/ori_500/line_67.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_67.png
originial_png_file: dataset/ori_500/heatmap_22.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_22.png
originial_png_file: dataset/ori_500/radar_17.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_17.png
originial_png_file: dataset/ori_500/CB_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_10.png
originial_png_file: dataset/ori_500/box_14.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_14.png
originial_png_file: dataset/ori_500/line_76.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_76.png
originial_png_file: dataset/ori_500/heatmap_28.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_28.png
Request timed out.
originial_png_file: dataset/ori_500/line_47.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_47.png
originial_png_file: dataset/ori_500/pie_11.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_11.png
originial_png_file: dataset/ori_500/area_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_5.png
originial_png_file: dataset/ori_500/pie_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_1.png
originial_png_file: dataset/ori_500/3d_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_7.png
originial_png_file: dataset/ori_500/tree_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_1.png
originial_png_file: dataset/ori_500/multidiff_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_5.png
originial_png_file: dataset/ori_500/scatter_17.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_17.png
originial_png_file: dataset/ori_500/quiver_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_3.png
originial_png_file: dataset/ori_500/scatter_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_9.png
originial_png_file: dataset/ori_500/graph_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/graph_4.png
originial_png_file: dataset/ori_500/bar_23.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_23.png
originial_png_file: dataset/ori_500/multidiff_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_3.png
originial_png_file: dataset/ori_500/bar_32.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_32.png
originial_png_file: dataset/ori_500/box_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_5.png
originial_png_file: dataset/ori_500/line_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_3.png
originial_png_file: dataset/ori_500/box_20.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_20.png
Request timed out.
originial_png_file: dataset/ori_500/CB_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_9.png
originial_png_file: dataset/ori_500/scatter_15.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_15.png
originial_png_file: dataset/ori_500/line_71.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_71.png
Request timed out.
originial_png_file: dataset/ori_500/bar_81.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_81.png
originial_png_file: dataset/ori_500/box_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_1.png
originial_png_file: dataset/ori_500/bar_67.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_67.png
 86%|████████▌ | 18/21 [37:04<15:57, 319.18s/it]originial_png_file: dataset/ori_500/bar_92.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_92.png
originial_png_file: dataset/ori_500/bar_78.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_78.png
originial_png_file: dataset/ori_500/scatter_11.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_11.png
originial_png_file: dataset/ori_500/line_78.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_78.png
originial_png_file: dataset/ori_500/bar_21.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_21.png
originial_png_file: dataset/ori_500/heatmap_14.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_14.png
originial_png_file: dataset/ori_500/box_16.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_16.png
originial_png_file: dataset/ori_500/CB_29.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_29.png
Request timed out.
originial_png_file: dataset/ori_500/errorbar_30.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_30.png
originial_png_file: dataset/ori_500/violin_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/violin_4.png
originial_png_file: dataset/ori_500/errorbar_24.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_24.png
Request timed out.
originial_png_file: dataset/ori_500/bar_48.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_48.png
originial_png_file: dataset/ori_500/errorpoint_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_10.png
originial_png_file: dataset/ori_500/errorbar_19.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_19.png
originial_png_file: dataset/ori_500/hist_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_2.png
originial_png_file: dataset/ori_500/CB_21.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_21.png
originial_png_file: dataset/ori_500/bar_99.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_99.png
originial_png_file: dataset/ori_500/box_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_7.png
originial_png_file: dataset/ori_500/errorbar_29.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_29.png
originial_png_file: dataset/ori_500/line_40.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_40.png
Request timed out.
 90%|█████████ | 19/21 [37:27<07:40, 230.23s/it] 95%|█████████▌| 20/21 [37:38<02:44, 164.36s/it]100%|██████████| 21/21 [37:56<00:00, 120.44s/it]100%|██████████| 21/21 [37:56<00:00, 108.39s/it]
originial_png_file: dataset/ori_500/bar_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_6.png
originial_png_file: dataset/ori_500/CB_16.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_16.png
originial_png_file: dataset/ori_500/multidiff_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_9.png
originial_png_file: dataset/ori_500/pie_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_12.png
originial_png_file: dataset/ori_500/CB_28.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_28.png
originial_png_file: dataset/ori_500/radar_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_7.png
originial_png_file: dataset/ori_500/errorbar_21.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_21.png
originial_png_file: dataset/ori_500/errorbar_18.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_18.png
originial_png_file: dataset/ori_500/errorbar_23.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_23.png
originial_png_file: dataset/ori_500/line_34.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_34.png
originial_png_file: dataset/ori_500/CB_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_2.png
originial_png_file: dataset/ori_500/CB_24.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_24.png
originial_png_file: dataset/ori_500/multidiff_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_10.png
Request timed out.
originial_png_file: dataset/ori_500/line_73.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_73.png
originial_png_file: dataset/ori_500/PIP_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_2.png
originial_png_file: dataset/ori_500/multidiff_11.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_11.png
Request timed out.
originial_png_file: dataset/ori_500/scatter_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_2.png
originial_png_file: dataset/ori_500/scatter_18.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_18.png
Request timed out.
originial_png_file: dataset/ori_500/bar_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_13.png
originial_png_file: dataset/ori_500/heatmap_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_8.png
originial_png_file: dataset/ori_500/PIP_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_6.png
originial_png_file: dataset/ori_500/bar_56.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_56.png
originial_png_file: dataset/ori_500/CB_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_7.png
originial_png_file: dataset/ori_500/tree_2.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/tree_2.png
Request timed out.
originial_png_file: dataset/ori_500/multidiff_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/multidiff_6.png
Request timed out.
originial_png_file: dataset/ori_500/scatter_25.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_25.png
originial_png_file: dataset/ori_500/line_46.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_46.png
originial_png_file: dataset/ori_500/radar_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_9.png
originial_png_file: dataset/ori_500/line_27.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_27.png
originial_png_file: dataset/ori_500/box_23.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_23.png
originial_png_file: dataset/ori_500/bar_35.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_35.png
originial_png_file: dataset/ori_500/CB_15.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_15.png
originial_png_file: dataset/ori_500/HR_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_1.png
originial_png_file: dataset/ori_500/bar_25.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_25.png
originial_png_file: dataset/ori_500/PIP_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_5.png
originial_png_file: dataset/ori_500/errorbar_15.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_15.png
originial_png_file: dataset/ori_500/heatmap_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_7.png
Request timed out.
originial_png_file: dataset/ori_500/quiver_5.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/quiver_5.png
originial_png_file: dataset/ori_500/box_17.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_17.png
originial_png_file: dataset/ori_500/heatmap_29.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_29.png
Request timed out.
originial_png_file: dataset/ori_500/errorbar_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_12.png
originial_png_file: dataset/ori_500/errorbar_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_4.png
originial_png_file: dataset/ori_500/area_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_4.png
originial_png_file: dataset/ori_500/bar_95.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_95.png
originial_png_file: dataset/ori_500/bar_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_9.png
originial_png_file: dataset/ori_500/line_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_12.png
originial_png_file: dataset/ori_500/box_21.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/box_21.png
originial_png_file: dataset/ori_500/line_79.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_79.png
originial_png_file: dataset/ori_500/line_56.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_56.png
originial_png_file: dataset/ori_500/bar_20.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_20.png
originial_png_file: dataset/ori_500/bar_50.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_50.png
originial_png_file: dataset/ori_500/bar_75.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_75.png
originial_png_file: dataset/ori_500/radar_10.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/radar_10.png
originial_png_file: dataset/ori_500/CB_25.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/CB_25.png
originial_png_file: dataset/ori_500/line_80.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_80.png
originial_png_file: dataset/ori_500/bar_26.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_26.png
originial_png_file: dataset/ori_500/line_15.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_15.png
originial_png_file: dataset/ori_500/line_60.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_60.png
originial_png_file: dataset/ori_500/hist_12.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_12.png
Request timed out.
originial_png_file: dataset/ori_500/line_66.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_66.png
Request timed out.
originial_png_file: dataset/ori_500/bar_77.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_77.png
Request timed out.
Request timed out.
originial_png_file: dataset/ori_500/bar_37.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_37.png
Request timed out.
originial_png_file: dataset/ori_500/bar_40.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_40.png
originial_png_file: dataset/ori_500/bar_60.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_60.png
originial_png_file: dataset/ori_500/hist_1.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/hist_1.png
Request timed out.
originial_png_file: dataset/ori_500/heatmap_13.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_13.png
originial_png_file: dataset/ori_500/heatmap_6.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/heatmap_6.png
originial_png_file: dataset/ori_500/line_45.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_45.png
originial_png_file: dataset/ori_500/scatter_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_8.png
originial_png_file: dataset/ori_500/PIP_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/PIP_3.png
originial_png_file: dataset/ori_500/line_70.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_70.png
originial_png_file: dataset/ori_500/area_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/area_3.png
Request timed out.
originial_png_file: dataset/ori_500/line_35.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_35.png
originial_png_file: dataset/ori_500/3d_4.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/3d_4.png
originial_png_file: dataset/ori_500/bar_8.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_8.png
originial_png_file: dataset/ori_500/bar_51.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_51.png
originial_png_file: dataset/ori_500/errorpoint_9.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorpoint_9.png
originial_png_file: dataset/ori_500/line_41.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_41.png
originial_png_file: dataset/ori_500/errorbar_27.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/errorbar_27.png
Request timed out.
Request timed out.
originial_png_file: dataset/ori_500/bar_17.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/bar_17.png
originial_png_file: dataset/ori_500/HR_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/HR_3.png
Request timed out.
originial_png_file: dataset/ori_500/scatter_14.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/scatter_14.png
originial_png_file: dataset/ori_500/pie_3.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/pie_3.png
originial_png_file: dataset/ori_500/line_7.png generated_png_file: results/direct/chart2code_stage2_llm_2nodes_1e5_web2code_bsz128_1e5_web2code_job_fixed-4000_DirectAgent_results/direct/line_7.png
Request timed out.
Time taken:  4943.195023536682
所有模型处理完成。
